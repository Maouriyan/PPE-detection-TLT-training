{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Mask Detection using NVIDIA TLT "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MIT License (MIT)\n",
    "\n",
    "Copyright (c) 2019-2020, NVIDIA CORPORATION.\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of\n",
    "this software and associated documentation files (the \"Software\"), to deal in\n",
    "the Software without restriction, including without limitation the rights to\n",
    "use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\n",
    "the Software, and to permit persons to whom the Software is furnished to do so,\n",
    "subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\n",
    "FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\n",
    "COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\n",
    "IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n",
    "CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DetectNet_v2 with ResNet-18 example usecase\n",
    "\n",
    "The goal of this notebook is to utilize NVIDIA TLT to train and make PPE detection model deploy ready.\n",
    "While working on such application, this notebook will serve as an example usecase of Object Detection using DetectNet_v2 in the Transfer Learning Toolkit.\n",
    "\n",
    "0. [Set up env variables](#head-0)\n",
    "1. [Prepare dataset and pre-trained model](#head-1)\n",
    "    1. [Download dataset](#head-1-1)\n",
    "    1. [Prepare tfrecords from kitti format dataset](#head-1-2)\n",
    "    2. [Download pre-trained model](#head-1-3)\n",
    "2. [Provide training specification](#head-2)\n",
    "3. [Run TLT training](#head-3)\n",
    "4. [Evaluate trained models](#head-4)\n",
    "5. [Prune trained models](#head-5)\n",
    "6. [Retrain pruned models](#head-6)\n",
    "7. [Evaluate retrained model](#head-7)\n",
    "8. [Visualize inferences](#head-8)\n",
    "9. [Deploy](#head-9)\n",
    "    1. [Int8 Optimization](#head-9-1)\n",
    "    2. [Generate TensorRT engine](#head-9-2)\n",
    "10. [Verify Deployed Model](#head-10)\n",
    "    1. [Inference using TensorRT engine](#head-10-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Set up env variables <a class=\"anchor\" id=\"head-0\"></a>\n",
    "When using the purpose-built pretrained models from NGC, please make sure to set the `$KEY` environment variable to the key as mentioned in the model overview. Failing to do so, can lead to errors when trying to load them as pretrained models.\n",
    "\n",
    "*Note: Please make sure to remove any stray artifacts/files from the `$USER_EXPERIMENT_DIR` or `$DATA_DOWNLOAD_DIR` paths as mentioned below, that may have been generated from previous experiments. Having checkpoint files etc may interfere with creating a training graph for a new experiment.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update directory paths if needed\n",
      "env: KEY=tlt_encode\n",
      "env: USER_EXPERIMENT_DIR=helmet/detectnet_v2\n",
      "env: DATA_DOWNLOAD_DIR=helmet/data_fm_0916\n",
      "env: SPECS_DIR=helmet/detectnet_v2/tlt_specs\n",
      "env: NUM_GPUS=1\n"
     ]
    }
   ],
   "source": [
    "# Setting up env variables for cleaner command line commands.\n",
    "print(\"Update directory paths if needed\")\n",
    "%env KEY=tlt_encode\n",
    "# User directory - pre-trained/unpruned/pruned/final models will be saved here\n",
    "%env USER_EXPERIMENT_DIR=helmet/detectnet_v2\n",
    "# Download directory - tfrecords will be generated here\n",
    "%env DATA_DOWNLOAD_DIR=helmet/data_fm_0916         \n",
    "# Spec Directory\n",
    "%env SPECS_DIR=helmet/detectnet_v2/tlt_specs  \n",
    "# Number of GPUs used for training\n",
    "%env NUM_GPUS=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare dataset and pre-trained model <a class=\"anchor\" id=\"head-1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Download dataset  <a class=\"anchor\" id=\"head-1-1\"></a>\n",
    "\n",
    "Images and Labels folder in the repository\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Download the data using provided links, such that all images and label files are in one folder. We expect in structure noted in GitHub repo.\n",
    "- Convert dataset to KITTI format \n",
    "- Use KITTI format directory as \"$DATA_DOWNLOAD_DIR\"\n",
    "\n",
    "\n",
    "Note: We do not use all the images from MAFA and WiderFace. Combining we will use about 6000 faces each with and without mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Prepare tf records from kitti format dataset <a class=\"anchor\" id=\"head-1-2\"></a>\n",
    "\n",
    "* Update the tfrecords spec file to take in your kitti format dataset\n",
    "* Create the tfrecords using the tlt-dataset-convert \n",
    "\n",
    "*Note: TfRecords only need to be generated once.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFrecords conversion spec file for kitti training\n",
      "kitti_config {\r\n",
      "  root_directory_path: \"/workspace/mntpt/helmet\"\r\n",
      "  image_dir_name: \"images\"\r\n",
      "  label_dir_name: \"labels\"\r\n",
      "  image_extension: \".jpg\"\r\n",
      "  partition_mode: \"random\"\r\n",
      "  num_partitions: 2\r\n",
      "  val_split: 20\r\n",
      "  num_shards: 10 }\r\n"
     ]
    }
   ],
   "source": [
    "print(\"TFrecords conversion spec file for kitti training\")\n",
    "!cat $SPECS_DIR/detectnet_v2_tfrecords_kitti_trainval.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting Tfrecords for kitti trainval dataset\n",
      "2021-06-20 06:27:35.583485: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "Using TensorFlow backend.\n",
      "2021-06-20 06:27:37,364 - iva.detectnet_v2.dataio.build_converter - INFO - Instantiating a kitti converter\n",
      "2021-06-20 06:27:37,367 - iva.detectnet_v2.dataio.kitti_converter_lib - INFO - Num images in\n",
      "Train: 988\tVal: 247\n",
      "2021-06-20 06:27:37,367 - iva.detectnet_v2.dataio.kitti_converter_lib - INFO - Validation data in partition 0. Hence, while choosing the validationset during training choose validation_fold 0.\n",
      "2021-06-20 06:27:37,368 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 0, shard 0\n",
      "WARNING:tensorflow:From /home/vpraveen/.cache/dazel/_dazel_vpraveen/715c8bafe7816f3bb6f309cd506049bb/execroot/ai_infra/bazel-out/k8-py3-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/detectnet_v2/dataio/dataset_converter_lib.py:142: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
      "\n",
      "2021-06-20 06:27:37,368 - tensorflow - WARNING - From /home/vpraveen/.cache/dazel/_dazel_vpraveen/715c8bafe7816f3bb6f309cd506049bb/execroot/ai_infra/bazel-out/k8-py3-fastbuild/bin/magnet/packages/iva/build_wheel.runfiles/ai_infra/iva/detectnet_v2/dataio/dataset_converter_lib.py:142: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/iva/detectnet_v2/dataio/kitti_converter_lib.py:273: VisibleDeprecationWarning: Reading unicode strings without specifying the encoding argument is deprecated. Set the encoding, use None for the system default.\n",
      "2021-06-20 06:27:37,394 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 0, shard 1\n",
      "2021-06-20 06:27:37,426 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 0, shard 2\n",
      "2021-06-20 06:27:37,451 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 0, shard 3\n",
      "2021-06-20 06:27:37,483 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 0, shard 4\n",
      "2021-06-20 06:27:37,509 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 0, shard 5\n",
      "2021-06-20 06:27:37,539 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 0, shard 6\n",
      "2021-06-20 06:27:37,569 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 0, shard 7\n",
      "2021-06-20 06:27:37,604 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 0, shard 8\n",
      "2021-06-20 06:27:37,631 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 0, shard 9\n",
      "2021-06-20 06:27:37,664 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - \n",
      "Wrote the following numbers of objects:\n",
      "b'person': 5\n",
      "b'helmet': 285\n",
      "b'person_with_helmet': 267\n",
      "b'person_without_helmet': 151\n",
      "\n",
      "2021-06-20 06:27:37,664 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 1, shard 0\n",
      "2021-06-20 06:27:37,761 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 1, shard 1\n",
      "2021-06-20 06:27:37,893 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 1, shard 2\n",
      "2021-06-20 06:27:38,003 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 1, shard 3\n",
      "2021-06-20 06:27:38,109 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 1, shard 4\n",
      "2021-06-20 06:27:38,228 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 1, shard 5\n",
      "2021-06-20 06:27:38,339 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 1, shard 6\n",
      "2021-06-20 06:27:38,465 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 1, shard 7\n",
      "2021-06-20 06:27:38,589 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 1, shard 8\n",
      "2021-06-20 06:27:38,718 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Writing partition 1, shard 9\n",
      "2021-06-20 06:27:38,837 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - \n",
      "Wrote the following numbers of objects:\n",
      "b'helmet': 1078\n",
      "b'person_with_helmet': 992\n",
      "b'person_without_helmet': 501\n",
      "b'person': 51\n",
      "\n",
      "2021-06-20 06:27:38,837 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Cumulative object statistics\n",
      "2021-06-20 06:27:38,837 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - \n",
      "Wrote the following numbers of objects:\n",
      "b'person': 56\n",
      "b'helmet': 1363\n",
      "b'person_with_helmet': 1259\n",
      "b'person_without_helmet': 652\n",
      "\n",
      "2021-06-20 06:27:38,837 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Class map. \n",
      "Label in GT: Label in tfrecords file \n",
      "b'person': b'person'\n",
      "b'helmet': b'helmet'\n",
      "b'person_with_helmet': b'person_with_helmet'\n",
      "b'person_without_helmet': b'person_without_helmet'\n",
      "For the dataset_config in the experiment_spec, please use labels in the tfrecords file, while writing the classmap.\n",
      "\n",
      "2021-06-20 06:27:38,837 - iva.detectnet_v2.dataio.dataset_converter_lib - INFO - Tfrecords generation complete.\n"
     ]
    }
   ],
   "source": [
    "# Creating a new directory for the output tfrecords dump.\n",
    "print(\"Converting Tfrecords for kitti trainval dataset\")\n",
    "!tlt-dataset-convert -d $SPECS_DIR/detectnet_v2_tfrecords_kitti_trainval.txt \\\n",
    "                     -o $DATA_DOWNLOAD_DIR/tfrecords/kitti_trainval/kitti_trainval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 932\r\n",
      "-rwxrwxrwx 1 1000 1000 17661 Jun 20 06:27 kitti_trainval-fold-000-of-002-shard-00000-of-00010\r\n",
      "-rwxrwxrwx 1 1000 1000 18754 Jun 20 06:27 kitti_trainval-fold-000-of-002-shard-00001-of-00010\r\n",
      "-rwxrwxrwx 1 1000 1000 17129 Jun 20 06:27 kitti_trainval-fold-000-of-002-shard-00002-of-00010\r\n",
      "-rwxrwxrwx 1 1000 1000 16396 Jun 20 06:27 kitti_trainval-fold-000-of-002-shard-00003-of-00010\r\n",
      "-rwxrwxrwx 1 1000 1000 18345 Jun 20 06:27 kitti_trainval-fold-000-of-002-shard-00004-of-00010\r\n",
      "-rwxrwxrwx 1 1000 1000 18955 Jun 20 06:27 kitti_trainval-fold-000-of-002-shard-00005-of-00010\r\n",
      "-rwxrwxrwx 1 1000 1000 19038 Jun 20 06:27 kitti_trainval-fold-000-of-002-shard-00006-of-00010\r\n",
      "-rwxrwxrwx 1 1000 1000 17079 Jun 20 06:27 kitti_trainval-fold-000-of-002-shard-00007-of-00010\r\n",
      "-rwxrwxrwx 1 1000 1000 17651 Jun 20 06:27 kitti_trainval-fold-000-of-002-shard-00008-of-00010\r\n",
      "-rwxrwxrwx 1 1000 1000 23797 Jun 20 06:27 kitti_trainval-fold-000-of-002-shard-00009-of-00010\r\n",
      "-rwxrwxrwx 1 1000 1000 74715 Jun 20 06:27 kitti_trainval-fold-001-of-002-shard-00000-of-00010\r\n",
      "-rwxrwxrwx 1 1000 1000 71554 Jun 20 06:27 kitti_trainval-fold-001-of-002-shard-00001-of-00010\r\n",
      "-rwxrwxrwx 1 1000 1000 72713 Jun 20 06:27 kitti_trainval-fold-001-of-002-shard-00002-of-00010\r\n",
      "-rwxrwxrwx 1 1000 1000 71207 Jun 20 06:27 kitti_trainval-fold-001-of-002-shard-00003-of-00010\r\n",
      "-rwxrwxrwx 1 1000 1000 71888 Jun 20 06:27 kitti_trainval-fold-001-of-002-shard-00004-of-00010\r\n",
      "-rwxrwxrwx 1 1000 1000 70355 Jun 20 06:27 kitti_trainval-fold-001-of-002-shard-00005-of-00010\r\n",
      "-rwxrwxrwx 1 1000 1000 73342 Jun 20 06:27 kitti_trainval-fold-001-of-002-shard-00006-of-00010\r\n",
      "-rwxrwxrwx 1 1000 1000 69854 Jun 20 06:27 kitti_trainval-fold-001-of-002-shard-00007-of-00010\r\n",
      "-rwxrwxrwx 1 1000 1000 72726 Jun 20 06:27 kitti_trainval-fold-001-of-002-shard-00008-of-00010\r\n",
      "-rwxrwxrwx 1 1000 1000 75938 Jun 20 06:27 kitti_trainval-fold-001-of-002-shard-00009-of-00010\r\n"
     ]
    }
   ],
   "source": [
    "!ls -rlt $DATA_DOWNLOAD_DIR/tfrecords/kitti_trainval/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Download pre-trained model <a class=\"anchor\" id=\"head-1-3\"></a>\n",
    "Download the correct pretrained model from the NGC model registry for your experiment. Please note that for DetectNet_v2, the input is expected to be 0-1 normalized with input channels in RGB order. Therefore, for optimum results please download models with `*_detectnet_v2` in their name string. All other models expect input preprocessing with mean subtraction and input channels in BGR order. Thus, using them as pretrained weights may result in suboptimal performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+-------+-------+-------+-------+\r\n",
      "| Versi | Accur | Epoch | Batch | GPU   | Memor | File  | Statu | Creat |\r\n",
      "| on    | acy   | s     | Size  | Model | y Foo | Size  | s     | ed    |\r\n",
      "|       |       |       |       |       | tprin |       |       | Date  |\r\n",
      "|       |       |       |       |       | t     |       |       |       |\r\n",
      "+-------+-------+-------+-------+-------+-------+-------+-------+-------+\r\n",
      "| vgg19 | 82.6  | 80    | 1     | V100  | 153.8 | 153.7 | UPLOA | Apr   |\r\n",
      "|       |       |       |       |       |       | 7 MB  | D_COM | 29,   |\r\n",
      "|       |       |       |       |       |       |       | PLETE | 2020  |\r\n",
      "| vgg16 | 82.2  | 80    | 1     | V100  | 113.2 | 113.2 | UPLOA | Apr   |\r\n",
      "|       |       |       |       |       |       | MB    | D_COM | 29,   |\r\n",
      "|       |       |       |       |       |       |       | PLETE | 2020  |\r\n",
      "| squee | 65.67 | 80    | 1     | V100  | 6.5   | 6.46  | UPLOA | Apr   |\r\n",
      "| zenet |       |       |       |       |       | MB    | D_COM | 29,   |\r\n",
      "|       |       |       |       |       |       |       | PLETE | 2020  |\r\n",
      "| resne | 82.7  | 80    | 1     | V100  | 294.5 | 294.5 | UPLOA | Apr   |\r\n",
      "| t50   |       |       |       |       |       | 3 MB  | D_COM | 29,   |\r\n",
      "|       |       |       |       |       |       |       | PLETE | 2020  |\r\n",
      "| resne | 79.5  | 80    | 1     | V100  | 163.6 | 163.5 | UPLOA | Aug   |\r\n",
      "| t34   |       |       |       |       |       | 5 MB  | D_COM | 03,   |\r\n",
      "|       |       |       |       |       |       |       | PLETE | 2020  |\r\n",
      "| resne | 79.0  | 80    | 1     | V100  | 89.0  | 89.02 | UPLOA | Apr   |\r\n",
      "| t18   |       |       |       |       |       | MB    | D_COM | 29,   |\r\n",
      "|       |       |       |       |       |       |       | PLETE | 2020  |\r\n",
      "| resne | 79.2  | 80    | 1     | V100  | 38.3  | 38.34 | UPLOA | Apr   |\r\n",
      "| t10   |       |       |       |       |       | MB    | D_COM | 29,   |\r\n",
      "|       |       |       |       |       |       |       | PLETE | 2020  |\r\n",
      "| mobil | 77.5  | 80    | 1     | V100  | 5.1   | 5.1   | UPLOA | Apr   |\r\n",
      "| enet_ |       |       |       |       |       | MB    | D_COM | 29,   |\r\n",
      "| v2    |       |       |       |       |       |       | PLETE | 2020  |\r\n",
      "| mobil | 79.5  | 80    | 1     | V100  | 13.4  | 13.37 | UPLOA | Apr   |\r\n",
      "| enet_ |       |       |       |       |       | MB    | D_COM | 29,   |\r\n",
      "| v1    |       |       |       |       |       |       | PLETE | 2020  |\r\n",
      "| googl | 82.2  | 80    | 1     | V100  | 47.7  | 47.74 | UPLOA | Apr   |\r\n",
      "| enet  |       |       |       |       |       | MB    | D_COM | 29,   |\r\n",
      "|       |       |       |       |       |       |       | PLETE | 2020  |\r\n",
      "| effic | 77.11 | 80    | 1     | V100  | 16.9  | 16.9  | UPLOA | Jun   |\r\n",
      "| ientn |       |       |       |       |       | MB    | D_COM | 09,   |\r\n",
      "| et_b0 |       |       |       |       |       |       | PLETE | 2021  |\r\n",
      "| _swis |       |       |       |       |       |       |       |       |\r\n",
      "| h     |       |       |       |       |       |       |       |       |\r\n",
      "| effic | 77.11 | 80    | 1     | V100  | 16.9  | 16.9  | UPLOA | Jun   |\r\n",
      "| ientn |       |       |       |       |       | MB    | D_COM | 09,   |\r\n",
      "| et_b0 |       |       |       |       |       |       | PLETE | 2021  |\r\n",
      "| _relu |       |       |       |       |       |       |       |       |\r\n",
      "| darkn | 76.44 | 80    | 1     | V100  | 467.3 | 467.3 | UPLOA | Apr   |\r\n",
      "| et53  |       |       |       |       |       | 2 MB  | D_COM | 29,   |\r\n",
      "|       |       |       |       |       |       |       | PLETE | 2020  |\r\n",
      "| darkn | 77.52 | 80    | 1     | V100  | 229.1 | 229.1 | UPLOA | Apr   |\r\n",
      "| et19  |       |       |       |       |       | 5 MB  | D_COM | 29,   |\r\n",
      "|       |       |       |       |       |       |       | PLETE | 2020  |\r\n",
      "+-------+-------+-------+-------+-------+-------+-------+-------+-------+\r\n"
     ]
    }
   ],
   "source": [
    "# List models available in the model registry.\n",
    "!ngc registry model list nvidia/tlt_pretrained_detectnet_v2:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the target destination to download the model.\n",
    "!mkdir -p $USER_EXPERIMENT_DIR/pretrained_resnet18/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 82.28 MB in 20s, Download speed: 4.11 MB/s               \n",
      "----------------------------------------------------\n",
      "Transfer id: tlt_pretrained_detectnet_v2_vresnet18 Download status: Completed.\n",
      "Downloaded local path: /workspace/mntpt/home/detectnet_v2/pretrained_resnet18/tlt_pretrained_detectnet_v2_vresnet18\n",
      "Total files downloaded: 1 \n",
      "Total downloaded size: 82.28 MB\n",
      "Started at: 2021-06-14 07:19:33.280954\n",
      "Completed at: 2021-06-14 07:19:53.305744\n",
      "Duration taken: 20s\n",
      "----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Download the pretrained model from NGC\n",
    "!ngc registry model download-version nvidia/tlt_pretrained_detectnet_v2:resnet18 \\\n",
    "    --dest $USER_EXPERIMENT_DIR/pretrained_resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 91160\r\n",
      "-rwxrwxrwx 1 1000 1000 93345248 Jun 14 07:19 resnet18.hdf5\r\n"
     ]
    }
   ],
   "source": [
    "!ls -rlt $USER_EXPERIMENT_DIR/pretrained_resnet18/tlt_pretrained_detectnet_v2_vresnet18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Provide training specification <a class=\"anchor\" id=\"head-2\"></a>\n",
    "* Tfrecords for the train datasets\n",
    "    * In order to use the newly generated tfrecords, update the dataset_config parameter in the spec file at `$SPECS_DIR/detectnet_v2_train_resnet18_kitti.txt` \n",
    "    * Update the fold number to use for evaluation. In case of random data split, please use fold `0` only\n",
    "    * For sequence-wise split, you may use any fold generated from the dataset convert tool\n",
    "* Pre-trained models\n",
    "* Augmentation parameters for on the fly data augmentation\n",
    "* Other training (hyper-)parameters such as batch size, number of epochs, learning rate etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_seed: 42\r\n",
      "dataset_config {\r\n",
      "  data_sources {\r\n",
      "    tfrecords_path: \"/workspace/mntpt/helmet/data_fm_0916/tfrecords/kitti_trainval/*\"\r\n",
      "    image_directory_path: \"/workspace/mntpt/helmet\"\r\n",
      "  }\r\n",
      "  image_extension: \"jpg\"\r\n",
      "  target_class_mapping {\r\n",
      "    key: \"helmet\"\r\n",
      "    value: \"helmet\"\r\n",
      "  }\r\n",
      "  target_class_mapping {\r\n",
      "    key: \"person_with_helmet\"\r\n",
      "    value: \"person_with_helmet\"\r\n",
      "  }\r\n",
      "  target_class_mapping {\r\n",
      "    key: \"person_without_helmet\"\r\n",
      "    value: \"person_without_helmet\"\r\n",
      "  }\r\n",
      "  validation_fold: 0\r\n",
      "  #validation_data_source: {\r\n",
      "    #tfrecords_path: \"/home/data/tfrecords/kitti_val/*\"\r\n",
      "    #image_directory_path: \"/home/data/test\"\r\n",
      "  #}\r\n",
      "}\r\n",
      "\r\n",
      "\r\n",
      "augmentation_config {\r\n",
      "  preprocessing {\r\n",
      "    output_image_width: 960\r\n",
      "    output_image_height: 544\r\n",
      "    min_bbox_width: 1.0\r\n",
      "    min_bbox_height: 1.0\r\n",
      "    output_image_channel: 3\r\n",
      "  }\r\n",
      "  spatial_augmentation {\r\n",
      "    hflip_probability: 0.5\r\n",
      "    vflip_probability: 0.0\r\n",
      "    zoom_min: 1.0\r\n",
      "    zoom_max: 1.0\r\n",
      "    translate_max_x: 8.0\r\n",
      "    translate_max_y: 8.0\r\n",
      "  }\r\n",
      "  color_augmentation {\r\n",
      "    hue_rotation_max: 25.0\r\n",
      "    saturation_shift_max: 0.20000000298\r\n",
      "    contrast_scale_max: 0.10000000149\r\n",
      "    contrast_center: 0.5\r\n",
      "  }\r\n",
      "}\r\n",
      "\r\n",
      "postprocessing_config {\r\n",
      "  target_class_config {\r\n",
      "    key: \"helmet\"\r\n",
      "    value {\r\n",
      "      clustering_config {\r\n",
      "        coverage_threshold: 0.00499999988824\r\n",
      "        dbscan_eps: 0.20000000298\r\n",
      "        dbscan_min_samples: 0.0500000007451\r\n",
      "        minimum_bounding_box_height: 20\r\n",
      "      }\r\n",
      "    }\r\n",
      "  }\r\n",
      "  target_class_config {\r\n",
      "    key: \"person_with_helmet\"\r\n",
      "    value {\r\n",
      "      clustering_config {\r\n",
      "        coverage_threshold: 0.00499999988824\r\n",
      "        dbscan_eps: 0.20000000298\r\n",
      "        dbscan_min_samples: 0.0500000007451\r\n",
      "        minimum_bounding_box_height: 20\r\n",
      "      }\r\n",
      "    }\r\n",
      "  }\r\n",
      "  target_class_config {\r\n",
      "    key: \"person_without_helmet\"\r\n",
      "    value {\r\n",
      "      clustering_config {\r\n",
      "        coverage_threshold: 0.00499999988824\r\n",
      "        dbscan_eps: 0.15000000596\r\n",
      "        dbscan_min_samples: 0.0500000007451\r\n",
      "        minimum_bounding_box_height: 20\r\n",
      "      }\r\n",
      "    }\r\n",
      "  }\r\n",
      "}\r\n",
      "\r\n",
      "model_config {\r\n",
      "  pretrained_model_file: \"/workspace/mntpt/tlt-workspace/detectnet_v2/pretrained_resnet18/tlt_pretrained_detectnet_v2_vresnet18/resnet18.hdf5\"\r\n",
      "  num_layers: 18\r\n",
      "  use_batch_norm: true\r\n",
      "  objective_set {\r\n",
      "    bbox {\r\n",
      "      scale: 35.0\r\n",
      "      offset: 0.5\r\n",
      "    }\r\n",
      "    cov {\r\n",
      "    }\r\n",
      "  }\r\n",
      "  training_precision {\r\n",
      "    backend_floatx: FLOAT32\r\n",
      "  }\r\n",
      "  arch: \"resnet\"\r\n",
      "}\r\n",
      "\r\n",
      "evaluation_config {\r\n",
      "  validation_period_during_training: 10\r\n",
      "  first_validation_epoch: 10\r\n",
      "  minimum_detection_ground_truth_overlap {\r\n",
      "    key: \"helmet\"\r\n",
      "    value: 0.5\r\n",
      "  }\r\n",
      "  minimum_detection_ground_truth_overlap {\r\n",
      "    key: \"person_with_helmet\"\r\n",
      "    value: 0.5\r\n",
      "  }\r\n",
      "  minimum_detection_ground_truth_overlap {\r\n",
      "    key: \"person_without_helmet\"\r\n",
      "    value: 0.5\r\n",
      "  }\r\n",
      "  evaluation_box_config {\r\n",
      "    key: \"helmet\"\r\n",
      "    value {\r\n",
      "      minimum_height: 20\r\n",
      "      maximum_height: 9999\r\n",
      "      minimum_width: 10\r\n",
      "      maximum_width: 9999\r\n",
      "    }\r\n",
      "  }\r\n",
      "  evaluation_box_config {\r\n",
      "    key: \"person_with_helmet\"\r\n",
      "    value {\r\n",
      "      minimum_height: 20\r\n",
      "      maximum_height: 9999\r\n",
      "      minimum_width: 10\r\n",
      "      maximum_width: 9999\r\n",
      "    }\r\n",
      "  }\r\n",
      "  evaluation_box_config {\r\n",
      "    key: \"person_without_helmet\"\r\n",
      "    value {\r\n",
      "      minimum_height: 20\r\n",
      "      maximum_height: 9999\r\n",
      "      minimum_width: 10\r\n",
      "      maximum_width: 9999\r\n",
      "    }\r\n",
      "  }\r\n",
      "  average_precision_mode: INTEGRATE\r\n",
      "}\r\n",
      "\r\n",
      "cost_function_config {\r\n",
      "  target_classes {\r\n",
      "    name: \"helmet\"\r\n",
      "    class_weight: 1.0\r\n",
      "    coverage_foreground_weight: 0.0500000007451\r\n",
      "    objectives {\r\n",
      "      name: \"cov\"\r\n",
      "      initial_weight: 1.0\r\n",
      "      weight_target: 1.0\r\n",
      "    }\r\n",
      "    objectives {\r\n",
      "      name: \"bbox\"\r\n",
      "      initial_weight: 10.0\r\n",
      "      weight_target: 10.0\r\n",
      "    }\r\n",
      "  }\r\n",
      "  target_classes {\r\n",
      "    name: \"person_with_helmet\"\r\n",
      "    class_weight: 1.0\r\n",
      "    coverage_foreground_weight: 0.0500000007451\r\n",
      "    objectives {\r\n",
      "      name: \"cov\"\r\n",
      "      initial_weight: 1.0\r\n",
      "      weight_target: 1.0\r\n",
      "    }\r\n",
      "    objectives {\r\n",
      "      name: \"bbox\"\r\n",
      "      initial_weight: 10.0\r\n",
      "      weight_target: 10.0\r\n",
      "    }\r\n",
      "  }\r\n",
      "  target_classes {\r\n",
      "    name: \"person_without_helmet\"\r\n",
      "    class_weight: 8.0\r\n",
      "    coverage_foreground_weight: 0.0500000007451\r\n",
      "    objectives {\r\n",
      "      name: \"cov\"\r\n",
      "      initial_weight: 1.0\r\n",
      "      weight_target: 1.0\r\n",
      "    }\r\n",
      "    objectives {\r\n",
      "      name: \"bbox\"\r\n",
      "      initial_weight: 10.0\r\n",
      "      weight_target: 1.0\r\n",
      "    }\r\n",
      "  }\r\n",
      "  enable_autoweighting: true\r\n",
      "  max_objective_weight: 0.999899983406\r\n",
      "  min_objective_weight: 9.99999974738e-05\r\n",
      "}\r\n",
      "\r\n",
      "training_config {\r\n",
      "  batch_size_per_gpu: 14\r\n",
      "  num_epochs: 200\r\n",
      "  learning_rate {\r\n",
      "    soft_start_annealing_schedule {\r\n",
      "      min_learning_rate: 5e-06\r\n",
      "      max_learning_rate: 5e-04\r\n",
      "      soft_start: 0.10000000149\r\n",
      "      annealing: 0.699999988079\r\n",
      "    }\r\n",
      "  }\r\n",
      "  regularizer {\r\n",
      "    type: L1\r\n",
      "    weight: 3.00000002618e-09\r\n",
      "  }\r\n",
      "  optimizer {\r\n",
      "    adam {\r\n",
      "      epsilon: 9.99999993923e-09\r\n",
      "      beta1: 0.899999976158\r\n",
      "      beta2: 0.999000012875\r\n",
      "    }\r\n",
      "  }\r\n",
      "  cost_scaling {\r\n",
      "    initial_exponent: 20.0\r\n",
      "    increment: 0.005\r\n",
      "    decrement: 1.0\r\n",
      "  }\r\n",
      "  checkpoint_interval: 30\r\n",
      "}\r\n",
      "\r\n",
      "bbox_rasterizer_config {\r\n",
      "  target_class_config {\r\n",
      "    key: \"helmet\"\r\n",
      "    value {\r\n",
      "      cov_center_x: 0.5\r\n",
      "      cov_center_y: 0.5\r\n",
      "      cov_radius_x: 0.40000000596\r\n",
      "      cov_radius_y: 0.40000000596\r\n",
      "      bbox_min_radius: 1.0\r\n",
      "    }\r\n",
      "  }\r\n",
      "  target_class_config {\r\n",
      "    key: \"person_with_helmet\"\r\n",
      "    value {\r\n",
      "      cov_center_x: 0.5\r\n",
      "      cov_center_y: 0.5\r\n",
      "      cov_radius_x: 1.0\r\n",
      "      cov_radius_y: 1.0\r\n",
      "      bbox_min_radius: 1.0\r\n",
      "    }\r\n",
      "  }\r\n",
      "  target_class_config {\r\n",
      "    key: \"person_without_helmet\"\r\n",
      "    value {\r\n",
      "      cov_center_x: 0.5\r\n",
      "      cov_center_y: 0.5\r\n",
      "      cov_radius_x: 0.40000000596\r\n",
      "      cov_radius_y: 0.40000000596\r\n",
      "      bbox_min_radius: 1.0\r\n",
      "    }\r\n",
      "  }\r\n",
      "  deadzone_radius: 0.400000154972\r\n",
      "}\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!cat $SPECS_DIR/detectnet_v2_train_resnet18_kitti.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run TLT training <a class=\"anchor\" id=\"head-3\"></a>\n",
    "* Provide the sample spec file and the output directory location for models\n",
    "\n",
    "*Note: The training may take hours to complete. Also, the remaining notebook, assumes that the training was done in single-GPU mode. When run in multi-GPU mode, please expect to update the pruning and inference steps with new pruning thresholds and updated parameters in the clusterfile.json accordingly for optimum performance.*\n",
    "\n",
    "*Detectnet_v2 now supports restart from checkpoint. Incase, the training job is killed prematurely, you may resume training from the closest checkpoint by simply re-running the same command line. Please do make sure to use the same number of GPUs when restarting the training.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "2021-06-20 06:45:59.904556: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-06-20 06:46:01.914699: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-06-20 06:46:01.944404: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 06:46:01.944796: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce RTX 2060 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.68\n",
      "pciBusID: 0000:06:00.0\n",
      "2021-06-20 06:46:01.944814: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-06-20 06:46:01.944845: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2021-06-20 06:46:01.945728: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2021-06-20 06:46:01.945930: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2021-06-20 06:46:01.946846: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2021-06-20 06:46:01.947560: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2021-06-20 06:46:01.947597: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-06-20 06:46:01.947736: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 06:46:01.948167: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 06:46:01.948511: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
      "2021-06-20 06:46:01.948532: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-06-20 06:46:02.589190: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-06-20 06:46:02.589237: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
      "2021-06-20 06:46:02.589245: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
      "2021-06-20 06:46:02.589486: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 06:46:02.589877: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 06:46:02.590240: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 06:46:02.590569: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6277 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:06:00.0, compute capability: 7.5)\n",
      "2021-06-20 06:46:02,591 [INFO] iva.detectnet_v2.scripts.train: Loading experiment spec at helmet/detectnet_v2/tlt_specs/detectnet_v2_train_resnet18_kitti.txt.\n",
      "2021-06-20 06:46:02,592 [INFO] iva.detectnet_v2.spec_handler.spec_loader: Merging specification from helmet/detectnet_v2/tlt_specs/detectnet_v2_train_resnet18_kitti.txt\n",
      "2021-06-20 06:46:02,799 [INFO] iva.detectnet_v2.scripts.train: Cannot iterate over exactly 988 samples with a batch size of 14; each epoch will therefore take one extra step.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 3, 544, 960)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 64, 272, 480) 9472        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 64, 272, 480) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 64, 272, 480) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_conv_1 (Conv2D)        (None, 64, 136, 240) 36928       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_1 (BatchNormalizati (None, 64, 136, 240) 256         block_1a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_relu_1 (Activation)    (None, 64, 136, 240) 0           block_1a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_conv_2 (Conv2D)        (None, 64, 136, 240) 36928       block_1a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_conv_shortcut (Conv2D) (None, 64, 136, 240) 4160        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_2 (BatchNormalizati (None, 64, 136, 240) 256         block_1a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_shortcut (BatchNorm (None, 64, 136, 240) 256         block_1a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 64, 136, 240) 0           block_1a_bn_2[0][0]              \n",
      "                                                                 block_1a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_relu (Activation)      (None, 64, 136, 240) 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_conv_1 (Conv2D)        (None, 64, 136, 240) 36928       block_1a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_bn_1 (BatchNormalizati (None, 64, 136, 240) 256         block_1b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_relu_1 (Activation)    (None, 64, 136, 240) 0           block_1b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_conv_2 (Conv2D)        (None, 64, 136, 240) 36928       block_1b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_bn_2 (BatchNormalizati (None, 64, 136, 240) 256         block_1b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 64, 136, 240) 0           block_1b_bn_2[0][0]              \n",
      "                                                                 block_1a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_relu (Activation)      (None, 64, 136, 240) 0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_conv_1 (Conv2D)        (None, 128, 68, 120) 73856       block_1b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_1 (BatchNormalizati (None, 128, 68, 120) 512         block_2a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_relu_1 (Activation)    (None, 128, 68, 120) 0           block_2a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_conv_2 (Conv2D)        (None, 128, 68, 120) 147584      block_2a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_conv_shortcut (Conv2D) (None, 128, 68, 120) 8320        block_1b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_2 (BatchNormalizati (None, 128, 68, 120) 512         block_2a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_shortcut (BatchNorm (None, 128, 68, 120) 512         block_2a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 128, 68, 120) 0           block_2a_bn_2[0][0]              \n",
      "                                                                 block_2a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_relu (Activation)      (None, 128, 68, 120) 0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_conv_1 (Conv2D)        (None, 128, 68, 120) 147584      block_2a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_bn_1 (BatchNormalizati (None, 128, 68, 120) 512         block_2b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_relu_1 (Activation)    (None, 128, 68, 120) 0           block_2b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_conv_2 (Conv2D)        (None, 128, 68, 120) 147584      block_2b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_bn_2 (BatchNormalizati (None, 128, 68, 120) 512         block_2b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 128, 68, 120) 0           block_2b_bn_2[0][0]              \n",
      "                                                                 block_2a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_relu (Activation)      (None, 128, 68, 120) 0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_conv_1 (Conv2D)        (None, 256, 34, 60)  295168      block_2b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_1 (BatchNormalizati (None, 256, 34, 60)  1024        block_3a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_relu_1 (Activation)    (None, 256, 34, 60)  0           block_3a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_conv_2 (Conv2D)        (None, 256, 34, 60)  590080      block_3a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_conv_shortcut (Conv2D) (None, 256, 34, 60)  33024       block_2b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_2 (BatchNormalizati (None, 256, 34, 60)  1024        block_3a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_shortcut (BatchNorm (None, 256, 34, 60)  1024        block_3a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 256, 34, 60)  0           block_3a_bn_2[0][0]              \n",
      "                                                                 block_3a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_relu (Activation)      (None, 256, 34, 60)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_conv_1 (Conv2D)        (None, 256, 34, 60)  590080      block_3a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_bn_1 (BatchNormalizati (None, 256, 34, 60)  1024        block_3b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_relu_1 (Activation)    (None, 256, 34, 60)  0           block_3b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_conv_2 (Conv2D)        (None, 256, 34, 60)  590080      block_3b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_bn_2 (BatchNormalizati (None, 256, 34, 60)  1024        block_3b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 256, 34, 60)  0           block_3b_bn_2[0][0]              \n",
      "                                                                 block_3a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_relu (Activation)      (None, 256, 34, 60)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_conv_1 (Conv2D)        (None, 512, 34, 60)  1180160     block_3b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_bn_1 (BatchNormalizati (None, 512, 34, 60)  2048        block_4a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_relu_1 (Activation)    (None, 512, 34, 60)  0           block_4a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_conv_2 (Conv2D)        (None, 512, 34, 60)  2359808     block_4a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_conv_shortcut (Conv2D) (None, 512, 34, 60)  131584      block_3b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_bn_2 (BatchNormalizati (None, 512, 34, 60)  2048        block_4a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_bn_shortcut (BatchNorm (None, 512, 34, 60)  2048        block_4a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 512, 34, 60)  0           block_4a_bn_2[0][0]              \n",
      "                                                                 block_4a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_relu (Activation)      (None, 512, 34, 60)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_conv_1 (Conv2D)        (None, 512, 34, 60)  2359808     block_4a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_bn_1 (BatchNormalizati (None, 512, 34, 60)  2048        block_4b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_relu_1 (Activation)    (None, 512, 34, 60)  0           block_4b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_conv_2 (Conv2D)        (None, 512, 34, 60)  2359808     block_4b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_bn_2 (BatchNormalizati (None, 512, 34, 60)  2048        block_4b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 512, 34, 60)  0           block_4b_bn_2[0][0]              \n",
      "                                                                 block_4a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_relu (Activation)      (None, 512, 34, 60)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "output_bbox (Conv2D)            (None, 12, 34, 60)   6156        block_4b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "output_cov (Conv2D)             (None, 3, 34, 60)    1539        block_4b_relu[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 11,203,023\n",
      "Trainable params: 11,193,295\n",
      "Non-trainable params: 9,728\n",
      "__________________________________________________________________________________________________\n",
      "2021-06-20 06:46:08,897 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: Serial augmentation enabled = False\n",
      "2021-06-20 06:46:08,897 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: Pseudo sharding enabled = False\n",
      "2021-06-20 06:46:08,897 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: Max Image Dimensions (all sources): (0, 0)\n",
      "2021-06-20 06:46:08,897 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: number of cpus: 16, io threads: 32, compute threads: 16, buffered batches: 4\n",
      "2021-06-20 06:46:08,897 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: total dataset size 988, number of sources: 1, batch size per gpu: 14, steps: 71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-20 06:46:08,982 [INFO] iva.detectnet_v2.dataloader.default_dataloader: Bounding box coordinates were detected in the input specification! Bboxes will be automatically converted to polygon coordinates.\n",
      "2021-06-20 06:46:09.005344: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 06:46:09.005728: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce RTX 2060 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.68\n",
      "pciBusID: 0000:06:00.0\n",
      "2021-06-20 06:46:09.005749: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-06-20 06:46:09.005774: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2021-06-20 06:46:09.005793: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2021-06-20 06:46:09.005807: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2021-06-20 06:46:09.005820: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2021-06-20 06:46:09.005833: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2021-06-20 06:46:09.005846: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-06-20 06:46:09.005913: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 06:46:09.006268: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 06:46:09.006567: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
      "2021-06-20 06:46:09,163 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: shuffle: True - shard 0 of 1\n",
      "2021-06-20 06:46:09,169 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: sampling 1 datasets with weights:\n",
      "2021-06-20 06:46:09,169 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: source: 0 weight: 1.000000\n",
      "2021-06-20 06:46:09,540 [INFO] iva.detectnet_v2.scripts.train: Found 988 samples in training set\n",
      "2021-06-20 06:46:11,302 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: Serial augmentation enabled = False\n",
      "2021-06-20 06:46:11,303 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: Pseudo sharding enabled = False\n",
      "2021-06-20 06:46:11,303 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: Max Image Dimensions (all sources): (0, 0)\n",
      "2021-06-20 06:46:11,303 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: number of cpus: 16, io threads: 32, compute threads: 16, buffered batches: 4\n",
      "2021-06-20 06:46:11,303 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: total dataset size 247, number of sources: 1, batch size per gpu: 14, steps: 18\n",
      "2021-06-20 06:46:11,325 [INFO] iva.detectnet_v2.dataloader.default_dataloader: Bounding box coordinates were detected in the input specification! Bboxes will be automatically converted to polygon coordinates.\n",
      "2021-06-20 06:46:11,497 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: shuffle: False - shard 0 of 1\n",
      "2021-06-20 06:46:11,501 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: sampling 1 datasets with weights:\n",
      "2021-06-20 06:46:11,501 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: source: 0 weight: 1.000000\n",
      "2021-06-20 06:46:11,738 [INFO] iva.detectnet_v2.scripts.train: Found 247 samples in validation set\n",
      "2021-06-20 06:46:16.599971: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 06:46:16.600353: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce RTX 2060 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.68\n",
      "pciBusID: 0000:06:00.0\n",
      "2021-06-20 06:46:16.600381: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-06-20 06:46:16.600416: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2021-06-20 06:46:16.600451: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2021-06-20 06:46:16.600467: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2021-06-20 06:46:16.600480: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2021-06-20 06:46:16.600492: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2021-06-20 06:46:16.600503: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-06-20 06:46:16.600567: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 06:46:16.600919: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 06:46:16.601215: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
      "2021-06-20 06:46:16.904299: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-06-20 06:46:16.904331: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
      "2021-06-20 06:46:16.904338: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
      "2021-06-20 06:46:16.904612: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 06:46:16.905014: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 06:46:16.905332: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6277 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:06:00.0, compute capability: 7.5)\n",
      "2021-06-20 06:46:39.198618: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2021-06-20 06:46:39.691527: I tensorflow/core/kernels/cuda_solvers.cc:159] Creating CudaSolver handles for stream 0x7cc23c0\n",
      "2021-06-20 06:46:39.691658: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2021-06-20 06:46:39.847387: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2021-06-20 06:46:39.851027: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-06-20 06:46:41.109548: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.47GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-06-20 06:46:41.109593: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.47GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-20 06:46:41.309419: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-06-20 06:46:41.309473: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-06-20 06:46:41.455023: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.19GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-06-20 06:46:41.455066: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.19GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-06-20 06:46:42.127085: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.19GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-06-20 06:46:42.127129: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.19GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-06-20 06:46:42.745382: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.19GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-06-20 06:46:42.745427: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.19GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-06-20 06:46:43,998 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 0/200: loss: 0.05413 Time taken: 0:00:00 ETA: 0:00:00\n",
      "2021-06-20 06:46:43,998 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 2.291\n",
      "2021-06-20 06:46:57,970 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 17.426\n",
      "2021-06-20 06:47:08,202 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 34.210\n",
      "2021-06-20 06:47:17,443 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 1/200: loss: 0.00127 Time taken: 0:00:39.140275 ETA: 2:09:48.914725\n",
      "2021-06-20 06:47:18,681 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.399\n",
      "2021-06-20 06:47:28,997 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.931\n",
      "2021-06-20 06:47:39,314 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.924\n",
      "2021-06-20 06:47:46,794 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 2/200: loss: 0.00124 Time taken: 0:00:29.346469 ETA: 1:36:50.600847\n",
      "2021-06-20 06:47:49,682 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.758\n",
      "2021-06-20 06:48:00,090 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.628\n",
      "2021-06-20 06:48:10,426 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.866\n",
      "2021-06-20 06:48:16,256 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 3/200: loss: 0.00140 Time taken: 0:00:29.470096 ETA: 1:36:45.608981\n",
      "2021-06-20 06:48:20,858 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.549\n",
      "2021-06-20 06:48:31,435 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.094\n",
      "2021-06-20 06:48:41,864 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.562\n",
      "2021-06-20 06:48:46,106 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 4/200: loss: 0.00145 Time taken: 0:00:29.846092 ETA: 1:37:29.833982\n",
      "2021-06-20 06:48:52,377 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.292\n",
      "2021-06-20 06:49:02,912 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.222\n",
      "2021-06-20 06:49:13,384 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.423\n",
      "2021-06-20 06:49:15,933 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 5/200: loss: 0.00123 Time taken: 0:00:29.823717 ETA: 1:36:55.624745\n",
      "2021-06-20 06:49:23,906 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.267\n",
      "2021-06-20 06:49:34,461 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.159\n",
      "2021-06-20 06:49:44,990 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.244\n",
      "2021-06-20 06:49:45,841 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 6/200: loss: 0.00148 Time taken: 0:00:29.907351 ETA: 1:36:42.026005\n",
      "2021-06-20 06:49:55,486 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.347\n",
      "2021-06-20 06:50:05,989 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.323\n",
      "2021-06-20 06:50:15,640 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 7/200: loss: 0.00116 Time taken: 0:00:29.794787 ETA: 1:35:50.393924\n",
      "2021-06-20 06:50:16,474 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.384\n",
      "2021-06-20 06:50:27,098 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 32.944\n",
      "2021-06-20 06:50:37,600 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.328\n",
      "2021-06-20 06:50:45,614 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 8/200: loss: 0.00100 Time taken: 0:00:29.962752 ETA: 1:35:52.848358\n",
      "2021-06-20 06:50:48,126 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.253\n",
      "2021-06-20 06:50:58,650 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.257\n",
      "2021-06-20 06:51:09,144 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.353\n",
      "2021-06-20 06:51:15,499 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 9/200: loss: 0.00095 Time taken: 0:00:29.893665 ETA: 1:35:09.690075\n",
      "2021-06-20 06:51:19,690 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.190\n",
      "2021-06-20 06:51:30,221 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.237\n",
      "2021-06-20 06:51:40,717 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.346\n",
      "2021-06-20 06:51:44,944 [INFO] iva.detectnet_v2.evaluation.evaluation: step 0 / 17, 0.00s/step\n",
      "2021-06-20 06:52:38,390 [INFO] iva.detectnet_v2.evaluation.evaluation: step 10 / 17, 5.34s/step\n",
      "Matching predictions to ground truth, class 1/3.: 100%|| 76879/76879 [00:02<00:00, 33985.40it/s]\n",
      "Matching predictions to ground truth, class 2/3.: 100%|| 173259/173259 [00:05<00:00, 32327.09it/s]\n",
      "Matching predictions to ground truth, class 3/3.: 100%|| 12915/12915 [00:00<00:00, 27835.47it/s]\n",
      "Epoch 10/200\n",
      "=========================\n",
      "\n",
      "Validation cost: 0.000595\n",
      "Mean average_precision (in %): 0.2240\n",
      "\n",
      "class name               average precision (in %)\n",
      "---------------------  --------------------------\n",
      "helmet                                  0.0466877\n",
      "person_with_helmet                      0.287143\n",
      "person_without_helmet                   0.338082\n",
      "\n",
      "Median Inference Time: 0.010786\n",
      "2021-06-20 06:53:28,015 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 10/200: loss: 0.00092 Time taken: 0:02:12.488552 ETA: 6:59:32.824852\n",
      "2021-06-20 06:53:33,771 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 3.096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-20 06:53:44,117 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.830\n",
      "2021-06-20 06:53:54,403 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 34.027\n",
      "2021-06-20 06:53:57,351 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 11/200: loss: 0.00104 Time taken: 0:00:29.350635 ETA: 1:32:27.270070\n",
      "2021-06-20 06:54:04,834 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.557\n",
      "2021-06-20 06:54:15,271 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.536\n",
      "2021-06-20 06:54:25,781 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.301\n",
      "2021-06-20 06:54:27,045 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 12/200: loss: 0.00092 Time taken: 0:00:29.697202 ETA: 1:33:03.073970\n",
      "2021-06-20 06:54:36,377 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.032\n",
      "2021-06-20 06:54:47,295 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 32.059\n",
      "2021-06-20 06:54:57,863 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 13/200: loss: 0.00089 Time taken: 0:00:30.779002 ETA: 1:35:55.673454\n",
      "2021-06-20 06:54:58,316 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 31.760\n",
      "2021-06-20 06:55:09,379 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 31.638\n",
      "2021-06-20 06:55:20,324 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 31.977\n",
      "2021-06-20 06:55:29,039 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 14/200: loss: 0.00094 Time taken: 0:00:31.165563 ETA: 1:36:36.794693\n",
      "2021-06-20 06:55:31,271 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 31.974\n",
      "2021-06-20 06:55:42,000 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 32.622\n",
      "2021-06-20 06:55:52,523 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.264\n",
      "2021-06-20 06:55:59,205 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 15/200: loss: 0.00107 Time taken: 0:00:30.209074 ETA: 1:33:08.678694\n",
      "2021-06-20 06:56:02,970 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.502\n",
      "2021-06-20 06:56:13,463 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.357\n",
      "2021-06-20 06:56:23,946 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.389\n",
      "2021-06-20 06:56:29,058 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 16/200: loss: 0.00082 Time taken: 0:00:29.851607 ETA: 1:31:32.695747\n",
      "2021-06-20 06:56:34,591 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 32.880\n",
      "2021-06-20 06:56:45,153 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.139\n",
      "2021-06-20 06:56:55,699 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.188\n",
      "2021-06-20 06:56:59,127 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 17/200: loss: 0.00090 Time taken: 0:00:30.064149 ETA: 1:31:41.739293\n",
      "2021-06-20 06:57:06,356 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 32.843\n",
      "2021-06-20 06:57:17,093 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 32.600\n",
      "2021-06-20 06:57:27,794 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 32.708\n",
      "2021-06-20 06:57:29,484 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 18/200: loss: 0.00080 Time taken: 0:00:30.359751 ETA: 1:32:05.474723\n",
      "2021-06-20 06:57:38,320 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.253\n",
      "2021-06-20 06:57:48,826 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.315\n",
      "2021-06-20 06:57:59,483 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 19/200: loss: 0.00086 Time taken: 0:00:29.996652 ETA: 1:30:29.393949\n",
      "2021-06-20 06:57:59,483 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 32.844\n",
      "2021-06-20 06:58:10,110 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 32.934\n",
      "2021-06-20 06:58:20,647 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.218\n",
      "2021-06-20 06:58:29,096 [INFO] iva.detectnet_v2.evaluation.evaluation: step 0 / 17, 0.00s/step\n",
      "2021-06-20 06:59:14,496 [INFO] iva.detectnet_v2.evaluation.evaluation: step 10 / 17, 4.54s/step\n",
      "Matching predictions to ground truth, class 1/3.: 100%|| 75708/75708 [00:02<00:00, 35085.48it/s]\n",
      "Matching predictions to ground truth, class 2/3.: 100%|| 333090/333090 [00:11<00:00, 30139.33it/s]\n",
      "Matching predictions to ground truth, class 3/3.: 100%|| 2809/2809 [00:00<00:00, 21018.66it/s]\n",
      "Epoch 20/200\n",
      "=========================\n",
      "\n",
      "Validation cost: 0.000347\n",
      "Mean average_precision (in %): 3.5178\n",
      "\n",
      "class name               average precision (in %)\n",
      "---------------------  --------------------------\n",
      "helmet                                   0.136772\n",
      "person_with_helmet                       2.19415\n",
      "person_without_helmet                    8.22239\n",
      "\n",
      "Median Inference Time: 0.010738\n",
      "2021-06-20 07:00:06,137 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 20/200: loss: 0.00086 Time taken: 0:02:06.590604 ETA: 6:19:46.308646\n",
      "2021-06-20 07:00:07,852 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 3.265\n",
      "2021-06-20 07:00:18,317 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.447\n",
      "2021-06-20 07:00:28,660 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.839\n",
      "2021-06-20 07:00:35,721 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 21/200: loss: 0.00099 Time taken: 0:00:29.632789 ETA: 1:28:24.269212\n",
      "2021-06-20 07:00:39,028 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.761\n",
      "2021-06-20 07:00:49,470 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.520\n",
      "2021-06-20 07:00:59,921 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.491\n",
      "2021-06-20 07:01:05,373 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 22/200: loss: 0.00091 Time taken: 0:00:29.649750 ETA: 1:27:57.655414\n",
      "2021-06-20 07:01:10,385 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.449\n",
      "2021-06-20 07:01:20,815 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.557\n",
      "2021-06-20 07:01:31,286 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.427\n",
      "2021-06-20 07:01:35,082 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 23/200: loss: 0.00089 Time taken: 0:00:29.706596 ETA: 1:27:38.067432\n",
      "2021-06-20 07:01:41,745 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.464\n",
      "2021-06-20 07:01:52,271 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.252\n",
      "2021-06-20 07:02:02,707 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.540\n",
      "2021-06-20 07:02:04,792 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 24/200: loss: 0.00086 Time taken: 0:00:29.709290 ETA: 1:27:08.835003\n",
      "2021-06-20 07:02:13,201 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.351\n",
      "2021-06-20 07:02:23,748 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.188\n",
      "2021-06-20 07:02:34,381 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 32.916\n",
      "2021-06-20 07:02:34,808 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 25/200: loss: 0.00094 Time taken: 0:00:30.003022 ETA: 1:27:30.528800\n",
      "2021-06-20 07:02:44,854 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.422\n",
      "2021-06-20 07:02:55,369 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.287\n",
      "2021-06-20 07:03:04,620 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 26/200: loss: 0.00069 Time taken: 0:00:29.800628 ETA: 1:26:25.309263\n",
      "2021-06-20 07:03:05,875 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.314\n",
      "2021-06-20 07:03:16,399 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-20 07:03:26,915 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.282\n",
      "2021-06-20 07:03:34,490 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 27/200: loss: 0.00068 Time taken: 0:00:29.885461 ETA: 1:26:10.184728\n",
      "2021-06-20 07:03:37,428 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.293\n",
      "2021-06-20 07:03:47,921 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.357\n",
      "2021-06-20 07:03:58,733 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 32.374\n",
      "2021-06-20 07:04:04,615 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 28/200: loss: 0.00074 Time taken: 0:00:30.110404 ETA: 1:26:18.989532\n",
      "2021-06-20 07:04:09,226 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.355\n",
      "2021-06-20 07:04:19,742 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.284\n",
      "2021-06-20 07:04:30,218 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.411\n",
      "2021-06-20 07:04:34,403 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 29/200: loss: 0.00086 Time taken: 0:00:29.806875 ETA: 1:24:56.975542\n",
      "2021-06-20 07:04:40,755 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.216\n",
      "2021-06-20 07:04:51,261 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.318\n",
      "2021-06-20 07:05:01,787 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.249\n",
      "2021-06-20 07:05:09,691 [INFO] iva.detectnet_v2.evaluation.evaluation: step 0 / 17, 0.00s/step\n",
      "2021-06-20 07:05:46,012 [INFO] iva.detectnet_v2.evaluation.evaluation: step 10 / 17, 3.63s/step\n",
      "Matching predictions to ground truth, class 1/3.: 100%|| 23838/23838 [00:00<00:00, 43311.05it/s]\n",
      "Matching predictions to ground truth, class 2/3.: 100%|| 135698/135698 [00:04<00:00, 31924.13it/s]\n",
      "Matching predictions to ground truth, class 3/3.: 100%|| 3200/3200 [00:00<00:00, 20960.84it/s]\n",
      "Epoch 30/200\n",
      "=========================\n",
      "\n",
      "Validation cost: 0.000272\n",
      "Mean average_precision (in %): 14.6407\n",
      "\n",
      "class name               average precision (in %)\n",
      "---------------------  --------------------------\n",
      "helmet                                   0.498689\n",
      "person_with_helmet                      11.3124\n",
      "person_without_helmet                   32.111\n",
      "\n",
      "Median Inference Time: 0.010833\n",
      "2021-06-20 07:06:19,034 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 30/200: loss: 0.00110 Time taken: 0:01:44.626281 ETA: 4:56:26.467814\n",
      "2021-06-20 07:06:26,862 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 4.114\n",
      "2021-06-20 07:06:37,188 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.896\n",
      "2021-06-20 07:06:47,608 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.591\n",
      "2021-06-20 07:06:48,440 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 31/200: loss: 0.00082 Time taken: 0:00:29.413098 ETA: 1:22:50.813619\n",
      "2021-06-20 07:06:58,157 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.179\n",
      "2021-06-20 07:07:08,638 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.396\n",
      "2021-06-20 07:07:18,213 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 32/200: loss: 0.00091 Time taken: 0:00:29.769489 ETA: 1:23:21.274200\n",
      "2021-06-20 07:07:19,050 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.615\n",
      "2021-06-20 07:07:29,534 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.383\n",
      "2021-06-20 07:07:40,019 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.383\n",
      "2021-06-20 07:07:47,941 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 33/200: loss: 0.00072 Time taken: 0:00:29.719996 ETA: 1:22:43.239368\n",
      "2021-06-20 07:07:50,444 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.577\n",
      "2021-06-20 07:08:00,872 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.562\n",
      "2021-06-20 07:08:11,326 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.483\n",
      "2021-06-20 07:08:17,604 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 34/200: loss: 0.00085 Time taken: 0:00:29.668148 ETA: 1:22:04.912496\n",
      "2021-06-20 07:08:21,782 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.475\n",
      "2021-06-20 07:08:32,322 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.208\n",
      "2021-06-20 07:08:42,799 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.406\n",
      "2021-06-20 07:08:47,424 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 35/200: loss: 0.00078 Time taken: 0:00:29.807719 ETA: 1:21:58.273555\n",
      "2021-06-20 07:08:53,298 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.337\n",
      "2021-06-20 07:09:03,789 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.362\n",
      "2021-06-20 07:09:14,280 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.363\n",
      "2021-06-20 07:09:17,222 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 36/200: loss: 0.00073 Time taken: 0:00:29.801044 ETA: 1:21:27.371214\n",
      "2021-06-20 07:09:24,758 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.407\n",
      "2021-06-20 07:09:35,495 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 32.597\n",
      "2021-06-20 07:09:46,153 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 32.840\n",
      "2021-06-20 07:09:47,416 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 37/200: loss: 0.00069 Time taken: 0:00:30.198299 ETA: 1:22:02.322765\n",
      "2021-06-20 07:09:56,690 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.218\n",
      "2021-06-20 07:10:07,250 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.146\n",
      "2021-06-20 07:10:17,285 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 38/200: loss: 0.00077 Time taken: 0:00:29.871538 ETA: 1:20:39.189221\n",
      "2021-06-20 07:10:17,713 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.451\n",
      "2021-06-20 07:10:28,265 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.169\n",
      "2021-06-20 07:10:38,921 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 32.848\n",
      "2021-06-20 07:10:47,418 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 39/200: loss: 0.00086 Time taken: 0:00:30.111702 ETA: 1:20:47.984093\n",
      "2021-06-20 07:10:49,525 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.006\n",
      "2021-06-20 07:11:00,105 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.085\n",
      "2021-06-20 07:11:10,775 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 32.802\n",
      "2021-06-20 07:11:17,099 [INFO] iva.detectnet_v2.evaluation.evaluation: step 0 / 17, 0.00s/step\n",
      "2021-06-20 07:11:35,568 [INFO] iva.detectnet_v2.evaluation.evaluation: step 10 / 17, 1.85s/step\n",
      "Matching predictions to ground truth, class 1/3.: 100%|| 4200/4200 [00:00<00:00, 50958.44it/s]\n",
      "Matching predictions to ground truth, class 2/3.: 100%|| 24733/24733 [00:00<00:00, 35523.21it/s]\n",
      "Matching predictions to ground truth, class 3/3.: 100%|| 1239/1239 [00:00<00:00, 21265.18it/s]\n",
      "Epoch 40/200\n",
      "=========================\n",
      "\n",
      "Validation cost: 0.000247\n",
      "Mean average_precision (in %): 20.9277\n",
      "\n",
      "class name               average precision (in %)\n",
      "---------------------  --------------------------\n",
      "helmet                                    5.40631\n",
      "person_with_helmet                       18.8334\n",
      "person_without_helmet                    38.5433\n",
      "\n",
      "Median Inference Time: 0.010508\n",
      "2021-06-20 07:11:50,028 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 40/200: loss: 0.00072 Time taken: 0:01:02.613420 ETA: 2:46:58.147125\n",
      "2021-06-20 07:11:53,869 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 8.122\n",
      "2021-06-20 07:12:04,372 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.323\n",
      "2021-06-20 07:12:14,950 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-20 07:12:19,972 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 41/200: loss: 0.00081 Time taken: 0:00:29.956698 ETA: 1:19:23.115010\n",
      "2021-06-20 07:12:25,516 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.127\n",
      "2021-06-20 07:12:36,027 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.299\n",
      "2021-06-20 07:12:46,608 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.079\n",
      "2021-06-20 07:12:50,005 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 42/200: loss: 0.00073 Time taken: 0:00:30.018724 ETA: 1:19:02.958424\n",
      "2021-06-20 07:12:57,193 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.065\n",
      "2021-06-20 07:13:07,702 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.307\n",
      "2021-06-20 07:13:18,179 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.408\n",
      "2021-06-20 07:13:19,860 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 43/200: loss: 0.00073 Time taken: 0:00:29.868972 ETA: 1:18:09.428651\n",
      "2021-06-20 07:13:28,726 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.184\n",
      "2021-06-20 07:13:39,278 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.172\n",
      "2021-06-20 07:13:49,900 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 44/200: loss: 0.00078 Time taken: 0:00:30.022157 ETA: 1:18:03.456559\n",
      "2021-06-20 07:13:49,900 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 32.950\n",
      "2021-06-20 07:14:00,805 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 32.097\n",
      "2021-06-20 07:14:11,919 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 31.492\n",
      "2021-06-20 07:14:21,296 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 45/200: loss: 0.00073 Time taken: 0:00:31.378180 ETA: 1:21:03.617941\n",
      "2021-06-20 07:14:23,082 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 31.354\n",
      "2021-06-20 07:14:34,118 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 31.716\n",
      "2021-06-20 07:14:45,242 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 31.464\n",
      "2021-06-20 07:14:52,795 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 46/200: loss: 0.00072 Time taken: 0:00:31.488589 ETA: 1:20:49.242750\n",
      "2021-06-20 07:14:56,398 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 31.374\n",
      "2021-06-20 07:15:07,489 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 31.558\n",
      "2021-06-20 07:15:18,609 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 31.476\n",
      "2021-06-20 07:15:24,380 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 47/200: loss: 0.00069 Time taken: 0:00:31.604723 ETA: 1:20:35.522579\n",
      "2021-06-20 07:15:29,688 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 31.593\n",
      "2021-06-20 07:15:40,718 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 31.731\n",
      "2021-06-20 07:15:51,309 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.051\n",
      "2021-06-20 07:15:55,105 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 48/200: loss: 0.00080 Time taken: 0:00:30.746683 ETA: 1:17:53.495762\n",
      "2021-06-20 07:16:01,850 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.203\n",
      "2021-06-20 07:16:12,426 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.095\n",
      "2021-06-20 07:16:23,128 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 32.707\n",
      "2021-06-20 07:16:25,297 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 49/200: loss: 0.00065 Time taken: 0:00:30.175056 ETA: 1:15:56.433417\n",
      "2021-06-20 07:16:33,841 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 32.670\n",
      "2021-06-20 07:16:44,399 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.151\n",
      "2021-06-20 07:16:54,954 [INFO] iva.detectnet_v2.evaluation.evaluation: step 0 / 17, 0.00s/step\n",
      "2021-06-20 07:17:10,316 [INFO] iva.detectnet_v2.evaluation.evaluation: step 10 / 17, 1.54s/step\n",
      "Matching predictions to ground truth, class 1/3.: 100%|| 5453/5453 [00:00<00:00, 44933.91it/s]\n",
      "Matching predictions to ground truth, class 2/3.: 100%|| 14439/14439 [00:00<00:00, 34888.30it/s]\n",
      "Matching predictions to ground truth, class 3/3.: 100%|| 2811/2811 [00:00<00:00, 24978.58it/s]\n",
      "Epoch 50/200\n",
      "=========================\n",
      "\n",
      "Validation cost: 0.000244\n",
      "Mean average_precision (in %): 27.4791\n",
      "\n",
      "class name               average precision (in %)\n",
      "---------------------  --------------------------\n",
      "helmet                                    16.0634\n",
      "person_with_helmet                        22.3852\n",
      "person_without_helmet                     43.9887\n",
      "\n",
      "Median Inference Time: 0.010236\n",
      "2021-06-20 07:17:22,072 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 9.291\n",
      "2021-06-20 07:17:22,501 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 50/200: loss: 0.00069 Time taken: 0:00:57.204434 ETA: 2:23:00.665088\n",
      "2021-06-20 07:17:32,489 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.601\n",
      "2021-06-20 07:17:42,997 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.310\n",
      "2021-06-20 07:17:52,318 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 51/200: loss: 0.00071 Time taken: 0:00:29.814691 ETA: 1:14:02.388898\n",
      "2021-06-20 07:17:53,569 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.108\n",
      "2021-06-20 07:18:04,126 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.153\n",
      "2021-06-20 07:18:14,686 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.144\n",
      "2021-06-20 07:18:22,257 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 52/200: loss: 0.00067 Time taken: 0:00:29.954606 ETA: 1:13:53.281696\n",
      "2021-06-20 07:18:25,216 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.241\n",
      "2021-06-20 07:18:35,708 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.359\n",
      "2021-06-20 07:18:46,214 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.314\n",
      "2021-06-20 07:18:52,157 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 53/200: loss: 0.00073 Time taken: 0:00:29.885272 ETA: 1:13:13.135023\n",
      "2021-06-20 07:18:56,793 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.086\n",
      "2021-06-20 07:19:07,850 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 31.655\n",
      "2021-06-20 07:19:18,574 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 32.638\n",
      "2021-06-20 07:19:22,801 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 54/200: loss: 0.00069 Time taken: 0:00:30.641284 ETA: 1:14:33.627393\n",
      "2021-06-20 07:19:29,072 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.342\n",
      "2021-06-20 07:19:39,585 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.293\n",
      "2021-06-20 07:19:50,085 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.335\n",
      "2021-06-20 07:19:52,766 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 55/200: loss: 0.00072 Time taken: 0:00:29.977978 ETA: 1:12:26.806878\n",
      "2021-06-20 07:20:00,774 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 32.744\n",
      "2021-06-20 07:20:11,303 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.244\n",
      "2021-06-20 07:20:21,826 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.260\n",
      "2021-06-20 07:20:22,710 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 56/200: loss: 0.00071 Time taken: 0:00:29.930079 ETA: 1:11:49.931408\n",
      "2021-06-20 07:20:32,325 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.338\n",
      "2021-06-20 07:20:42,982 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 32.843\n",
      "2021-06-20 07:20:52,628 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 57/200: loss: 0.00076 Time taken: 0:00:29.930151 ETA: 1:11:20.011523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-20 07:20:53,493 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.298\n",
      "2021-06-20 07:21:04,051 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.152\n",
      "2021-06-20 07:21:14,542 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.364\n",
      "2021-06-20 07:21:22,479 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 58/200: loss: 0.00065 Time taken: 0:00:29.851150 ETA: 1:10:38.863271\n",
      "2021-06-20 07:21:25,017 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.412\n",
      "2021-06-20 07:21:35,489 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.423\n",
      "2021-06-20 07:21:45,991 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.329\n",
      "2021-06-20 07:21:52,316 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 59/200: loss: 0.00066 Time taken: 0:00:29.822719 ETA: 1:10:05.003426\n",
      "2021-06-20 07:21:56,536 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.192\n",
      "2021-06-20 07:22:07,000 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.448\n",
      "2021-06-20 07:22:17,547 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.187\n",
      "2021-06-20 07:22:27,622 [INFO] iva.detectnet_v2.evaluation.evaluation: step 0 / 17, 0.00s/step\n",
      "2021-06-20 07:22:30,665 [INFO] iva.detectnet_v2.evaluation.evaluation: step 10 / 17, 0.30s/step\n",
      "Matching predictions to ground truth, class 1/3.: 100%|| 1969/1969 [00:00<00:00, 54238.23it/s]\n",
      "Matching predictions to ground truth, class 2/3.: 100%|| 8387/8387 [00:00<00:00, 34801.77it/s]\n",
      "Matching predictions to ground truth, class 3/3.: 100%|| 961/961 [00:00<00:00, 22070.57it/s]\n",
      "Epoch 60/200\n",
      "=========================\n",
      "\n",
      "Validation cost: 0.000234\n",
      "Mean average_precision (in %): 30.8346\n",
      "\n",
      "class name               average precision (in %)\n",
      "---------------------  --------------------------\n",
      "helmet                                    25.581\n",
      "person_with_helmet                        25.415\n",
      "person_without_helmet                     41.5079\n",
      "\n",
      "Median Inference Time: 0.010102\n",
      "2021-06-20 07:22:33,727 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 60/200: loss: 0.00068 Time taken: 0:00:41.383602 ETA: 1:36:33.704267\n",
      "2021-06-20 07:22:39,580 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 15.885\n",
      "2021-06-20 07:22:50,112 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.232\n",
      "2021-06-20 07:23:00,689 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.092\n",
      "2021-06-20 07:23:03,649 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 61/200: loss: 0.00064 Time taken: 0:00:29.947597 ETA: 1:09:22.715954\n",
      "2021-06-20 07:23:11,231 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.202\n",
      "2021-06-20 07:23:21,726 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.350\n",
      "2021-06-20 07:23:32,229 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.326\n",
      "2021-06-20 07:23:33,490 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 62/200: loss: 0.00065 Time taken: 0:00:29.851180 ETA: 1:08:39.462883\n",
      "2021-06-20 07:23:42,730 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.332\n",
      "2021-06-20 07:23:53,248 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.275\n",
      "2021-06-20 07:24:03,370 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 63/200: loss: 0.00078 Time taken: 0:00:29.876721 ETA: 1:08:13.110731\n",
      "2021-06-20 07:24:03,791 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.199\n",
      "2021-06-20 07:24:14,372 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.079\n",
      "2021-06-20 07:24:24,866 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.352\n",
      "2021-06-20 07:24:33,318 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 64/200: loss: 0.00073 Time taken: 0:00:29.940107 ETA: 1:07:51.854567\n",
      "2021-06-20 07:24:35,420 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.164\n",
      "2021-06-20 07:24:45,946 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.253\n",
      "2021-06-20 07:24:56,508 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.139\n",
      "2021-06-20 07:25:03,250 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 65/200: loss: 0.00063 Time taken: 0:00:29.942990 ETA: 1:07:22.303627\n",
      "2021-06-20 07:25:07,032 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.258\n",
      "2021-06-20 07:25:17,595 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.135\n",
      "2021-06-20 07:25:28,050 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.478\n",
      "2021-06-20 07:25:33,085 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 66/200: loss: 0.00064 Time taken: 0:00:29.823860 ETA: 1:06:36.397199\n",
      "2021-06-20 07:25:38,562 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.296\n",
      "2021-06-20 07:25:49,023 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.461\n",
      "2021-06-20 07:25:59,560 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.215\n",
      "2021-06-20 07:26:02,969 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 67/200: loss: 0.00060 Time taken: 0:00:29.890529 ETA: 1:06:15.440346\n",
      "2021-06-20 07:26:10,097 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.219\n",
      "2021-06-20 07:26:20,596 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.338\n",
      "2021-06-20 07:26:31,100 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.321\n",
      "2021-06-20 07:26:32,806 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 68/200: loss: 0.00061 Time taken: 0:00:29.836690 ETA: 1:05:38.443042\n",
      "2021-06-20 07:26:41,620 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.270\n",
      "2021-06-20 07:26:52,188 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.121\n",
      "2021-06-20 07:27:02,822 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 69/200: loss: 0.00060 Time taken: 0:00:30.013214 ETA: 1:05:31.731080\n",
      "2021-06-20 07:27:02,822 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 32.915\n",
      "2021-06-20 07:27:13,347 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.255\n",
      "2021-06-20 07:27:23,803 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.474\n",
      "2021-06-20 07:27:32,252 [INFO] iva.detectnet_v2.evaluation.evaluation: step 0 / 17, 0.00s/step\n",
      "2021-06-20 07:27:35,462 [INFO] iva.detectnet_v2.evaluation.evaluation: step 10 / 17, 0.32s/step\n",
      "Matching predictions to ground truth, class 1/3.: 100%|| 2088/2088 [00:00<00:00, 41416.02it/s]\n",
      "Matching predictions to ground truth, class 2/3.: 100%|| 6644/6644 [00:00<00:00, 32155.28it/s]\n",
      "Matching predictions to ground truth, class 3/3.: 100%|| 922/922 [00:00<00:00, 24395.80it/s]\n",
      "Epoch 70/200\n",
      "=========================\n",
      "\n",
      "Validation cost: 0.000222\n",
      "Mean average_precision (in %): 39.5500\n",
      "\n",
      "class name               average precision (in %)\n",
      "---------------------  --------------------------\n",
      "helmet                                    36.7196\n",
      "person_with_helmet                        30.1402\n",
      "person_without_helmet                     51.7903\n",
      "\n",
      "Median Inference Time: 0.010133\n",
      "2021-06-20 07:27:38,561 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 70/200: loss: 0.00064 Time taken: 0:00:35.740717 ETA: 1:17:26.293201\n",
      "2021-06-20 07:27:40,248 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 21.284\n",
      "2021-06-20 07:27:50,802 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.163\n",
      "2021-06-20 07:28:01,329 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.250\n",
      "2021-06-20 07:28:08,438 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 71/200: loss: 0.00063 Time taken: 0:00:29.871686 ETA: 1:04:13.447492\n",
      "2021-06-20 07:28:11,814 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-20 07:28:22,281 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.441\n",
      "2021-06-20 07:28:32,846 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.128\n",
      "2021-06-20 07:28:38,306 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 72/200: loss: 0.00063 Time taken: 0:00:29.871326 ETA: 1:03:43.529785\n",
      "2021-06-20 07:28:43,388 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.199\n",
      "2021-06-20 07:28:53,922 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.227\n",
      "2021-06-20 07:29:04,402 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.398\n",
      "2021-06-20 07:29:08,177 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 73/200: loss: 0.00058 Time taken: 0:00:29.870302 ETA: 1:03:13.528410\n",
      "2021-06-20 07:29:14,893 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.364\n",
      "2021-06-20 07:29:25,387 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.354\n",
      "2021-06-20 07:29:35,947 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.145\n",
      "2021-06-20 07:29:38,046 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 74/200: loss: 0.00065 Time taken: 0:00:29.864016 ETA: 1:02:42.866023\n",
      "2021-06-20 07:29:46,463 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.282\n",
      "2021-06-20 07:29:56,956 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.358\n",
      "2021-06-20 07:30:07,502 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.190\n",
      "2021-06-20 07:30:07,954 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 75/200: loss: 0.00060 Time taken: 0:00:29.876311 ETA: 1:02:14.538823\n",
      "2021-06-20 07:30:18,063 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.144\n",
      "2021-06-20 07:30:28,577 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.288\n",
      "2021-06-20 07:30:37,830 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 76/200: loss: 0.00062 Time taken: 0:00:29.899295 ETA: 1:01:47.512562\n",
      "2021-06-20 07:30:39,087 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.303\n",
      "2021-06-20 07:30:49,616 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.244\n",
      "2021-06-20 07:31:00,162 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.187\n",
      "2021-06-20 07:31:07,811 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 77/200: loss: 0.00065 Time taken: 0:00:29.945964 ETA: 1:01:23.353613\n",
      "2021-06-20 07:31:10,870 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 32.687\n",
      "2021-06-20 07:31:21,603 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 32.613\n",
      "2021-06-20 07:31:32,072 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.430\n",
      "2021-06-20 07:31:38,005 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 78/200: loss: 0.00057 Time taken: 0:00:30.215810 ETA: 1:01:26.328827\n",
      "2021-06-20 07:31:42,606 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.228\n",
      "2021-06-20 07:31:53,133 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.249\n",
      "2021-06-20 07:32:03,634 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.333\n",
      "2021-06-20 07:32:07,922 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 79/200: loss: 0.00060 Time taken: 0:00:29.939261 ETA: 1:00:22.650547\n",
      "2021-06-20 07:32:14,208 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.100\n",
      "2021-06-20 07:32:24,728 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.271\n",
      "2021-06-20 07:32:35,203 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.414\n",
      "2021-06-20 07:32:37,368 [INFO] iva.detectnet_v2.evaluation.evaluation: step 0 / 17, 0.00s/step\n",
      "2021-06-20 07:32:39,915 [INFO] iva.detectnet_v2.evaluation.evaluation: step 10 / 17, 0.25s/step\n",
      "Matching predictions to ground truth, class 1/3.: 100%|| 2392/2392 [00:00<00:00, 41473.17it/s]\n",
      "Matching predictions to ground truth, class 2/3.: 100%|| 5829/5829 [00:00<00:00, 32969.77it/s]\n",
      "Matching predictions to ground truth, class 3/3.: 100%|| 1759/1759 [00:00<00:00, 23018.52it/s]\n",
      "Epoch 80/200\n",
      "=========================\n",
      "\n",
      "Validation cost: 0.000243\n",
      "Mean average_precision (in %): 45.8059\n",
      "\n",
      "class name               average precision (in %)\n",
      "---------------------  --------------------------\n",
      "helmet                                    63.2962\n",
      "person_with_helmet                        35.2894\n",
      "person_without_helmet                     38.8322\n",
      "\n",
      "Median Inference Time: 0.010006\n",
      "2021-06-20 07:32:42,601 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 80/200: loss: 0.00054 Time taken: 0:00:34.675778 ETA: 1:09:21.093378\n",
      "2021-06-20 07:32:50,570 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 22.776\n",
      "2021-06-20 07:33:01,121 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.173\n",
      "2021-06-20 07:33:11,612 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.364\n",
      "2021-06-20 07:33:12,465 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 81/200: loss: 0.00051 Time taken: 0:00:29.865541 ETA: 0:59:13.999320\n",
      "2021-06-20 07:33:22,145 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.228\n",
      "2021-06-20 07:33:32,668 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.263\n",
      "2021-06-20 07:33:42,515 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 82/200: loss: 0.00064 Time taken: 0:00:30.044292 ETA: 0:59:05.226453\n",
      "2021-06-20 07:33:43,374 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 32.693\n",
      "2021-06-20 07:33:53,902 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.246\n",
      "2021-06-20 07:34:04,467 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.130\n",
      "2021-06-20 07:34:12,486 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 83/200: loss: 0.00054 Time taken: 0:00:29.974543 ETA: 0:58:27.021514\n",
      "2021-06-20 07:34:15,040 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.104\n",
      "2021-06-20 07:34:25,553 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.292\n",
      "2021-06-20 07:34:36,030 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.408\n",
      "2021-06-20 07:34:42,381 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 84/200: loss: 0.00057 Time taken: 0:00:29.886263 ETA: 0:57:46.806468\n",
      "2021-06-20 07:34:46,598 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.119\n",
      "2021-06-20 07:34:57,116 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.279\n",
      "2021-06-20 07:35:07,658 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.201\n",
      "2021-06-20 07:35:12,292 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 85/200: loss: 0.00055 Time taken: 0:00:29.920233 ETA: 0:57:20.826741\n",
      "2021-06-20 07:35:18,181 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.261\n",
      "2021-06-20 07:35:28,714 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.228\n",
      "2021-06-20 07:35:39,242 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.246\n",
      "2021-06-20 07:35:42,214 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 86/200: loss: 0.00057 Time taken: 0:00:29.908520 ETA: 0:56:49.571278\n",
      "2021-06-20 07:35:49,762 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.271\n",
      "2021-06-20 07:36:00,401 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 32.898\n",
      "2021-06-20 07:36:11,073 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 32.797\n",
      "2021-06-20 07:36:12,334 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 87/200: loss: 0.00059 Time taken: 0:00:30.130523 ETA: 0:56:44.749068\n",
      "2021-06-20 07:36:21,586 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-20 07:36:32,132 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.186\n",
      "2021-06-20 07:36:42,274 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 88/200: loss: 0.00057 Time taken: 0:00:29.927736 ETA: 0:55:51.906464\n",
      "2021-06-20 07:36:42,731 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.023\n",
      "2021-06-20 07:36:53,277 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.192\n",
      "2021-06-20 07:37:03,813 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.218\n",
      "2021-06-20 07:37:12,331 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 89/200: loss: 0.00049 Time taken: 0:00:30.067281 ETA: 0:55:37.468245\n",
      "2021-06-20 07:37:14,472 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 32.839\n",
      "2021-06-20 07:37:24,996 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.257\n",
      "2021-06-20 07:37:35,501 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.317\n",
      "2021-06-20 07:37:48,036 [INFO] iva.detectnet_v2.evaluation.evaluation: step 0 / 17, 0.00s/step\n",
      "2021-06-20 07:37:50,421 [INFO] iva.detectnet_v2.evaluation.evaluation: step 10 / 17, 0.24s/step\n",
      "Matching predictions to ground truth, class 1/3.: 100%|| 2523/2523 [00:00<00:00, 40019.32it/s]\n",
      "Matching predictions to ground truth, class 2/3.: 100%|| 4491/4491 [00:00<00:00, 29480.12it/s]\n",
      "Matching predictions to ground truth, class 3/3.: 100%|| 836/836 [00:00<00:00, 20372.88it/s]\n",
      "Epoch 90/200\n",
      "=========================\n",
      "\n",
      "Validation cost: 0.000235\n",
      "Mean average_precision (in %): 53.5314\n",
      "\n",
      "class name               average precision (in %)\n",
      "---------------------  --------------------------\n",
      "helmet                                    67.3997\n",
      "person_with_helmet                        39.5169\n",
      "person_without_helmet                     53.6775\n",
      "\n",
      "Median Inference Time: 0.010026\n",
      "2021-06-20 07:37:52,968 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 90/200: loss: 0.00051 Time taken: 0:00:40.625596 ETA: 1:14:28.815565\n",
      "2021-06-20 07:37:56,730 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 16.487\n",
      "2021-06-20 07:38:07,224 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.353\n",
      "2021-06-20 07:38:17,712 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.374\n",
      "2021-06-20 07:38:22,734 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 91/200: loss: 0.00054 Time taken: 0:00:29.769204 ETA: 0:54:04.843225\n",
      "2021-06-20 07:38:28,230 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.278\n",
      "2021-06-20 07:38:38,718 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.370\n",
      "2021-06-20 07:38:49,218 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.334\n",
      "2021-06-20 07:38:52,590 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 92/200: loss: 0.00049 Time taken: 0:00:29.858602 ETA: 0:53:44.729021\n",
      "2021-06-20 07:38:59,773 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.162\n",
      "2021-06-20 07:39:10,249 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.412\n",
      "2021-06-20 07:39:20,769 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.269\n",
      "2021-06-20 07:39:22,458 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 93/200: loss: 0.00051 Time taken: 0:00:29.869561 ETA: 0:53:16.043022\n",
      "2021-06-20 07:39:31,279 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.303\n",
      "2021-06-20 07:39:41,871 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.046\n",
      "2021-06-20 07:39:52,402 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 94/200: loss: 0.00051 Time taken: 0:00:29.944173 ETA: 0:52:54.082323\n",
      "2021-06-20 07:39:52,402 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.234\n",
      "2021-06-20 07:40:02,931 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.244\n",
      "2021-06-20 07:40:13,486 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.160\n",
      "2021-06-20 07:40:22,370 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 95/200: loss: 0.00051 Time taken: 0:00:29.959121 ETA: 0:52:25.707704\n",
      "2021-06-20 07:40:24,056 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.112\n",
      "2021-06-20 07:40:34,569 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.294\n",
      "2021-06-20 07:40:45,088 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.274\n",
      "2021-06-20 07:40:52,222 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 96/200: loss: 0.00051 Time taken: 0:00:29.857122 ETA: 0:51:45.140682\n",
      "2021-06-20 07:40:55,636 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.182\n",
      "2021-06-20 07:41:06,155 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.275\n",
      "2021-06-20 07:41:16,696 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.204\n",
      "2021-06-20 07:41:22,187 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 97/200: loss: 0.00047 Time taken: 0:00:29.965605 ETA: 0:51:26.457342\n",
      "2021-06-20 07:41:27,199 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.326\n",
      "2021-06-20 07:41:37,694 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.351\n",
      "2021-06-20 07:41:48,290 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.033\n",
      "2021-06-20 07:41:52,064 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 98/200: loss: 0.00046 Time taken: 0:00:29.874449 ETA: 0:50:47.193775\n",
      "2021-06-20 07:41:58,833 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.196\n",
      "2021-06-20 07:42:09,362 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.245\n",
      "2021-06-20 07:42:19,856 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.353\n",
      "2021-06-20 07:42:21,985 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 99/200: loss: 0.00047 Time taken: 0:00:29.920604 ETA: 0:50:21.981051\n",
      "2021-06-20 07:42:30,395 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.211\n",
      "2021-06-20 07:42:40,930 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.222\n",
      "2021-06-20 07:42:51,499 [INFO] iva.detectnet_v2.evaluation.evaluation: step 0 / 17, 0.00s/step\n",
      "2021-06-20 07:42:53,835 [INFO] iva.detectnet_v2.evaluation.evaluation: step 10 / 17, 0.23s/step\n",
      "Matching predictions to ground truth, class 1/3.: 100%|| 2217/2217 [00:00<00:00, 40965.92it/s]\n",
      "Matching predictions to ground truth, class 2/3.: 100%|| 3006/3006 [00:00<00:00, 33589.83it/s]\n",
      "Matching predictions to ground truth, class 3/3.: 100%|| 979/979 [00:00<00:00, 20979.56it/s]\n",
      "Epoch 100/200\n",
      "=========================\n",
      "\n",
      "Validation cost: 0.000229\n",
      "Mean average_precision (in %): 58.6344\n",
      "\n",
      "class name               average precision (in %)\n",
      "---------------------  --------------------------\n",
      "helmet                                    74.3187\n",
      "person_with_helmet                        46.5445\n",
      "person_without_helmet                     55.0401\n",
      "\n",
      "Median Inference Time: 0.010131\n",
      "2021-06-20 07:42:55,812 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 23.519\n",
      "2021-06-20 07:42:56,232 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 100/200: loss: 0.00054 Time taken: 0:00:34.243041 ETA: 0:57:04.304128\n",
      "2021-06-20 07:43:06,301 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.373\n",
      "2021-06-20 07:43:16,834 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.231\n",
      "2021-06-20 07:43:26,127 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 101/200: loss: 0.00046 Time taken: 0:00:29.897698 ETA: 0:49:19.872095\n",
      "2021-06-20 07:43:27,382 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.183\n",
      "2021-06-20 07:43:37,869 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.374\n",
      "2021-06-20 07:43:48,411 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-20 07:43:56,025 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 102/200: loss: 0.00052 Time taken: 0:00:29.887767 ETA: 0:48:49.001197\n",
      "2021-06-20 07:43:59,020 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 32.991\n",
      "2021-06-20 07:44:09,517 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.344\n",
      "2021-06-20 07:44:20,046 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.242\n",
      "2021-06-20 07:44:25,941 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 103/200: loss: 0.00042 Time taken: 0:00:29.924264 ETA: 0:48:22.653627\n",
      "2021-06-20 07:44:30,614 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.119\n",
      "2021-06-20 07:44:41,136 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.266\n",
      "2021-06-20 07:44:51,634 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.339\n",
      "2021-06-20 07:44:55,851 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 104/200: loss: 0.00057 Time taken: 0:00:29.908360 ETA: 0:47:51.202538\n",
      "2021-06-20 07:45:02,155 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.270\n",
      "2021-06-20 07:45:12,706 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.174\n",
      "2021-06-20 07:45:23,240 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.226\n",
      "2021-06-20 07:45:25,803 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 105/200: loss: 0.00053 Time taken: 0:00:29.950839 ETA: 0:47:25.329732\n",
      "2021-06-20 07:45:33,862 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 32.951\n",
      "2021-06-20 07:45:44,406 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.195\n",
      "2021-06-20 07:45:55,010 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.008\n",
      "2021-06-20 07:45:55,890 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 106/200: loss: 0.00047 Time taken: 0:00:30.077296 ETA: 0:47:07.265848\n",
      "2021-06-20 07:46:05,538 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.246\n",
      "2021-06-20 07:46:16,083 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.192\n",
      "2021-06-20 07:46:25,779 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 107/200: loss: 0.00042 Time taken: 0:00:29.894938 ETA: 0:46:20.229189\n",
      "2021-06-20 07:46:26,618 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.223\n",
      "2021-06-20 07:46:37,158 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.209\n",
      "2021-06-20 07:46:47,731 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.105\n",
      "2021-06-20 07:46:55,788 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 108/200: loss: 0.00046 Time taken: 0:00:30.012179 ETA: 0:46:01.120502\n",
      "2021-06-20 07:46:58,350 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 32.960\n",
      "2021-06-20 07:47:08,858 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.307\n",
      "2021-06-20 07:47:19,444 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.064\n",
      "2021-06-20 07:47:25,726 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 109/200: loss: 0.00046 Time taken: 0:00:29.922966 ETA: 0:45:22.989950\n",
      "2021-06-20 07:47:29,964 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.271\n",
      "2021-06-20 07:47:40,521 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.154\n",
      "2021-06-20 07:47:51,024 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.324\n",
      "2021-06-20 07:47:55,258 [INFO] iva.detectnet_v2.evaluation.evaluation: step 0 / 17, 0.00s/step\n",
      "2021-06-20 07:47:57,439 [INFO] iva.detectnet_v2.evaluation.evaluation: step 10 / 17, 0.22s/step\n",
      "Matching predictions to ground truth, class 1/3.: 100%|| 840/840 [00:00<00:00, 34043.36it/s]\n",
      "Matching predictions to ground truth, class 2/3.: 100%|| 3146/3146 [00:00<00:00, 29887.79it/s]\n",
      "Matching predictions to ground truth, class 3/3.: 100%|| 493/493 [00:00<00:00, 22291.61it/s]\n",
      "Epoch 110/200\n",
      "=========================\n",
      "\n",
      "Validation cost: 0.000232\n",
      "Mean average_precision (in %): 59.6083\n",
      "\n",
      "class name               average precision (in %)\n",
      "---------------------  --------------------------\n",
      "helmet                                    75.5948\n",
      "person_with_helmet                        55.3216\n",
      "person_without_helmet                     47.9084\n",
      "\n",
      "Median Inference Time: 0.010246\n",
      "2021-06-20 07:47:59,567 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 110/200: loss: 0.00045 Time taken: 0:00:33.851431 ETA: 0:50:46.628823\n",
      "2021-06-20 07:48:05,462 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 24.242\n",
      "2021-06-20 07:48:15,979 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.281\n",
      "2021-06-20 07:48:26,474 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.349\n",
      "2021-06-20 07:48:29,495 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 111/200: loss: 0.00037 Time taken: 0:00:29.930281 ETA: 0:44:23.795045\n",
      "2021-06-20 07:48:37,065 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.049\n",
      "2021-06-20 07:48:47,625 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.146\n",
      "2021-06-20 07:48:58,257 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 32.919\n",
      "2021-06-20 07:48:59,541 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 112/200: loss: 0.00042 Time taken: 0:00:30.036832 ETA: 0:44:03.241245\n",
      "2021-06-20 07:49:08,794 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.218\n",
      "2021-06-20 07:49:19,279 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.383\n",
      "2021-06-20 07:49:29,434 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 113/200: loss: 0.00040 Time taken: 0:00:29.897421 ETA: 0:43:21.075617\n",
      "2021-06-20 07:49:29,856 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.090\n",
      "2021-06-20 07:49:40,361 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.319\n",
      "2021-06-20 07:49:50,865 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.320\n",
      "2021-06-20 07:49:59,283 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 114/200: loss: 0.00039 Time taken: 0:00:29.851110 ETA: 0:42:47.195499\n",
      "2021-06-20 07:50:01,424 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.148\n",
      "2021-06-20 07:50:11,953 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.243\n",
      "2021-06-20 07:50:22,470 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.282\n",
      "2021-06-20 07:50:29,198 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 115/200: loss: 0.00040 Time taken: 0:00:29.911330 ETA: 0:42:22.463089\n",
      "2021-06-20 07:50:33,028 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.151\n",
      "2021-06-20 07:50:43,591 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.135\n",
      "2021-06-20 07:50:54,094 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.324\n",
      "2021-06-20 07:50:59,168 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 116/200: loss: 0.00045 Time taken: 0:00:29.963047 ETA: 0:41:56.895930\n",
      "2021-06-20 07:51:04,616 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.264\n",
      "2021-06-20 07:51:15,132 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.284\n",
      "2021-06-20 07:51:25,697 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.130\n",
      "2021-06-20 07:51:29,090 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 117/200: loss: 0.00037 Time taken: 0:00:29.925179 ETA: 0:41:23.789838\n",
      "2021-06-20 07:51:36,267 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.113\n",
      "2021-06-20 07:51:46,748 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.394\n",
      "2021-06-20 07:51:57,517 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 32.501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-20 07:51:59,228 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 118/200: loss: 0.00040 Time taken: 0:00:30.142268 ETA: 0:41:11.665971\n",
      "2021-06-20 07:52:08,052 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.227\n",
      "2021-06-20 07:52:18,552 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.334\n",
      "2021-06-20 07:52:29,058 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 119/200: loss: 0.00042 Time taken: 0:00:29.821030 ETA: 0:40:15.503461\n",
      "2021-06-20 07:52:29,059 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.313\n",
      "2021-06-20 07:52:39,563 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.320\n",
      "2021-06-20 07:52:50,071 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.308\n",
      "2021-06-20 07:53:04,379 [INFO] iva.detectnet_v2.evaluation.evaluation: step 0 / 17, 0.00s/step\n",
      "2021-06-20 07:53:06,464 [INFO] iva.detectnet_v2.evaluation.evaluation: step 10 / 17, 0.21s/step\n",
      "Matching predictions to ground truth, class 1/3.: 100%|| 1335/1335 [00:00<00:00, 32286.76it/s]\n",
      "Matching predictions to ground truth, class 2/3.: 100%|| 2312/2312 [00:00<00:00, 26510.59it/s]\n",
      "Matching predictions to ground truth, class 3/3.: 100%|| 846/846 [00:00<00:00, 26094.30it/s]\n",
      "Epoch 120/200\n",
      "=========================\n",
      "\n",
      "Validation cost: 0.000234\n",
      "Mean average_precision (in %): 62.6165\n",
      "\n",
      "class name               average precision (in %)\n",
      "---------------------  --------------------------\n",
      "helmet                                    79.0328\n",
      "person_with_helmet                        59.1845\n",
      "person_without_helmet                     49.6321\n",
      "\n",
      "Median Inference Time: 0.010102\n",
      "2021-06-20 07:53:08,594 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 120/200: loss: 0.00041 Time taken: 0:00:39.506460 ETA: 0:52:40.516834\n",
      "2021-06-20 07:53:10,272 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 17.326\n",
      "2021-06-20 07:53:20,786 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.288\n",
      "2021-06-20 07:53:31,324 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.216\n",
      "2021-06-20 07:53:38,488 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 121/200: loss: 0.00044 Time taken: 0:00:29.930738 ETA: 0:39:24.528281\n",
      "2021-06-20 07:53:41,855 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.238\n",
      "2021-06-20 07:53:52,349 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.351\n",
      "2021-06-20 07:54:02,864 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.287\n",
      "2021-06-20 07:54:08,333 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 122/200: loss: 0.00038 Time taken: 0:00:29.826936 ETA: 0:38:46.501009\n",
      "2021-06-20 07:54:13,403 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.211\n",
      "2021-06-20 07:54:23,933 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.240\n",
      "2021-06-20 07:54:34,430 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.345\n",
      "2021-06-20 07:54:38,287 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 123/200: loss: 0.00034 Time taken: 0:00:29.961577 ETA: 0:38:27.041406\n",
      "2021-06-20 07:54:45,038 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 32.994\n",
      "2021-06-20 07:54:55,626 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.057\n",
      "2021-06-20 07:55:06,160 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.225\n",
      "2021-06-20 07:55:08,285 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 124/200: loss: 0.00034 Time taken: 0:00:30.006480 ETA: 0:38:00.492496\n",
      "2021-06-20 07:55:16,695 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.223\n",
      "2021-06-20 07:55:27,217 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.266\n",
      "2021-06-20 07:55:37,750 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.228\n",
      "2021-06-20 07:55:38,179 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 125/200: loss: 0.00035 Time taken: 0:00:29.878644 ETA: 0:37:20.898299\n",
      "2021-06-20 07:55:48,309 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.152\n",
      "2021-06-20 07:55:58,861 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.169\n",
      "2021-06-20 07:56:08,107 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 126/200: loss: 0.00034 Time taken: 0:00:29.928336 ETA: 0:36:54.696875\n",
      "2021-06-20 07:56:09,401 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.209\n",
      "2021-06-20 07:56:19,917 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.283\n",
      "2021-06-20 07:56:30,455 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.217\n",
      "2021-06-20 07:56:38,067 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 127/200: loss: 0.00036 Time taken: 0:00:29.962750 ETA: 0:36:27.280747\n",
      "2021-06-20 07:56:41,002 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.184\n",
      "2021-06-20 07:56:51,522 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.272\n",
      "2021-06-20 07:57:02,073 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.175\n",
      "2021-06-20 07:57:07,942 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 128/200: loss: 0.00033 Time taken: 0:00:29.881482 ETA: 0:35:51.466696\n",
      "2021-06-20 07:57:12,555 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.391\n",
      "2021-06-20 07:57:23,076 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.267\n",
      "2021-06-20 07:57:33,590 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.291\n",
      "2021-06-20 07:57:37,923 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 129/200: loss: 0.00034 Time taken: 0:00:29.974500 ETA: 0:35:28.189496\n",
      "2021-06-20 07:57:44,235 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 32.881\n",
      "2021-06-20 07:57:54,762 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.249\n",
      "2021-06-20 07:58:05,310 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.183\n",
      "2021-06-20 07:58:07,448 [INFO] iva.detectnet_v2.evaluation.evaluation: step 0 / 17, 0.00s/step\n",
      "2021-06-20 07:58:09,734 [INFO] iva.detectnet_v2.evaluation.evaluation: step 10 / 17, 0.23s/step\n",
      "Matching predictions to ground truth, class 1/3.: 100%|| 1347/1347 [00:00<00:00, 33060.03it/s]\n",
      "Matching predictions to ground truth, class 2/3.: 100%|| 4160/4160 [00:00<00:00, 29292.00it/s]\n",
      "Matching predictions to ground truth, class 3/3.: 100%|| 524/524 [00:00<00:00, 21090.05it/s]\n",
      "Epoch 130/200\n",
      "=========================\n",
      "\n",
      "Validation cost: 0.000229\n",
      "Mean average_precision (in %): 65.3043\n",
      "\n",
      "class name               average precision (in %)\n",
      "---------------------  --------------------------\n",
      "helmet                                    81.8708\n",
      "person_with_helmet                        60.5839\n",
      "person_without_helmet                     53.4582\n",
      "\n",
      "Median Inference Time: 0.010117\n",
      "2021-06-20 07:58:12,002 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 130/200: loss: 0.00036 Time taken: 0:00:34.081101 ETA: 0:39:45.677099\n",
      "2021-06-20 07:58:19,968 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 23.878\n",
      "2021-06-20 07:58:30,501 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.231\n",
      "2021-06-20 07:58:41,087 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.063\n",
      "2021-06-20 07:58:41,941 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 131/200: loss: 0.00036 Time taken: 0:00:29.931324 ETA: 0:34:25.261323\n",
      "2021-06-20 07:58:51,632 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.191\n",
      "2021-06-20 07:59:02,257 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 32.941\n",
      "2021-06-20 07:59:11,929 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 132/200: loss: 0.00035 Time taken: 0:00:29.996024 ETA: 0:33:59.729625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-20 07:59:12,801 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.197\n",
      "2021-06-20 07:59:23,313 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.296\n",
      "2021-06-20 07:59:33,773 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.460\n",
      "2021-06-20 07:59:41,778 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 133/200: loss: 0.00030 Time taken: 0:00:29.844921 ETA: 0:33:19.609730\n",
      "2021-06-20 07:59:44,341 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.120\n",
      "2021-06-20 07:59:54,864 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.263\n",
      "2021-06-20 08:00:05,436 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.106\n",
      "2021-06-20 08:00:11,762 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 134/200: loss: 0.00030 Time taken: 0:00:29.988098 ETA: 0:32:59.214493\n",
      "2021-06-20 08:00:15,972 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.222\n",
      "2021-06-20 08:00:26,533 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.141\n",
      "2021-06-20 08:00:37,037 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.323\n",
      "2021-06-20 08:00:41,715 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 135/200: loss: 0.00037 Time taken: 0:00:29.939304 ETA: 0:32:26.054767\n",
      "2021-06-20 08:00:47,592 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.160\n",
      "2021-06-20 08:00:58,206 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 32.975\n",
      "2021-06-20 08:01:08,811 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.006\n",
      "2021-06-20 08:01:11,804 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 136/200: loss: 0.00031 Time taken: 0:00:30.094358 ETA: 0:32:06.038940\n",
      "2021-06-20 08:01:19,383 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.106\n",
      "2021-06-20 08:01:29,922 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.212\n",
      "2021-06-20 08:01:40,472 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.177\n",
      "2021-06-20 08:01:41,737 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 137/200: loss: 0.00035 Time taken: 0:00:29.929391 ETA: 0:31:25.551657\n",
      "2021-06-20 08:01:51,014 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.200\n",
      "2021-06-20 08:02:01,572 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.153\n",
      "2021-06-20 08:02:11,742 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 138/200: loss: 0.00035 Time taken: 0:00:30.012457 ETA: 0:31:00.772357\n",
      "2021-06-20 08:02:12,162 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.050\n",
      "2021-06-20 08:02:22,696 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.226\n",
      "2021-06-20 08:02:33,169 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.420\n",
      "2021-06-20 08:02:41,599 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 139/200: loss: 0.00026 Time taken: 0:00:29.856007 ETA: 0:30:21.216419\n",
      "2021-06-20 08:02:43,729 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.147\n",
      "2021-06-20 08:02:54,256 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.249\n",
      "2021-06-20 08:03:04,819 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.133\n",
      "2021-06-20 08:03:11,159 [INFO] iva.detectnet_v2.evaluation.evaluation: step 0 / 17, 0.00s/step\n",
      "2021-06-20 08:03:13,426 [INFO] iva.detectnet_v2.evaluation.evaluation: step 10 / 17, 0.23s/step\n",
      "Matching predictions to ground truth, class 1/3.: 100%|| 1168/1168 [00:00<00:00, 30090.52it/s]\n",
      "Matching predictions to ground truth, class 2/3.: 100%|| 3619/3619 [00:00<00:00, 28258.33it/s]\n",
      "Matching predictions to ground truth, class 3/3.: 100%|| 696/696 [00:00<00:00, 22568.50it/s]\n",
      "Epoch 140/200\n",
      "=========================\n",
      "\n",
      "Validation cost: 0.000215\n",
      "Mean average_precision (in %): 64.3671\n",
      "\n",
      "class name               average precision (in %)\n",
      "---------------------  --------------------------\n",
      "helmet                                    80.5956\n",
      "person_with_helmet                        56.9183\n",
      "person_without_helmet                     55.5874\n",
      "\n",
      "Median Inference Time: 0.010265\n",
      "2021-06-20 08:03:15,715 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 140/200: loss: 0.00035 Time taken: 0:00:34.113770 ETA: 0:34:06.826186\n",
      "2021-06-20 08:03:19,524 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 23.803\n",
      "2021-06-20 08:03:30,086 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.138\n",
      "2021-06-20 08:03:40,578 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.360\n",
      "2021-06-20 08:03:45,664 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 141/200: loss: 0.00028 Time taken: 0:00:29.943206 ETA: 0:29:26.649130\n",
      "2021-06-20 08:03:51,133 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.162\n",
      "2021-06-20 08:04:01,665 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.234\n",
      "2021-06-20 08:04:12,163 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.340\n",
      "2021-06-20 08:04:15,549 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 142/200: loss: 0.00031 Time taken: 0:00:29.889585 ETA: 0:28:53.595903\n",
      "2021-06-20 08:04:22,692 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.243\n",
      "2021-06-20 08:04:33,218 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.250\n",
      "2021-06-20 08:04:43,878 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 32.834\n",
      "2021-06-20 08:04:45,570 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 143/200: loss: 0.00027 Time taken: 0:00:30.014742 ETA: 0:28:30.840302\n",
      "2021-06-20 08:04:54,429 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.172\n",
      "2021-06-20 08:05:04,946 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.282\n",
      "2021-06-20 08:05:15,451 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 144/200: loss: 0.00028 Time taken: 0:00:29.870809 ETA: 0:27:52.765295\n",
      "2021-06-20 08:05:15,451 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.317\n",
      "2021-06-20 08:05:25,953 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.328\n",
      "2021-06-20 08:05:36,490 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.218\n",
      "2021-06-20 08:05:45,346 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 145/200: loss: 0.00028 Time taken: 0:00:29.905911 ETA: 0:27:24.825130\n",
      "2021-06-20 08:05:47,066 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.094\n",
      "2021-06-20 08:05:57,547 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.394\n",
      "2021-06-20 08:06:08,128 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.081\n",
      "2021-06-20 08:06:15,302 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 146/200: loss: 0.00025 Time taken: 0:00:29.959494 ETA: 0:26:57.812669\n",
      "2021-06-20 08:06:18,672 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.194\n",
      "2021-06-20 08:06:29,170 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.343\n",
      "2021-06-20 08:06:39,661 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.360\n",
      "2021-06-20 08:06:45,156 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 147/200: loss: 0.00037 Time taken: 0:00:29.847466 ETA: 0:26:21.915723\n",
      "2021-06-20 08:06:50,192 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.236\n",
      "2021-06-20 08:07:00,755 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.137\n",
      "2021-06-20 08:07:11,245 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.366\n",
      "2021-06-20 08:07:15,180 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 148/200: loss: 0.00026 Time taken: 0:00:30.026822 ETA: 0:26:01.394736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-20 08:07:21,937 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 32.734\n",
      "2021-06-20 08:07:32,423 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.380\n",
      "2021-06-20 08:07:42,967 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.196\n",
      "2021-06-20 08:07:45,090 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 149/200: loss: 0.00022 Time taken: 0:00:29.901781 ETA: 0:25:24.990811\n",
      "2021-06-20 08:07:53,526 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.146\n",
      "2021-06-20 08:08:04,030 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.322\n",
      "2021-06-20 08:08:21,048 [INFO] iva.detectnet_v2.evaluation.evaluation: step 0 / 17, 0.00s/step\n",
      "2021-06-20 08:08:23,066 [INFO] iva.detectnet_v2.evaluation.evaluation: step 10 / 17, 0.20s/step\n",
      "Matching predictions to ground truth, class 1/3.: 100%|| 607/607 [00:00<00:00, 29385.64it/s]\n",
      "Matching predictions to ground truth, class 2/3.: 100%|| 2186/2186 [00:00<00:00, 26489.70it/s]\n",
      "Matching predictions to ground truth, class 3/3.: 100%|| 391/391 [00:00<00:00, 23017.49it/s]\n",
      "Epoch 150/200\n",
      "=========================\n",
      "\n",
      "Validation cost: 0.000182\n",
      "Mean average_precision (in %): 70.9376\n",
      "\n",
      "class name               average precision (in %)\n",
      "---------------------  --------------------------\n",
      "helmet                                    85.6302\n",
      "person_with_helmet                        67.15\n",
      "person_without_helmet                     60.0325\n",
      "\n",
      "Median Inference Time: 0.010007\n",
      "2021-06-20 08:08:24,637 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 16.985\n",
      "2021-06-20 08:08:25,060 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 150/200: loss: 0.00022 Time taken: 0:00:39.971155 ETA: 0:33:18.557746\n",
      "2021-06-20 08:08:35,125 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.378\n",
      "2021-06-20 08:08:45,660 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.223\n",
      "2021-06-20 08:08:54,929 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 151/200: loss: 0.00022 Time taken: 0:00:29.856412 ETA: 0:24:22.964208\n",
      "2021-06-20 08:08:56,195 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.224\n",
      "2021-06-20 08:09:06,734 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.210\n",
      "2021-06-20 08:09:17,236 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.327\n",
      "2021-06-20 08:09:24,830 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 152/200: loss: 0.00026 Time taken: 0:00:29.915078 ETA: 0:23:55.923763\n",
      "2021-06-20 08:09:27,807 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.110\n",
      "2021-06-20 08:09:38,436 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 32.931\n",
      "2021-06-20 08:09:48,917 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.393\n",
      "2021-06-20 08:09:54,857 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 153/200: loss: 0.00021 Time taken: 0:00:30.025115 ETA: 0:23:31.180417\n",
      "2021-06-20 08:09:59,490 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.107\n",
      "2021-06-20 08:10:10,028 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.213\n",
      "2021-06-20 08:10:20,530 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.329\n",
      "2021-06-20 08:10:24,759 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 154/200: loss: 0.00024 Time taken: 0:00:29.902618 ETA: 0:22:55.520414\n",
      "2021-06-20 08:10:31,055 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.254\n",
      "2021-06-20 08:10:41,565 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.301\n",
      "2021-06-20 08:10:52,082 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.281\n",
      "2021-06-20 08:10:54,670 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 155/200: loss: 0.00020 Time taken: 0:00:29.913677 ETA: 0:22:26.115443\n",
      "2021-06-20 08:11:02,651 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.119\n",
      "2021-06-20 08:11:13,102 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.489\n",
      "2021-06-20 08:11:23,587 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.381\n",
      "2021-06-20 08:11:24,470 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 156/200: loss: 0.00022 Time taken: 0:00:29.796854 ETA: 0:21:51.061577\n",
      "2021-06-20 08:11:34,147 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.146\n",
      "2021-06-20 08:11:44,666 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.274\n",
      "2021-06-20 08:11:54,324 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 157/200: loss: 0.00020 Time taken: 0:00:29.853474 ETA: 0:21:23.699388\n",
      "2021-06-20 08:11:55,176 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.302\n",
      "2021-06-20 08:12:05,671 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.353\n",
      "2021-06-20 08:12:16,222 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.173\n",
      "2021-06-20 08:12:24,241 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 158/200: loss: 0.00020 Time taken: 0:00:29.909892 ETA: 0:20:56.215447\n",
      "2021-06-20 08:12:26,765 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.199\n",
      "2021-06-20 08:12:37,280 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.287\n",
      "2021-06-20 08:12:47,847 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.120\n",
      "2021-06-20 08:12:54,198 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 159/200: loss: 0.00019 Time taken: 0:00:29.964020 ETA: 0:20:28.524840\n",
      "2021-06-20 08:12:58,427 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.084\n",
      "2021-06-20 08:13:08,903 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.409\n",
      "2021-06-20 08:13:19,429 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.252\n",
      "2021-06-20 08:13:23,686 [INFO] iva.detectnet_v2.evaluation.evaluation: step 0 / 17, 0.00s/step\n",
      "2021-06-20 08:13:25,600 [INFO] iva.detectnet_v2.evaluation.evaluation: step 10 / 17, 0.19s/step\n",
      "Matching predictions to ground truth, class 1/3.: 100%|| 481/481 [00:00<00:00, 25408.82it/s]\n",
      "Matching predictions to ground truth, class 2/3.: 100%|| 1565/1565 [00:00<00:00, 25219.52it/s]\n",
      "Matching predictions to ground truth, class 3/3.: 100%|| 322/322 [00:00<00:00, 22141.15it/s]\n",
      "Epoch 160/200\n",
      "=========================\n",
      "\n",
      "Validation cost: 0.000190\n",
      "Mean average_precision (in %): 70.0375\n",
      "\n",
      "class name               average precision (in %)\n",
      "---------------------  --------------------------\n",
      "helmet                                    86.135\n",
      "person_with_helmet                        69.6588\n",
      "person_without_helmet                     54.3187\n",
      "\n",
      "Median Inference Time: 0.009913\n",
      "2021-06-20 08:13:27,511 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 160/200: loss: 0.00021 Time taken: 0:00:33.296975 ETA: 0:22:11.878986\n",
      "2021-06-20 08:13:33,376 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 25.097\n",
      "2021-06-20 08:13:43,927 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.173\n",
      "2021-06-20 08:13:54,434 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.312\n",
      "2021-06-20 08:13:57,398 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 161/200: loss: 0.00019 Time taken: 0:00:29.899607 ETA: 0:19:26.084689\n",
      "2021-06-20 08:14:04,940 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.316\n",
      "2021-06-20 08:14:15,493 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.166\n",
      "2021-06-20 08:14:26,005 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.297\n",
      "2021-06-20 08:14:27,293 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 162/200: loss: 0.00020 Time taken: 0:00:29.895964 ETA: 0:18:56.046628\n",
      "2021-06-20 08:14:36,490 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-20 08:14:47,014 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.259\n",
      "2021-06-20 08:14:57,173 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 163/200: loss: 0.00022 Time taken: 0:00:29.878006 ETA: 0:18:25.486239\n",
      "2021-06-20 08:14:57,596 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.075\n",
      "2021-06-20 08:15:08,090 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.353\n",
      "2021-06-20 08:15:18,626 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.222\n",
      "2021-06-20 08:15:27,054 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 164/200: loss: 0.00020 Time taken: 0:00:29.880721 ETA: 0:17:55.705959\n",
      "2021-06-20 08:15:29,203 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.093\n",
      "2021-06-20 08:15:39,726 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.259\n",
      "2021-06-20 08:15:50,306 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.084\n",
      "2021-06-20 08:15:57,046 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 165/200: loss: 0.00018 Time taken: 0:00:29.982885 ETA: 0:17:29.400979\n",
      "2021-06-20 08:16:00,862 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.155\n",
      "2021-06-20 08:16:11,426 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.134\n",
      "2021-06-20 08:16:21,938 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.296\n",
      "2021-06-20 08:16:27,074 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 166/200: loss: 0.00022 Time taken: 0:00:30.025995 ETA: 0:17:00.883831\n",
      "2021-06-20 08:16:32,583 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 32.879\n",
      "2021-06-20 08:16:43,112 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.243\n",
      "2021-06-20 08:16:53,643 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.238\n",
      "2021-06-20 08:16:57,042 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 167/200: loss: 0.00020 Time taken: 0:00:29.975587 ETA: 0:16:29.194360\n",
      "2021-06-20 08:17:04,173 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.237\n",
      "2021-06-20 08:17:14,694 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.269\n",
      "2021-06-20 08:17:25,175 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.394\n",
      "2021-06-20 08:17:26,904 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 168/200: loss: 0.00018 Time taken: 0:00:29.858058 ETA: 0:15:55.457855\n",
      "2021-06-20 08:17:35,816 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 32.893\n",
      "2021-06-20 08:17:46,387 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.113\n",
      "2021-06-20 08:17:56,900 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 169/200: loss: 0.00019 Time taken: 0:00:29.997497 ETA: 0:15:29.922395\n",
      "2021-06-20 08:17:56,900 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.290\n",
      "2021-06-20 08:18:07,400 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.337\n",
      "2021-06-20 08:18:17,924 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.258\n",
      "2021-06-20 08:18:26,349 [INFO] iva.detectnet_v2.evaluation.evaluation: step 0 / 17, 0.00s/step\n",
      "2021-06-20 08:18:28,280 [INFO] iva.detectnet_v2.evaluation.evaluation: step 10 / 17, 0.19s/step\n",
      "Matching predictions to ground truth, class 1/3.: 100%|| 494/494 [00:00<00:00, 26280.90it/s]\n",
      "Matching predictions to ground truth, class 2/3.: 100%|| 1601/1601 [00:00<00:00, 24586.56it/s]\n",
      "Matching predictions to ground truth, class 3/3.: 100%|| 246/246 [00:00<00:00, 20484.80it/s]\n",
      "Epoch 170/200\n",
      "=========================\n",
      "\n",
      "Validation cost: 0.000180\n",
      "Mean average_precision (in %): 69.6277\n",
      "\n",
      "class name               average precision (in %)\n",
      "---------------------  --------------------------\n",
      "helmet                                    86.2291\n",
      "person_with_helmet                        69.9629\n",
      "person_without_helmet                     52.6911\n",
      "\n",
      "Median Inference Time: 0.010049\n",
      "2021-06-20 08:18:30,168 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 170/200: loss: 0.00017 Time taken: 0:00:33.262194 ETA: 0:16:37.865810\n",
      "2021-06-20 08:18:31,883 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 25.075\n",
      "2021-06-20 08:18:42,354 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.426\n",
      "2021-06-20 08:18:52,874 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.271\n",
      "2021-06-20 08:19:00,071 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 171/200: loss: 0.00019 Time taken: 0:00:29.906763 ETA: 0:14:27.296115\n",
      "2021-06-20 08:19:03,446 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.105\n",
      "2021-06-20 08:19:13,938 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.360\n",
      "2021-06-20 08:19:24,486 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.185\n",
      "2021-06-20 08:19:29,991 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 172/200: loss: 0.00018 Time taken: 0:00:29.918407 ETA: 0:13:57.715408\n",
      "2021-06-20 08:19:35,040 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.163\n",
      "2021-06-20 08:19:45,567 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.247\n",
      "2021-06-20 08:19:56,071 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.322\n",
      "2021-06-20 08:19:59,871 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 173/200: loss: 0.00018 Time taken: 0:00:29.881208 ETA: 0:13:26.792608\n",
      "2021-06-20 08:20:06,615 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.197\n",
      "2021-06-20 08:20:17,142 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.247\n",
      "2021-06-20 08:20:27,638 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.349\n",
      "2021-06-20 08:20:29,768 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 174/200: loss: 0.00019 Time taken: 0:00:29.893053 ETA: 0:12:57.219379\n",
      "2021-06-20 08:20:38,202 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.130\n",
      "2021-06-20 08:20:48,717 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.287\n",
      "2021-06-20 08:20:59,289 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.109\n",
      "2021-06-20 08:20:59,729 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 175/200: loss: 0.00018 Time taken: 0:00:29.939552 ETA: 0:12:28.488796\n",
      "2021-06-20 08:21:09,812 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.263\n",
      "2021-06-20 08:21:20,314 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.327\n",
      "2021-06-20 08:21:29,602 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 176/200: loss: 0.00018 Time taken: 0:00:29.885601 ETA: 0:11:57.254419\n",
      "2021-06-20 08:21:30,855 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.205\n",
      "2021-06-20 08:21:41,362 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.312\n",
      "2021-06-20 08:21:51,867 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.320\n",
      "2021-06-20 08:21:59,440 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 177/200: loss: 0.00019 Time taken: 0:00:29.846949 ETA: 0:11:26.479829\n",
      "2021-06-20 08:22:02,363 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.346\n",
      "2021-06-20 08:22:12,905 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.200\n",
      "2021-06-20 08:22:23,429 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.260\n",
      "2021-06-20 08:22:29,307 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 178/200: loss: 0.00017 Time taken: 0:00:29.864191 ETA: 0:10:57.012203\n",
      "2021-06-20 08:22:33,947 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.277\n",
      "2021-06-20 08:22:44,413 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-20 08:22:55,002 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.055\n",
      "2021-06-20 08:22:59,186 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 179/200: loss: 0.00018 Time taken: 0:00:29.881277 ETA: 0:10:27.506809\n",
      "2021-06-20 08:23:05,529 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.247\n",
      "2021-06-20 08:23:16,028 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.340\n",
      "2021-06-20 08:23:26,522 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.352\n",
      "2021-06-20 08:23:34,318 [INFO] iva.detectnet_v2.evaluation.evaluation: step 0 / 17, 0.00s/step\n",
      "2021-06-20 08:23:36,231 [INFO] iva.detectnet_v2.evaluation.evaluation: step 10 / 17, 0.19s/step\n",
      "Matching predictions to ground truth, class 1/3.: 100%|| 462/462 [00:00<00:00, 22491.92it/s]\n",
      "Matching predictions to ground truth, class 2/3.: 100%|| 1520/1520 [00:00<00:00, 24138.97it/s]\n",
      "Matching predictions to ground truth, class 3/3.: 100%|| 217/217 [00:00<00:00, 20772.89it/s]\n",
      "Epoch 180/200\n",
      "=========================\n",
      "\n",
      "Validation cost: 0.000182\n",
      "Mean average_precision (in %): 69.5915\n",
      "\n",
      "class name               average precision (in %)\n",
      "---------------------  --------------------------\n",
      "helmet                                    85.4841\n",
      "person_with_helmet                        71.1984\n",
      "person_without_helmet                     52.092\n",
      "\n",
      "Median Inference Time: 0.009978\n",
      "2021-06-20 08:23:38,093 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 180/200: loss: 0.00018 Time taken: 0:00:38.904847 ETA: 0:12:58.096948\n",
      "2021-06-20 08:23:46,050 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 17.924\n",
      "2021-06-20 08:23:56,530 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.398\n",
      "2021-06-20 08:24:07,050 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.271\n",
      "2021-06-20 08:24:07,917 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 181/200: loss: 0.00017 Time taken: 0:00:29.825331 ETA: 0:09:26.681288\n",
      "2021-06-20 08:24:17,601 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.171\n",
      "2021-06-20 08:24:28,145 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.195\n",
      "2021-06-20 08:24:37,864 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 182/200: loss: 0.00019 Time taken: 0:00:29.943071 ETA: 0:08:58.975276\n",
      "2021-06-20 08:24:38,776 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 32.925\n",
      "2021-06-20 08:24:49,264 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.372\n",
      "2021-06-20 08:24:59,809 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.192\n",
      "2021-06-20 08:25:07,768 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 183/200: loss: 0.00017 Time taken: 0:00:29.905003 ETA: 0:08:28.385048\n",
      "2021-06-20 08:25:10,291 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.391\n",
      "2021-06-20 08:25:20,761 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.429\n",
      "2021-06-20 08:25:31,306 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.192\n",
      "2021-06-20 08:25:37,648 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 184/200: loss: 0.00019 Time taken: 0:00:29.878019 ETA: 0:07:58.048309\n",
      "2021-06-20 08:25:41,879 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.104\n",
      "2021-06-20 08:25:52,357 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.406\n",
      "2021-06-20 08:26:02,883 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.251\n",
      "2021-06-20 08:26:07,531 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 185/200: loss: 0.00018 Time taken: 0:00:29.881767 ETA: 0:07:28.226509\n",
      "2021-06-20 08:26:13,478 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.037\n",
      "2021-06-20 08:26:23,994 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.284\n",
      "2021-06-20 08:26:34,533 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.210\n",
      "2021-06-20 08:26:37,490 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 186/200: loss: 0.00017 Time taken: 0:00:29.960639 ETA: 0:06:59.448943\n",
      "2021-06-20 08:26:45,111 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.088\n",
      "2021-06-20 08:26:55,661 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.177\n",
      "2021-06-20 08:27:06,162 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.330\n",
      "2021-06-20 08:27:07,458 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 187/200: loss: 0.00017 Time taken: 0:00:29.962176 ETA: 0:06:29.508283\n",
      "2021-06-20 08:27:16,755 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.041\n",
      "2021-06-20 08:27:27,324 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.118\n",
      "2021-06-20 08:27:37,438 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 188/200: loss: 0.00018 Time taken: 0:00:29.968261 ETA: 0:05:59.619129\n",
      "2021-06-20 08:27:37,858 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.225\n",
      "2021-06-20 08:27:48,419 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.142\n",
      "2021-06-20 08:27:58,996 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.092\n",
      "2021-06-20 08:28:07,417 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 189/200: loss: 0.00017 Time taken: 0:00:29.991215 ETA: 0:05:29.903370\n",
      "2021-06-20 08:28:09,548 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.168\n",
      "2021-06-20 08:28:20,008 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.463\n",
      "2021-06-20 08:28:30,578 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.115\n",
      "2021-06-20 08:28:36,902 [INFO] iva.detectnet_v2.evaluation.evaluation: step 0 / 17, 0.00s/step\n",
      "2021-06-20 08:28:38,857 [INFO] iva.detectnet_v2.evaluation.evaluation: step 10 / 17, 0.20s/step\n",
      "Matching predictions to ground truth, class 1/3.: 100%|| 494/494 [00:00<00:00, 25413.79it/s]\n",
      "Matching predictions to ground truth, class 2/3.: 100%|| 1604/1604 [00:00<00:00, 24123.43it/s]\n",
      "Matching predictions to ground truth, class 3/3.: 100%|| 216/216 [00:00<00:00, 19849.91it/s]\n",
      "Epoch 190/200\n",
      "=========================\n",
      "\n",
      "Validation cost: 0.000170\n",
      "Mean average_precision (in %): 69.1172\n",
      "\n",
      "class name               average precision (in %)\n",
      "---------------------  --------------------------\n",
      "helmet                                    86.7466\n",
      "person_with_helmet                        68.4748\n",
      "person_without_helmet                     52.1303\n",
      "\n",
      "Median Inference Time: 0.010164\n",
      "2021-06-20 08:28:40,759 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 190/200: loss: 0.00017 Time taken: 0:00:33.336461 ETA: 0:05:33.364608\n",
      "2021-06-20 08:28:44,546 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 25.057\n",
      "2021-06-20 08:28:55,128 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.075\n",
      "2021-06-20 08:29:05,610 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.391\n",
      "2021-06-20 08:29:10,646 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 191/200: loss: 0.00019 Time taken: 0:00:29.887341 ETA: 0:04:28.986071\n",
      "2021-06-20 08:29:16,138 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.247\n",
      "2021-06-20 08:29:26,663 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.255\n",
      "2021-06-20 08:29:37,194 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.237\n",
      "2021-06-20 08:29:40,630 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 192/200: loss: 0.00017 Time taken: 0:00:29.979382 ETA: 0:03:59.835056\n",
      "2021-06-20 08:29:47,752 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.152\n",
      "2021-06-20 08:29:58,291 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.209\n",
      "2021-06-20 08:30:08,815 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-20 08:30:10,565 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 193/200: loss: 0.00018 Time taken: 0:00:29.933328 ETA: 0:03:29.533299\n",
      "2021-06-20 08:30:19,419 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.009\n",
      "2021-06-20 08:30:29,910 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.363\n",
      "2021-06-20 08:30:40,430 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 194/200: loss: 0.00018 Time taken: 0:00:29.853186 ETA: 0:02:59.119118\n",
      "2021-06-20 08:30:40,430 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.270\n",
      "2021-06-20 08:30:50,992 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.137\n",
      "2021-06-20 08:31:01,550 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.152\n",
      "2021-06-20 08:31:10,377 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 195/200: loss: 0.00017 Time taken: 0:00:29.964961 ETA: 0:02:29.824804\n",
      "2021-06-20 08:31:12,076 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.253\n",
      "2021-06-20 08:31:22,579 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.325\n",
      "2021-06-20 08:31:33,125 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.187\n",
      "2021-06-20 08:31:40,307 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 196/200: loss: 0.00017 Time taken: 0:00:29.928028 ETA: 0:01:59.712112\n",
      "2021-06-20 08:31:43,683 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.152\n",
      "2021-06-20 08:31:54,142 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.465\n",
      "2021-06-20 08:32:04,632 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.366\n",
      "2021-06-20 08:32:10,137 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 197/200: loss: 0.00018 Time taken: 0:00:29.832288 ETA: 0:01:29.496865\n",
      "2021-06-20 08:32:15,188 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.157\n",
      "2021-06-20 08:32:25,745 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.154\n",
      "2021-06-20 08:32:36,299 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.165\n",
      "2021-06-20 08:32:40,147 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 198/200: loss: 0.00016 Time taken: 0:00:30.010259 ETA: 0:01:00.020517\n",
      "2021-06-20 08:32:46,877 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.088\n",
      "2021-06-20 08:32:57,406 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.244\n",
      "2021-06-20 08:33:07,906 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.332\n",
      "2021-06-20 08:33:10,026 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 199/200: loss: 0.00017 Time taken: 0:00:29.865713 ETA: 0:00:29.865713\n",
      "2021-06-20 08:33:18,424 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.279\n",
      "2021-06-20 08:33:28,968 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 33.194\n",
      "2021-06-20 08:33:39,500 [INFO] iva.detectnet_v2.evaluation.evaluation: step 0 / 17, 0.00s/step\n",
      "2021-06-20 08:33:41,432 [INFO] iva.detectnet_v2.evaluation.evaluation: step 10 / 17, 0.19s/step\n",
      "Matching predictions to ground truth, class 1/3.: 100%|| 470/470 [00:00<00:00, 24666.51it/s]\n",
      "Matching predictions to ground truth, class 2/3.: 100%|| 1571/1571 [00:00<00:00, 25029.82it/s]\n",
      "Matching predictions to ground truth, class 3/3.: 100%|| 234/234 [00:00<00:00, 20670.73it/s]\n",
      "Epoch 200/200\n",
      "=========================\n",
      "\n",
      "Validation cost: 0.000177\n",
      "Mean average_precision (in %): 70.7318\n",
      "\n",
      "class name               average precision (in %)\n",
      "---------------------  --------------------------\n",
      "helmet                                    88.3467\n",
      "person_with_helmet                        70.3136\n",
      "person_without_helmet                     53.5349\n",
      "\n",
      "Median Inference Time: 0.010066\n",
      "2021-06-20 08:33:42,897 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 25.128\n",
      "2021-06-20 08:33:50,163 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 25.128\n",
      "Time taken to run iva.detectnet_v2.scripts.train:main: 1:47:48.453218.\n"
     ]
    }
   ],
   "source": [
    "!tlt-train detectnet_v2 -e $SPECS_DIR/detectnet_v2_train_resnet18_kitti.txt \\\n",
    "                        -r $USER_EXPERIMENT_DIR/experiment_dir_unpruned \\\n",
    "                        -k $KEY \\\n",
    "                        -n resnet18_detector_hemlet \\\n",
    "                        --gpus $NUM_GPUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for each epoch:\n",
      "---------------------\n",
      "total 86M\r\n",
      "-rwxrwxrwx 1 1000 1000 43M Jun 19 16:57 resnet18_detector.tlt\r\n",
      "-rwxrwxrwx 1 1000 1000 43M Jun 20 08:33 resnet18_detector_hemlet.tlt\r\n"
     ]
    }
   ],
   "source": [
    "print('Model for each epoch:')\n",
    "print('---------------------')\n",
    "!ls -lh $USER_EXPERIMENT_DIR/experiment_dir_unpruned/weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate the trained model <a class=\"anchor\" id=\"head-4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "2021-06-20 08:52:26.984905: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-06-20 08:52:28,892 [INFO] iva.detectnet_v2.spec_handler.spec_loader: Merging specification from helmet/detectnet_v2/tlt_specs/detectnet_v2_train_resnet18_kitti.txt\n",
      "2021-06-20 08:52:30.156987: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-06-20 08:52:30.182501: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 08:52:30.182886: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce RTX 2060 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.68\n",
      "pciBusID: 0000:06:00.0\n",
      "2021-06-20 08:52:30.182905: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-06-20 08:52:30.182933: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2021-06-20 08:52:30.183787: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2021-06-20 08:52:30.192083: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2021-06-20 08:52:30.205190: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2021-06-20 08:52:30.208766: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2021-06-20 08:52:30.208818: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-06-20 08:52:30.208990: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 08:52:30.209583: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 08:52:30.210037: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
      "2021-06-20 08:52:30.210066: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-06-20 08:52:30.853686: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-06-20 08:52:30.853734: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
      "2021-06-20 08:52:30.853740: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
      "2021-06-20 08:52:30.853975: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 08:52:30.854750: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 08:52:30.855083: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 08:52:30.855382: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6266 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:06:00.0, compute capability: 7.5)\n",
      "2021-06-20 08:52:31,454 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: Serial augmentation enabled = False\n",
      "2021-06-20 08:52:31,454 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: Pseudo sharding enabled = False\n",
      "2021-06-20 08:52:31,454 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: Max Image Dimensions (all sources): (0, 0)\n",
      "2021-06-20 08:52:31,454 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: number of cpus: 16, io threads: 32, compute threads: 16, buffered batches: 4\n",
      "2021-06-20 08:52:31,454 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: total dataset size 247, number of sources: 1, batch size per gpu: 14, steps: 18\n",
      "2021-06-20 08:52:31,541 [INFO] iva.detectnet_v2.dataloader.default_dataloader: Bounding box coordinates were detected in the input specification! Bboxes will be automatically converted to polygon coordinates.\n",
      "2021-06-20 08:52:31.563554: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 08:52:31.563844: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce RTX 2060 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.68\n",
      "pciBusID: 0000:06:00.0\n",
      "2021-06-20 08:52:31.563872: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-06-20 08:52:31.563912: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2021-06-20 08:52:31.563927: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2021-06-20 08:52:31.563938: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2021-06-20 08:52:31.563950: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2021-06-20 08:52:31.563962: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2021-06-20 08:52:31.563973: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-06-20 08:52:31.564033: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 08:52:31.564283: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 08:52:31.564500: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
      "2021-06-20 08:52:31,799 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: shuffle: False - shard 0 of 1\n",
      "2021-06-20 08:52:31,803 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: sampling 1 datasets with weights:\n",
      "2021-06-20 08:52:31,803 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: source: 0 weight: 1.000000\n",
      "2021-06-20 08:52:32,050 [INFO] iva.detectnet_v2.evaluation.build_evaluator: Found 247 samples in validation set\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 3, 544, 960)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 64, 272, 480) 9472        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 64, 272, 480) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 64, 272, 480) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_conv_1 (Conv2D)        (None, 64, 136, 240) 36928       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_1 (BatchNormalizati (None, 64, 136, 240) 256         block_1a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_relu_1 (Activation)    (None, 64, 136, 240) 0           block_1a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_conv_2 (Conv2D)        (None, 64, 136, 240) 36928       block_1a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_conv_shortcut (Conv2D) (None, 64, 136, 240) 4160        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_2 (BatchNormalizati (None, 64, 136, 240) 256         block_1a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_shortcut (BatchNorm (None, 64, 136, 240) 256         block_1a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 64, 136, 240) 0           block_1a_bn_2[0][0]              \n",
      "                                                                 block_1a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_relu (Activation)      (None, 64, 136, 240) 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_conv_1 (Conv2D)        (None, 64, 136, 240) 36928       block_1a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_bn_1 (BatchNormalizati (None, 64, 136, 240) 256         block_1b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_relu_1 (Activation)    (None, 64, 136, 240) 0           block_1b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_conv_2 (Conv2D)        (None, 64, 136, 240) 36928       block_1b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_bn_2 (BatchNormalizati (None, 64, 136, 240) 256         block_1b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 64, 136, 240) 0           block_1b_bn_2[0][0]              \n",
      "                                                                 block_1a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_relu (Activation)      (None, 64, 136, 240) 0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_conv_1 (Conv2D)        (None, 128, 68, 120) 73856       block_1b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_1 (BatchNormalizati (None, 128, 68, 120) 512         block_2a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_relu_1 (Activation)    (None, 128, 68, 120) 0           block_2a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_conv_2 (Conv2D)        (None, 128, 68, 120) 147584      block_2a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_conv_shortcut (Conv2D) (None, 128, 68, 120) 8320        block_1b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_2 (BatchNormalizati (None, 128, 68, 120) 512         block_2a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_shortcut (BatchNorm (None, 128, 68, 120) 512         block_2a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 128, 68, 120) 0           block_2a_bn_2[0][0]              \n",
      "                                                                 block_2a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_relu (Activation)      (None, 128, 68, 120) 0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_conv_1 (Conv2D)        (None, 128, 68, 120) 147584      block_2a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_bn_1 (BatchNormalizati (None, 128, 68, 120) 512         block_2b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_relu_1 (Activation)    (None, 128, 68, 120) 0           block_2b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_conv_2 (Conv2D)        (None, 128, 68, 120) 147584      block_2b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_bn_2 (BatchNormalizati (None, 128, 68, 120) 512         block_2b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 128, 68, 120) 0           block_2b_bn_2[0][0]              \n",
      "                                                                 block_2a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_relu (Activation)      (None, 128, 68, 120) 0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_conv_1 (Conv2D)        (None, 256, 34, 60)  295168      block_2b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_1 (BatchNormalizati (None, 256, 34, 60)  1024        block_3a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_relu_1 (Activation)    (None, 256, 34, 60)  0           block_3a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_conv_2 (Conv2D)        (None, 256, 34, 60)  590080      block_3a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_conv_shortcut (Conv2D) (None, 256, 34, 60)  33024       block_2b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_2 (BatchNormalizati (None, 256, 34, 60)  1024        block_3a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_shortcut (BatchNorm (None, 256, 34, 60)  1024        block_3a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 256, 34, 60)  0           block_3a_bn_2[0][0]              \n",
      "                                                                 block_3a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_relu (Activation)      (None, 256, 34, 60)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_conv_1 (Conv2D)        (None, 256, 34, 60)  590080      block_3a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_bn_1 (BatchNormalizati (None, 256, 34, 60)  1024        block_3b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_relu_1 (Activation)    (None, 256, 34, 60)  0           block_3b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_conv_2 (Conv2D)        (None, 256, 34, 60)  590080      block_3b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_bn_2 (BatchNormalizati (None, 256, 34, 60)  1024        block_3b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 256, 34, 60)  0           block_3b_bn_2[0][0]              \n",
      "                                                                 block_3a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_relu (Activation)      (None, 256, 34, 60)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_conv_1 (Conv2D)        (None, 512, 34, 60)  1180160     block_3b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_bn_1 (BatchNormalizati (None, 512, 34, 60)  2048        block_4a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_relu_1 (Activation)    (None, 512, 34, 60)  0           block_4a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_conv_2 (Conv2D)        (None, 512, 34, 60)  2359808     block_4a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_conv_shortcut (Conv2D) (None, 512, 34, 60)  131584      block_3b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_bn_2 (BatchNormalizati (None, 512, 34, 60)  2048        block_4a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_bn_shortcut (BatchNorm (None, 512, 34, 60)  2048        block_4a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 512, 34, 60)  0           block_4a_bn_2[0][0]              \n",
      "                                                                 block_4a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_relu (Activation)      (None, 512, 34, 60)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_conv_1 (Conv2D)        (None, 512, 34, 60)  2359808     block_4a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_bn_1 (BatchNormalizati (None, 512, 34, 60)  2048        block_4b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_relu_1 (Activation)    (None, 512, 34, 60)  0           block_4b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_conv_2 (Conv2D)        (None, 512, 34, 60)  2359808     block_4b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_bn_2 (BatchNormalizati (None, 512, 34, 60)  2048        block_4b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 512, 34, 60)  0           block_4b_bn_2[0][0]              \n",
      "                                                                 block_4a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_relu (Activation)      (None, 512, 34, 60)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "output_bbox (Conv2D)            (None, 12, 34, 60)   6156        block_4b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "output_cov (Conv2D)             (None, 3, 34, 60)    1539        block_4b_relu[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 11,203,023\n",
      "Trainable params: 11,193,295\n",
      "Non-trainable params: 9,728\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-20 08:52:32.946919: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 08:52:32.947203: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce RTX 2060 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.68\n",
      "pciBusID: 0000:06:00.0\n",
      "2021-06-20 08:52:32.947240: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-06-20 08:52:32.947278: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2021-06-20 08:52:32.947292: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2021-06-20 08:52:32.947305: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2021-06-20 08:52:32.947316: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2021-06-20 08:52:32.947327: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2021-06-20 08:52:32.947338: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-06-20 08:52:32.947407: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 08:52:32.947674: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 08:52:32.947881: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
      "2021-06-20 08:52:32.959441: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-06-20 08:52:32.959461: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
      "2021-06-20 08:52:32.959475: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
      "2021-06-20 08:52:32.959635: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 08:52:32.960016: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 08:52:32.960309: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6266 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:06:00.0, compute capability: 7.5)\n",
      "2021-06-20 08:52:34,066 [INFO] iva.detectnet_v2.evaluation.evaluation: step 0 / 18, 0.00s/step\n",
      "2021-06-20 08:52:34.505215: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2021-06-20 08:52:34.518983: I tensorflow/core/kernels/cuda_solvers.cc:159] Creating CudaSolver handles for stream 0x8f42720\n",
      "2021-06-20 08:52:34.519334: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2021-06-20 08:52:35.020861: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-06-20 08:52:35.146487: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2021-06-20 08:52:39,346 [INFO] iva.detectnet_v2.evaluation.evaluation: step 10 / 18, 0.53s/step\n",
      "Matching predictions to ground truth, class 1/3.: 100%|| 510/510 [00:00<00:00, 25101.15it/s]\n",
      "Matching predictions to ground truth, class 2/3.: 100%|| 1696/1696 [00:00<00:00, 24499.71it/s]\n",
      "Matching predictions to ground truth, class 3/3.: 100%|| 239/239 [00:00<00:00, 20851.56it/s]\n",
      "\n",
      "Validation cost: 0.000624\n",
      "Mean average_precision (in %): 69.8310\n",
      "\n",
      "class name               average precision (in %)\n",
      "---------------------  --------------------------\n",
      "helmet                                    85.9246\n",
      "person_with_helmet                        70.552\n",
      "person_without_helmet                     53.0164\n",
      "\n",
      "Median Inference Time: 0.010154\n",
      "2021-06-20 08:52:41,054 [INFO] iva.detectnet_v2.scripts.evaluate: Evaluation complete.\n",
      "Time taken to run iva.detectnet_v2.scripts.evaluate:main: 0:00:12.163243.\n"
     ]
    }
   ],
   "source": [
    "!tlt-evaluate detectnet_v2 -e $SPECS_DIR/detectnet_v2_train_resnet18_kitti.txt\\\n",
    "                           -m $USER_EXPERIMENT_DIR/experiment_dir_unpruned/weights/resnet18_detector_hemlet.tlt \\\n",
    "                           -k $KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prune the trained model <a class=\"anchor\" id=\"head-5\"></a>\n",
    "* Specify pre-trained model\n",
    "* Equalization criterion (`Applicable for resnets and mobilenets`)\n",
    "* Threshold for pruning.\n",
    "* A key to save and load the model\n",
    "* Output directory to store the model\n",
    "\n",
    "*Usually, you just need to adjust `-pth` (threshold) for accuracy and model size trade off. Higher `pth` gives you smaller model (and thus higher inference speed) but worse accuracy. The threshold to use is depend on the dataset. A pth value `5.2e-6` is just a start point. If the retrain accuracy is good, you can increase this value to get smaller models. Otherwise, lower this value to get better accuracy.*\n",
    "\n",
    "*For some internal studies, we have noticed that a pth value of 0.01 is a good starting point for detectnet_v2 models.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an output directory if it doesn't exist.\n",
    "!mkdir -p $USER_EXPERIMENT_DIR/experiment_dir_pruned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change Threshold (-pth) value according to you experiments\n",
      "2021-06-20 10:50:12.982088: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "Using TensorFlow backend.\n",
      "2021-06-20 10:50:16.009248: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-06-20 10:50:16.032459: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 10:50:16.032837: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce RTX 2060 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.68\n",
      "pciBusID: 0000:06:00.0\n",
      "2021-06-20 10:50:16.032856: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-06-20 10:50:16.033686: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2021-06-20 10:50:16.034442: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2021-06-20 10:50:16.034609: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2021-06-20 10:50:16.035503: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2021-06-20 10:50:16.036196: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2021-06-20 10:50:16.038409: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-06-20 10:50:16.038552: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 10:50:16.038963: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 10:50:16.039297: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
      "2021-06-20 10:50:16.039321: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-06-20 10:50:16.501397: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-06-20 10:50:16.501445: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
      "2021-06-20 10:50:16.501452: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
      "2021-06-20 10:50:16.501658: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 10:50:16.502039: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 10:50:16.502390: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 10:50:16.502712: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6343 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:06:00.0, compute capability: 7.5)\n",
      "2021-06-20 10:50:16,932 [INFO] modulus.pruning.pruning: Exploring graph for retainable indices\n",
      "2021-06-20 10:50:17,306 [INFO] modulus.pruning.pruning: Pruning model and appending pruned nodes to new graph\n",
      "2021-06-20 10:50:27,023 [INFO] iva.common.magnet_prune: Pruning ratio (pruned model / original model): 0.5489317481540473\n"
     ]
    }
   ],
   "source": [
    "print(\"Change Threshold (-pth) value according to you experiments\")\n",
    "\n",
    "!tlt-prune -m $USER_EXPERIMENT_DIR/experiment_dir_unpruned/weights/resnet18_detector_hemlet.tlt \\\n",
    "           -o $USER_EXPERIMENT_DIR/experiment_dir_pruned/resnet18_helmet_nopool_bn_detectnet_v2_pruned_0_2.tlt \\\n",
    "           -eq union \\\n",
    "           -pth 0.2 \\\n",
    "           -k $KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 113048\r\n",
      "-rwxrwxrwx 1 1000 1000 33069800 Jun 20 10:13 resnet18_helmet_nopool_bn_detectnet_v2_pruned.tlt\r\n",
      "-rwxrwxrwx 1 1000 1000 33069800 Jun 20 10:14 resnet18_helmet_nopool_bn_detectnet_v2_pruned_0.08.tlt\r\n",
      "-rwxrwxrwx 1 1000 1000 24807408 Jun 20 10:50 resnet18_helmet_nopool_bn_detectnet_v2_pruned_0_08.tlt\r\n",
      "-rwxrwxrwx 1 1000 1000 24807408 Jun 20 10:50 resnet18_helmet_nopool_bn_detectnet_v2_pruned_0_2.tlt\r\n"
     ]
    }
   ],
   "source": [
    "!ls -rlt $USER_EXPERIMENT_DIR/experiment_dir_pruned/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Retrain the pruned model <a class=\"anchor\" id=\"head-6\"></a>\n",
    "* Model needs to be re-trained to bring back accuracy after pruning\n",
    "* Specify re-training specification with pretrained weights as pruned model.\n",
    "\n",
    "*Note: For retraining, please set the `load_graph` option to `true` in the model_config to load the pruned model graph. Also, if after retraining, the model shows some decrease in mAP, it could be that the originally trained model, was pruned a little too much. Please try reducing the pruning threshold, thereby reducing the pruning ratio, and use the new model to retrain.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_seed: 42\r\n",
      "dataset_config {\r\n",
      "  data_sources {\r\n",
      "    tfrecords_path: \"/workspace/mntpt/helmet/data_fm_0916/tfrecords/kitti_trainval/*\"\r\n",
      "    image_directory_path: \"/workspace/mntpt/helmet\"\r\n",
      "  }\r\n",
      "  image_extension: \"jpg\"\r\n",
      "  target_class_mapping {\r\n",
      "    key: \"helmet\"\r\n",
      "    value: \"helmet\"\r\n",
      "  }\r\n",
      "  target_class_mapping {\r\n",
      "    key: \"person_with_helmet\"\r\n",
      "    value: \"person_with_helmet\"\r\n",
      "  }\r\n",
      "  target_class_mapping {\r\n",
      "    key: \"person_without_helmet\"\r\n",
      "    value: \"person_without_helmet\"\r\n",
      "  }\r\n",
      "  validation_fold: 0\r\n",
      "  #validation_data_source: {\r\n",
      "    #tfrecords_path: \"/home/data/tfrecords/kitti_val/*\"\r\n",
      "    #image_directory_path: \"/home/data/test\"\r\n",
      "  #}\r\n",
      "}\r\n",
      "\r\n",
      "\r\n",
      "augmentation_config {\r\n",
      "  preprocessing {\r\n",
      "    output_image_width: 960\r\n",
      "    output_image_height: 544\r\n",
      "    min_bbox_width: 1.0\r\n",
      "    min_bbox_height: 1.0\r\n",
      "    output_image_channel: 3\r\n",
      "  }\r\n",
      "  spatial_augmentation {\r\n",
      "    hflip_probability: 0.5\r\n",
      "    vflip_probability: 0.0\r\n",
      "    zoom_min: 1.0\r\n",
      "    zoom_max: 1.0\r\n",
      "    translate_max_x: 8.0\r\n",
      "    translate_max_y: 8.0\r\n",
      "  }\r\n",
      "  color_augmentation {\r\n",
      "    hue_rotation_max: 25.0\r\n",
      "    saturation_shift_max: 0.20000000298\r\n",
      "    contrast_scale_max: 0.10000000149\r\n",
      "    contrast_center: 0.5\r\n",
      "  }\r\n",
      "}\r\n",
      "\r\n",
      "postprocessing_config {\r\n",
      "  target_class_config {\r\n",
      "    key: \"helmet\"\r\n",
      "    value {\r\n",
      "      clustering_config {\r\n",
      "        coverage_threshold: 0.00499999988824\r\n",
      "        dbscan_eps: 0.20000000298\r\n",
      "        dbscan_min_samples: 0.0500000007451\r\n",
      "        minimum_bounding_box_height: 20\r\n",
      "      }\r\n",
      "    }\r\n",
      "  }\r\n",
      "  target_class_config {\r\n",
      "    key: \"person_with_helmet\"\r\n",
      "    value {\r\n",
      "      clustering_config {\r\n",
      "        coverage_threshold: 0.00499999988824\r\n",
      "        dbscan_eps: 0.20000000298\r\n",
      "        dbscan_min_samples: 0.0500000007451\r\n",
      "        minimum_bounding_box_height: 20\r\n",
      "      }\r\n",
      "    }\r\n",
      "  }\r\n",
      "  target_class_config {\r\n",
      "    key: \"person_without_helmet\"\r\n",
      "    value {\r\n",
      "      clustering_config {\r\n",
      "        coverage_threshold: 0.00499999988824\r\n",
      "        dbscan_eps: 0.15000000596\r\n",
      "        dbscan_min_samples: 0.0500000007451\r\n",
      "        minimum_bounding_box_height: 20\r\n",
      "      }\r\n",
      "    }\r\n",
      "  }\r\n",
      "}\r\n",
      "\r\n",
      "model_config {\r\n",
      "  pretrained_model_file: \"/workspace/mntpt/helmet/detectnet_v2/experiment_dir_pruned/resnet18_helmet_nopool_bn_detectnet_v2_pruned_0_2.tlt\"\r\n",
      "  num_layers: 18\r\n",
      "  use_batch_norm: true\r\n",
      "  load_graph: true\r\n",
      "  objective_set {\r\n",
      "    bbox {\r\n",
      "      scale: 35.0\r\n",
      "      offset: 0.5\r\n",
      "    }\r\n",
      "    cov {\r\n",
      "    }\r\n",
      "  }\r\n",
      "  training_precision {\r\n",
      "    backend_floatx: FLOAT32\r\n",
      "  }\r\n",
      "  arch: \"resnet\"\r\n",
      "}\r\n",
      "\r\n",
      "evaluation_config {\r\n",
      "  validation_period_during_training: 10\r\n",
      "  first_validation_epoch: 10\r\n",
      "  minimum_detection_ground_truth_overlap {\r\n",
      "    key: \"helmet\"\r\n",
      "    value: 0.5\r\n",
      "  }\r\n",
      "  minimum_detection_ground_truth_overlap {\r\n",
      "    key: \"person_with_helmet\"\r\n",
      "    value: 0.5\r\n",
      "  }\r\n",
      "  minimum_detection_ground_truth_overlap {\r\n",
      "    key: \"person_without_helmet\"\r\n",
      "    value: 0.5\r\n",
      "  }\r\n",
      "  evaluation_box_config {\r\n",
      "    key: \"helmet\"\r\n",
      "    value {\r\n",
      "      minimum_height: 20\r\n",
      "      maximum_height: 9999\r\n",
      "      minimum_width: 10\r\n",
      "      maximum_width: 9999\r\n",
      "    }\r\n",
      "  }\r\n",
      "  evaluation_box_config {\r\n",
      "    key: \"person_with_helmet\"\r\n",
      "    value {\r\n",
      "      minimum_height: 20\r\n",
      "      maximum_height: 9999\r\n",
      "      minimum_width: 10\r\n",
      "      maximum_width: 9999\r\n",
      "    }\r\n",
      "  }\r\n",
      "  evaluation_box_config {\r\n",
      "    key: \"person_without_helmet\"\r\n",
      "    value {\r\n",
      "      minimum_height: 20\r\n",
      "      maximum_height: 9999\r\n",
      "      minimum_width: 10\r\n",
      "      maximum_width: 9999\r\n",
      "    }\r\n",
      "  }\r\n",
      "  average_precision_mode: INTEGRATE\r\n",
      "}\r\n",
      "\r\n",
      "cost_function_config {\r\n",
      "  target_classes {\r\n",
      "    name: \"helmet\"\r\n",
      "    class_weight: 1.0\r\n",
      "    coverage_foreground_weight: 0.0500000007451\r\n",
      "    objectives {\r\n",
      "      name: \"cov\"\r\n",
      "      initial_weight: 1.0\r\n",
      "      weight_target: 1.0\r\n",
      "    }\r\n",
      "    objectives {\r\n",
      "      name: \"bbox\"\r\n",
      "      initial_weight: 10.0\r\n",
      "      weight_target: 10.0\r\n",
      "    }\r\n",
      "  }\r\n",
      "  target_classes {\r\n",
      "    name: \"person_with_helmet\"\r\n",
      "    class_weight: 1.0\r\n",
      "    coverage_foreground_weight: 0.0500000007451\r\n",
      "    objectives {\r\n",
      "      name: \"cov\"\r\n",
      "      initial_weight: 1.0\r\n",
      "      weight_target: 1.0\r\n",
      "    }\r\n",
      "    objectives {\r\n",
      "      name: \"bbox\"\r\n",
      "      initial_weight: 10.0\r\n",
      "      weight_target: 10.0\r\n",
      "    }\r\n",
      "  }\r\n",
      "  target_classes {\r\n",
      "    name: \"person_without_helmet\"\r\n",
      "    class_weight: 8.0\r\n",
      "    coverage_foreground_weight: 0.0500000007451\r\n",
      "    objectives {\r\n",
      "      name: \"cov\"\r\n",
      "      initial_weight: 1.0\r\n",
      "      weight_target: 1.0\r\n",
      "    }\r\n",
      "    objectives {\r\n",
      "      name: \"bbox\"\r\n",
      "      initial_weight: 10.0\r\n",
      "      weight_target: 1.0\r\n",
      "    }\r\n",
      "  }\r\n",
      "  enable_autoweighting: true\r\n",
      "  max_objective_weight: 0.999899983406\r\n",
      "  min_objective_weight: 9.99999974738e-05\r\n",
      "}\r\n",
      "\r\n",
      "training_config {\r\n",
      "  batch_size_per_gpu: 14\r\n",
      "  num_epochs: 200\r\n",
      "  learning_rate {\r\n",
      "    soft_start_annealing_schedule {\r\n",
      "      min_learning_rate: 5e-06\r\n",
      "      max_learning_rate: 5e-04\r\n",
      "      soft_start: 0.10000000149\r\n",
      "      annealing: 0.699999988079\r\n",
      "    }\r\n",
      "  }\r\n",
      "  regularizer {\r\n",
      "    type: L1\r\n",
      "    weight: 3.00000002618e-09\r\n",
      "  }\r\n",
      "  optimizer {\r\n",
      "    adam {\r\n",
      "      epsilon: 9.99999993923e-09\r\n",
      "      beta1: 0.899999976158\r\n",
      "      beta2: 0.999000012875\r\n",
      "    }\r\n",
      "  }\r\n",
      "  cost_scaling {\r\n",
      "    initial_exponent: 20.0\r\n",
      "    increment: 0.005\r\n",
      "    decrement: 1.0\r\n",
      "  }\r\n",
      "  checkpoint_interval: 30\r\n",
      "}\r\n",
      "\r\n",
      "bbox_rasterizer_config {\r\n",
      "  target_class_config {\r\n",
      "    key: \"helmet\"\r\n",
      "    value {\r\n",
      "      cov_center_x: 0.5\r\n",
      "      cov_center_y: 0.5\r\n",
      "      cov_radius_x: 0.40000000596\r\n",
      "      cov_radius_y: 0.40000000596\r\n",
      "      bbox_min_radius: 1.0\r\n",
      "    }\r\n",
      "  }\r\n",
      "  target_class_config {\r\n",
      "    key: \"person_with_helmet\"\r\n",
      "    value {\r\n",
      "      cov_center_x: 0.5\r\n",
      "      cov_center_y: 0.5\r\n",
      "      cov_radius_x: 1.0\r\n",
      "      cov_radius_y: 1.0\r\n",
      "      bbox_min_radius: 1.0\r\n",
      "    }\r\n",
      "  }\r\n",
      "  target_class_config {\r\n",
      "    key: \"person_without_helmet\"\r\n",
      "    value {\r\n",
      "      cov_center_x: 0.5\r\n",
      "      cov_center_y: 0.5\r\n",
      "      cov_radius_x: 0.40000000596\r\n",
      "      cov_radius_y: 0.40000000596\r\n",
      "      bbox_min_radius: 1.0\r\n",
      "    }\r\n",
      "  }\r\n",
      "  deadzone_radius: 0.400000154972\r\n",
      "}\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# Printing the retrain experiment file. \n",
    "# Note: We have updated the experiment file to include the \n",
    "# newly pruned model as a pretrained weights and, the\n",
    "# load_graph option is set to true \n",
    "!cat $SPECS_DIR/detectnet_v2_retrain_resnet18_kitti.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "2021-06-20 10:53:56.764978: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-06-20 10:53:58.782128: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-06-20 10:53:58.808635: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 10:53:58.809032: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce RTX 2060 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.68\n",
      "pciBusID: 0000:06:00.0\n",
      "2021-06-20 10:53:58.809051: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-06-20 10:53:58.809084: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2021-06-20 10:53:58.809964: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2021-06-20 10:53:58.810151: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2021-06-20 10:53:58.811040: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2021-06-20 10:53:58.811699: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2021-06-20 10:53:58.811734: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-06-20 10:53:58.811826: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 10:53:58.812232: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 10:53:58.812615: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
      "2021-06-20 10:53:58.812644: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-06-20 10:53:59.446352: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-06-20 10:53:59.446401: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
      "2021-06-20 10:53:59.446409: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
      "2021-06-20 10:53:59.446652: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 10:53:59.447040: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 10:53:59.447398: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 10:53:59.447717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6237 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:06:00.0, compute capability: 7.5)\n",
      "2021-06-20 10:53:59,448 [INFO] iva.detectnet_v2.scripts.train: Loading experiment spec at helmet/detectnet_v2/tlt_specs/detectnet_v2_retrain_resnet18_kitti.txt.\n",
      "2021-06-20 10:53:59,449 [INFO] iva.detectnet_v2.spec_handler.spec_loader: Merging specification from helmet/detectnet_v2/tlt_specs/detectnet_v2_retrain_resnet18_kitti.txt\n",
      "2021-06-20 10:53:59,649 [INFO] iva.detectnet_v2.scripts.train: Cannot iterate over exactly 988 samples with a batch size of 14; each epoch will therefore take one extra step.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 3, 544, 960)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 64, 272, 480) 9472        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 64, 272, 480) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 64, 272, 480) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_conv_1 (Conv2D)        (None, 64, 136, 240) 36928       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_1 (BatchNormalizati (None, 64, 136, 240) 256         block_1a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_relu_1 (Activation)    (None, 64, 136, 240) 0           block_1a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_conv_2 (Conv2D)        (None, 64, 136, 240) 36928       block_1a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_conv_shortcut (Conv2D) (None, 64, 136, 240) 4160        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_2 (BatchNormalizati (None, 64, 136, 240) 256         block_1a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_shortcut (BatchNorm (None, 64, 136, 240) 256         block_1a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 64, 136, 240) 0           block_1a_bn_2[0][0]              \n",
      "                                                                 block_1a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_relu (Activation)      (None, 64, 136, 240) 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_conv_1 (Conv2D)        (None, 64, 136, 240) 36928       block_1a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_bn_1 (BatchNormalizati (None, 64, 136, 240) 256         block_1b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_relu_1 (Activation)    (None, 64, 136, 240) 0           block_1b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_conv_2 (Conv2D)        (None, 64, 136, 240) 36928       block_1b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_bn_2 (BatchNormalizati (None, 64, 136, 240) 256         block_1b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 64, 136, 240) 0           block_1b_bn_2[0][0]              \n",
      "                                                                 block_1a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_relu (Activation)      (None, 64, 136, 240) 0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_conv_1 (Conv2D)        (None, 128, 68, 120) 73856       block_1b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_1 (BatchNormalizati (None, 128, 68, 120) 512         block_2a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_relu_1 (Activation)    (None, 128, 68, 120) 0           block_2a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_conv_2 (Conv2D)        (None, 128, 68, 120) 147584      block_2a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_conv_shortcut (Conv2D) (None, 128, 68, 120) 8320        block_1b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_2 (BatchNormalizati (None, 128, 68, 120) 512         block_2a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_shortcut (BatchNorm (None, 128, 68, 120) 512         block_2a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 128, 68, 120) 0           block_2a_bn_2[0][0]              \n",
      "                                                                 block_2a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_relu (Activation)      (None, 128, 68, 120) 0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_conv_1 (Conv2D)        (None, 128, 68, 120) 147584      block_2a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_bn_1 (BatchNormalizati (None, 128, 68, 120) 512         block_2b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_relu_1 (Activation)    (None, 128, 68, 120) 0           block_2b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_conv_2 (Conv2D)        (None, 128, 68, 120) 147584      block_2b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_bn_2 (BatchNormalizati (None, 128, 68, 120) 512         block_2b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 128, 68, 120) 0           block_2b_bn_2[0][0]              \n",
      "                                                                 block_2a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_relu (Activation)      (None, 128, 68, 120) 0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_conv_1 (Conv2D)        (None, 256, 34, 60)  295168      block_2b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_1 (BatchNormalizati (None, 256, 34, 60)  1024        block_3a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_relu_1 (Activation)    (None, 256, 34, 60)  0           block_3a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_conv_2 (Conv2D)        (None, 256, 34, 60)  590080      block_3a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_conv_shortcut (Conv2D) (None, 256, 34, 60)  33024       block_2b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_2 (BatchNormalizati (None, 256, 34, 60)  1024        block_3a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_shortcut (BatchNorm (None, 256, 34, 60)  1024        block_3a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 256, 34, 60)  0           block_3a_bn_2[0][0]              \n",
      "                                                                 block_3a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_relu (Activation)      (None, 256, 34, 60)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_conv_1 (Conv2D)        (None, 248, 34, 60)  571640      block_3a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_bn_1 (BatchNormalizati (None, 248, 34, 60)  992         block_3b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_relu_1 (Activation)    (None, 248, 34, 60)  0           block_3b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_conv_2 (Conv2D)        (None, 256, 34, 60)  571648      block_3b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_bn_2 (BatchNormalizati (None, 256, 34, 60)  1024        block_3b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 256, 34, 60)  0           block_3b_bn_2[0][0]              \n",
      "                                                                 block_3a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_relu (Activation)      (None, 256, 34, 60)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_conv_1 (Conv2D)        (None, 352, 34, 60)  811360      block_3b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_bn_1 (BatchNormalizati (None, 352, 34, 60)  1408        block_4a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_relu_1 (Activation)    (None, 352, 34, 60)  0           block_4a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_conv_2 (Conv2D)        (None, 512, 34, 60)  1622528     block_4a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_conv_shortcut (Conv2D) (None, 512, 34, 60)  131584      block_3b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_bn_2 (BatchNormalizati (None, 512, 34, 60)  2048        block_4a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_bn_shortcut (BatchNorm (None, 512, 34, 60)  2048        block_4a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 512, 34, 60)  0           block_4a_bn_2[0][0]              \n",
      "                                                                 block_4a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_relu (Activation)      (None, 512, 34, 60)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_conv_1 (Conv2D)        (None, 88, 34, 60)   405592      block_4a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_bn_1 (BatchNormalizati (None, 88, 34, 60)   352         block_4b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_relu_1 (Activation)    (None, 88, 34, 60)   0           block_4b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_conv_2 (Conv2D)        (None, 512, 34, 60)  406016      block_4b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_bn_2 (BatchNormalizati (None, 512, 34, 60)  2048        block_4b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 512, 34, 60)  0           block_4b_bn_2[0][0]              \n",
      "                                                                 block_4a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_relu (Activation)      (None, 512, 34, 60)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "output_bbox (Conv2D)            (None, 12, 34, 60)   6156        block_4b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "output_cov (Conv2D)             (None, 3, 34, 60)    1539        block_4b_relu[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 6,149,695\n",
      "Trainable params: 6,141,151\n",
      "Non-trainable params: 8,544\n",
      "__________________________________________________________________________________________________\n",
      "2021-06-20 10:54:01,864 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: Serial augmentation enabled = False\n",
      "2021-06-20 10:54:01,864 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: Pseudo sharding enabled = False\n",
      "2021-06-20 10:54:01,864 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: Max Image Dimensions (all sources): (0, 0)\n",
      "2021-06-20 10:54:01,865 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: number of cpus: 16, io threads: 32, compute threads: 16, buffered batches: 4\n",
      "2021-06-20 10:54:01,865 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: total dataset size 988, number of sources: 1, batch size per gpu: 14, steps: 71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-20 10:54:01,947 [INFO] iva.detectnet_v2.dataloader.default_dataloader: Bounding box coordinates were detected in the input specification! Bboxes will be automatically converted to polygon coordinates.\n",
      "2021-06-20 10:54:01.969911: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 10:54:01.970291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce RTX 2060 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.68\n",
      "pciBusID: 0000:06:00.0\n",
      "2021-06-20 10:54:01.970309: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-06-20 10:54:01.970333: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2021-06-20 10:54:01.970350: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2021-06-20 10:54:01.970364: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2021-06-20 10:54:01.970377: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2021-06-20 10:54:01.970390: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2021-06-20 10:54:01.970402: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-06-20 10:54:01.970470: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 10:54:01.970825: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 10:54:01.971126: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
      "2021-06-20 10:54:02,124 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: shuffle: True - shard 0 of 1\n",
      "2021-06-20 10:54:02,129 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: sampling 1 datasets with weights:\n",
      "2021-06-20 10:54:02,129 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: source: 0 weight: 1.000000\n",
      "2021-06-20 10:54:02,479 [INFO] iva.detectnet_v2.scripts.train: Found 988 samples in training set\n",
      "2021-06-20 10:54:04,217 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: Serial augmentation enabled = False\n",
      "2021-06-20 10:54:04,217 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: Pseudo sharding enabled = False\n",
      "2021-06-20 10:54:04,217 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: Max Image Dimensions (all sources): (0, 0)\n",
      "2021-06-20 10:54:04,217 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: number of cpus: 16, io threads: 32, compute threads: 16, buffered batches: 4\n",
      "2021-06-20 10:54:04,217 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: total dataset size 247, number of sources: 1, batch size per gpu: 14, steps: 18\n",
      "2021-06-20 10:54:04,240 [INFO] iva.detectnet_v2.dataloader.default_dataloader: Bounding box coordinates were detected in the input specification! Bboxes will be automatically converted to polygon coordinates.\n",
      "2021-06-20 10:54:04,406 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: shuffle: False - shard 0 of 1\n",
      "2021-06-20 10:54:04,410 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: sampling 1 datasets with weights:\n",
      "2021-06-20 10:54:04,410 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: source: 0 weight: 1.000000\n",
      "2021-06-20 10:54:04,643 [INFO] iva.detectnet_v2.scripts.train: Found 247 samples in validation set\n",
      "2021-06-20 10:54:06.938934: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 10:54:06.939325: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce RTX 2060 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.68\n",
      "pciBusID: 0000:06:00.0\n",
      "2021-06-20 10:54:06.939353: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-06-20 10:54:06.939387: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2021-06-20 10:54:06.939413: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2021-06-20 10:54:06.939428: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2021-06-20 10:54:06.939442: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2021-06-20 10:54:06.939455: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2021-06-20 10:54:06.939467: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-06-20 10:54:06.939534: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 10:54:06.939888: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 10:54:06.940185: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
      "2021-06-20 10:54:06.941127: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-06-20 10:54:06.941138: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
      "2021-06-20 10:54:06.941143: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
      "2021-06-20 10:54:06.941237: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 10:54:06.941597: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 10:54:06.941902: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6237 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:06:00.0, compute capability: 7.5)\n",
      "2021-06-20 10:54:27.079728: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2021-06-20 10:54:27.590015: I tensorflow/core/kernels/cuda_solvers.cc:159] Creating CudaSolver handles for stream 0x25805a60\n",
      "2021-06-20 10:54:27.590153: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2021-06-20 10:54:27.744736: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2021-06-20 10:54:27.748523: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-06-20 10:54:28.985884: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.47GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-06-20 10:54:28.985932: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.47GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-20 10:54:29.169028: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-06-20 10:54:29.169084: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-06-20 10:54:29.307776: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.19GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-06-20 10:54:29.307816: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.19GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-06-20 10:54:29.385849: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.13GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-06-20 10:54:29.385887: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.13GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-06-20 10:54:29.460978: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.12GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-06-20 10:54:29.461015: W tensorflow/core/common_runtime/bfc_allocator.cc:239] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.12GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2021-06-20 10:54:32,158 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 0/200: loss: 0.00040 Time taken: 0:00:00 ETA: 0:00:00\n",
      "2021-06-20 10:54:32,158 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 2.238\n",
      "2021-06-20 10:54:44,150 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 19.180\n",
      "2021-06-20 10:54:53,195 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 38.698\n",
      "2021-06-20 10:55:01,329 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 1/200: loss: 0.00020 Time taken: 0:00:35.070058 ETA: 1:56:18.941611\n",
      "2021-06-20 10:55:02,427 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.910\n",
      "2021-06-20 10:55:11,487 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 38.633\n",
      "2021-06-20 10:55:20,562 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 38.570\n",
      "2021-06-20 10:55:27,137 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 2/200: loss: 0.00022 Time taken: 0:00:25.803806 ETA: 1:25:09.153648\n",
      "2021-06-20 10:55:29,680 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 38.388\n",
      "2021-06-20 10:55:38,785 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 38.441\n",
      "2021-06-20 10:55:47,971 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 38.103\n",
      "2021-06-20 10:55:53,096 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 3/200: loss: 0.00024 Time taken: 0:00:25.947965 ETA: 1:25:11.749040\n",
      "2021-06-20 10:55:57,133 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 38.204\n",
      "2021-06-20 10:56:06,274 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 38.288\n",
      "2021-06-20 10:56:15,465 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 38.082\n",
      "2021-06-20 10:56:19,156 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 4/200: loss: 0.00018 Time taken: 0:00:26.065371 ETA: 1:25:08.812630\n",
      "2021-06-20 10:56:24,682 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.977\n",
      "2021-06-20 10:56:33,892 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 38.001\n",
      "2021-06-20 10:56:43,098 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 38.021\n",
      "2021-06-20 10:56:45,313 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 5/200: loss: 0.00022 Time taken: 0:00:26.151243 ETA: 1:24:59.492472\n",
      "2021-06-20 10:56:52,337 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.884\n",
      "2021-06-20 10:57:01,627 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.674\n",
      "2021-06-20 10:57:10,832 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 38.026\n",
      "2021-06-20 10:57:11,586 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 6/200: loss: 0.00018 Time taken: 0:00:26.262427 ETA: 1:24:54.910856\n",
      "2021-06-20 10:57:20,039 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 38.018\n",
      "2021-06-20 10:57:29,270 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.917\n",
      "2021-06-20 10:57:37,751 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 7/200: loss: 0.00018 Time taken: 0:00:26.176889 ETA: 1:24:12.139658\n",
      "2021-06-20 10:57:38,523 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.825\n",
      "2021-06-20 10:57:47,744 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.959\n",
      "2021-06-20 10:57:56,992 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.845\n",
      "2021-06-20 10:58:04,034 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 8/200: loss: 0.00018 Time taken: 0:00:26.274960 ETA: 1:24:04.792328\n",
      "2021-06-20 10:58:06,241 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.844\n",
      "2021-06-20 10:58:15,511 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.759\n",
      "2021-06-20 10:58:24,760 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.841\n",
      "2021-06-20 10:58:30,309 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 9/200: loss: 0.00017 Time taken: 0:00:26.281544 ETA: 1:23:39.774898\n",
      "2021-06-20 10:58:34,007 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.852\n",
      "2021-06-20 10:58:43,296 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.681\n",
      "2021-06-20 10:58:52,559 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.785\n",
      "2021-06-20 10:58:56,318 [INFO] iva.detectnet_v2.evaluation.evaluation: step 0 / 17, 0.00s/step\n",
      "2021-06-20 10:58:58,862 [INFO] iva.detectnet_v2.evaluation.evaluation: step 10 / 17, 0.25s/step\n",
      "Matching predictions to ground truth, class 1/3.: 100%|| 556/556 [00:00<00:00, 25706.40it/s]\n",
      "Matching predictions to ground truth, class 2/3.: 100%|| 1759/1759 [00:00<00:00, 24504.79it/s]\n",
      "Matching predictions to ground truth, class 3/3.: 100%|| 245/245 [00:00<00:00, 20314.81it/s]\n",
      "Epoch 10/200\n",
      "=========================\n",
      "\n",
      "Validation cost: 0.000200\n",
      "Mean average_precision (in %): 68.5411\n",
      "\n",
      "class name               average precision (in %)\n",
      "---------------------  --------------------------\n",
      "helmet                                    86.0217\n",
      "person_with_helmet                        69.587\n",
      "person_without_helmet                     50.0146\n",
      "\n",
      "Median Inference Time: 0.008925\n",
      "2021-06-20 10:59:00,614 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 10/200: loss: 0.00016 Time taken: 0:00:30.300069 ETA: 1:35:57.013128\n",
      "2021-06-20 10:59:05,776 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 26.482\n",
      "2021-06-20 10:59:15,033 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-20 10:59:24,343 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.597\n",
      "2021-06-20 10:59:26,950 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 11/200: loss: 0.00022 Time taken: 0:00:26.336499 ETA: 1:22:57.598261\n",
      "2021-06-20 10:59:33,591 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.850\n",
      "2021-06-20 10:59:42,898 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.607\n",
      "2021-06-20 10:59:52,190 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.668\n",
      "2021-06-20 10:59:53,328 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 12/200: loss: 0.00019 Time taken: 0:00:26.372595 ETA: 1:22:38.047784\n",
      "2021-06-20 11:00:01,513 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.541\n",
      "2021-06-20 11:00:10,836 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.543\n",
      "2021-06-20 11:00:19,724 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 13/200: loss: 0.00023 Time taken: 0:00:26.401579 ETA: 1:22:17.095299\n",
      "2021-06-20 11:00:20,099 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.788\n",
      "2021-06-20 11:00:29,428 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.517\n",
      "2021-06-20 11:00:38,675 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.853\n",
      "2021-06-20 11:00:46,158 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 14/200: loss: 0.00019 Time taken: 0:00:26.432006 ETA: 1:21:56.353138\n",
      "2021-06-20 11:00:48,017 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.465\n",
      "2021-06-20 11:00:57,359 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.464\n",
      "2021-06-20 11:01:06,654 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.656\n",
      "2021-06-20 11:01:12,583 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 15/200: loss: 0.00023 Time taken: 0:00:26.423230 ETA: 1:21:28.297538\n",
      "2021-06-20 11:01:15,957 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.623\n",
      "2021-06-20 11:01:25,187 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.922\n",
      "2021-06-20 11:01:34,516 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.519\n",
      "2021-06-20 11:01:39,004 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 16/200: loss: 0.00021 Time taken: 0:00:26.422048 ETA: 1:21:01.656761\n",
      "2021-06-20 11:01:43,854 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.481\n",
      "2021-06-20 11:01:53,117 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.789\n",
      "2021-06-20 11:02:02,354 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.891\n",
      "2021-06-20 11:02:05,330 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 17/200: loss: 0.00028 Time taken: 0:00:26.318057 ETA: 1:20:16.204486\n",
      "2021-06-20 11:02:11,677 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.542\n",
      "2021-06-20 11:02:20,971 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.662\n",
      "2021-06-20 11:02:30,285 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.578\n",
      "2021-06-20 11:02:31,807 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 18/200: loss: 0.00024 Time taken: 0:00:26.465746 ETA: 1:20:16.765802\n",
      "2021-06-20 11:02:39,574 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.679\n",
      "2021-06-20 11:02:48,868 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.661\n",
      "2021-06-20 11:02:58,261 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 19/200: loss: 0.00033 Time taken: 0:00:26.466565 ETA: 1:19:50.448246\n",
      "2021-06-20 11:02:58,261 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.262\n",
      "2021-06-20 11:03:07,515 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.823\n",
      "2021-06-20 11:03:16,763 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.846\n",
      "2021-06-20 11:03:24,210 [INFO] iva.detectnet_v2.evaluation.evaluation: step 0 / 17, 0.00s/step\n",
      "2021-06-20 11:03:26,580 [INFO] iva.detectnet_v2.evaluation.evaluation: step 10 / 17, 0.24s/step\n",
      "Matching predictions to ground truth, class 1/3.: 100%|| 2980/2980 [00:00<00:00, 35083.80it/s]\n",
      "Matching predictions to ground truth, class 2/3.: 100%|| 4906/4906 [00:00<00:00, 32808.70it/s]\n",
      "Matching predictions to ground truth, class 3/3.: 100%|| 400/400 [00:00<00:00, 20466.51it/s]\n",
      "Epoch 20/200\n",
      "=========================\n",
      "\n",
      "Validation cost: 0.000301\n",
      "Mean average_precision (in %): 41.3855\n",
      "\n",
      "class name               average precision (in %)\n",
      "---------------------  --------------------------\n",
      "helmet                                    57.7105\n",
      "person_with_helmet                        35.5341\n",
      "person_without_helmet                     30.9118\n",
      "\n",
      "Median Inference Time: 0.008896\n",
      "2021-06-20 11:03:28,924 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 20/200: loss: 0.00029 Time taken: 0:00:30.664526 ETA: 1:31:59.614763\n",
      "2021-06-20 11:03:30,408 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 25.651\n",
      "2021-06-20 11:03:39,697 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.678\n",
      "2021-06-20 11:03:48,969 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.752\n",
      "2021-06-20 11:03:55,270 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 21/200: loss: 0.00028 Time taken: 0:00:26.345813 ETA: 1:18:35.900576\n",
      "2021-06-20 11:03:58,253 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.698\n",
      "2021-06-20 11:04:07,504 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.837\n",
      "2021-06-20 11:04:16,748 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.862\n",
      "2021-06-20 11:04:21,689 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 22/200: loss: 0.00045 Time taken: 0:00:26.374247 ETA: 1:18:14.616022\n",
      "2021-06-20 11:04:26,318 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 36.575\n",
      "2021-06-20 11:04:35,682 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.379\n",
      "2021-06-20 11:04:44,973 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.670\n",
      "2021-06-20 11:04:48,304 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 23/200: loss: 0.00024 Time taken: 0:00:26.658164 ETA: 1:18:38.495075\n",
      "2021-06-20 11:04:54,293 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.556\n",
      "2021-06-20 11:05:03,543 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.841\n",
      "2021-06-20 11:05:12,831 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.684\n",
      "2021-06-20 11:05:14,707 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 24/200: loss: 0.00026 Time taken: 0:00:26.397364 ETA: 1:17:25.936047\n",
      "2021-06-20 11:05:22,133 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.626\n",
      "2021-06-20 11:05:31,425 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.671\n",
      "2021-06-20 11:05:40,771 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.450\n",
      "2021-06-20 11:05:41,153 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 25/200: loss: 0.00022 Time taken: 0:00:26.435509 ETA: 1:17:06.214111\n",
      "2021-06-20 11:05:50,026 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.822\n",
      "2021-06-20 11:05:59,282 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.814\n",
      "2021-06-20 11:06:07,448 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 26/200: loss: 0.00023 Time taken: 0:00:26.306877 ETA: 1:16:17.396539\n",
      "2021-06-20 11:06:08,565 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.703\n",
      "2021-06-20 11:06:17,853 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.685\n",
      "2021-06-20 11:06:27,122 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-20 11:06:33,744 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 27/200: loss: 0.00023 Time taken: 0:00:26.298421 ETA: 1:15:49.626899\n",
      "2021-06-20 11:06:36,373 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.837\n",
      "2021-06-20 11:06:45,628 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.818\n",
      "2021-06-20 11:06:54,898 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.754\n",
      "2021-06-20 11:07:00,091 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 28/200: loss: 0.00019 Time taken: 0:00:26.340239 ETA: 1:15:30.521116\n",
      "2021-06-20 11:07:04,165 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.772\n",
      "2021-06-20 11:07:13,472 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.605\n",
      "2021-06-20 11:07:22,784 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.589\n",
      "2021-06-20 11:07:26,474 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 29/200: loss: 0.00021 Time taken: 0:00:26.381826 ETA: 1:15:11.292233\n",
      "2021-06-20 11:07:32,050 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.775\n",
      "2021-06-20 11:07:41,358 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.602\n",
      "2021-06-20 11:07:50,634 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.736\n",
      "2021-06-20 11:07:56,294 [INFO] iva.detectnet_v2.evaluation.evaluation: step 0 / 17, 0.00s/step\n",
      "2021-06-20 11:07:58,225 [INFO] iva.detectnet_v2.evaluation.evaluation: step 10 / 17, 0.19s/step\n",
      "Matching predictions to ground truth, class 1/3.: 100%|| 804/804 [00:00<00:00, 24982.93it/s]\n",
      "Matching predictions to ground truth, class 2/3.: 100%|| 4215/4215 [00:00<00:00, 25513.28it/s]\n",
      "Matching predictions to ground truth, class 3/3.: 100%|| 309/309 [00:00<00:00, 19194.34it/s]\n",
      "Epoch 30/200\n",
      "=========================\n",
      "\n",
      "Validation cost: 0.000229\n",
      "Mean average_precision (in %): 57.1447\n",
      "\n",
      "class name               average precision (in %)\n",
      "---------------------  --------------------------\n",
      "helmet                                    72.0664\n",
      "person_with_helmet                        57.4779\n",
      "person_without_helmet                     41.8899\n",
      "\n",
      "Median Inference Time: 0.009039\n",
      "2021-06-20 11:08:00,284 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 30/200: loss: 0.00022 Time taken: 0:00:33.781899 ETA: 1:35:42.922785\n",
      "2021-06-20 11:08:07,305 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 20.995\n",
      "2021-06-20 11:08:16,549 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.863\n",
      "2021-06-20 11:08:25,858 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.598\n",
      "2021-06-20 11:08:26,636 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 31/200: loss: 0.00020 Time taken: 0:00:26.379305 ETA: 1:14:18.102606\n",
      "2021-06-20 11:08:35,128 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.756\n",
      "2021-06-20 11:08:44,444 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.573\n",
      "2021-06-20 11:08:53,079 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 32/200: loss: 0.00022 Time taken: 0:00:26.419808 ETA: 1:13:58.527809\n",
      "2021-06-20 11:08:53,851 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.206\n",
      "2021-06-20 11:09:03,130 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.720\n",
      "2021-06-20 11:09:12,375 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.860\n",
      "2021-06-20 11:09:19,407 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 33/200: loss: 0.00027 Time taken: 0:00:26.345690 ETA: 1:13:19.730192\n",
      "2021-06-20 11:09:21,646 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.754\n",
      "2021-06-20 11:09:30,950 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.620\n",
      "2021-06-20 11:09:40,215 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.777\n",
      "2021-06-20 11:09:45,801 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 34/200: loss: 0.00019 Time taken: 0:00:26.395777 ETA: 1:13:01.698901\n",
      "2021-06-20 11:09:49,520 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.615\n",
      "2021-06-20 11:09:59,154 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 36.334\n",
      "2021-06-20 11:10:09,074 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 35.281\n",
      "2021-06-20 11:10:13,396 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 35/200: loss: 0.00021 Time taken: 0:00:27.584984 ETA: 1:15:51.522292\n",
      "2021-06-20 11:10:18,760 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 36.136\n",
      "2021-06-20 11:10:28,048 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.686\n",
      "2021-06-20 11:10:37,357 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.597\n",
      "2021-06-20 11:10:39,958 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 36/200: loss: 0.00017 Time taken: 0:00:26.574434 ETA: 1:12:38.207222\n",
      "2021-06-20 11:10:46,626 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.764\n",
      "2021-06-20 11:10:55,997 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.352\n",
      "2021-06-20 11:11:05,264 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.768\n",
      "2021-06-20 11:11:06,390 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 37/200: loss: 0.00019 Time taken: 0:00:26.429880 ETA: 1:11:48.070385\n",
      "2021-06-20 11:11:14,577 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.583\n",
      "2021-06-20 11:11:23,889 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.588\n",
      "2021-06-20 11:11:32,792 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 38/200: loss: 0.00021 Time taken: 0:00:26.402278 ETA: 1:11:17.169066\n",
      "2021-06-20 11:11:33,172 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.705\n",
      "2021-06-20 11:11:42,498 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.529\n",
      "2021-06-20 11:11:51,812 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.581\n",
      "2021-06-20 11:11:59,272 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 39/200: loss: 0.00023 Time taken: 0:00:26.479319 ETA: 1:11:03.170413\n",
      "2021-06-20 11:12:01,139 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.525\n",
      "2021-06-20 11:12:10,430 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.675\n",
      "2021-06-20 11:12:19,789 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.397\n",
      "2021-06-20 11:12:25,351 [INFO] iva.detectnet_v2.evaluation.evaluation: step 0 / 17, 0.00s/step\n",
      "2021-06-20 11:12:27,054 [INFO] iva.detectnet_v2.evaluation.evaluation: step 10 / 17, 0.17s/step\n",
      "Matching predictions to ground truth, class 1/3.: 100%|| 315/315 [00:00<00:00, 23142.91it/s]\n",
      "Matching predictions to ground truth, class 2/3.: 100%|| 781/781 [00:00<00:00, 28044.86it/s]\n",
      "Matching predictions to ground truth, class 3/3.: 100%|| 598/598 [00:00<00:00, 24575.44it/s]\n",
      "Epoch 40/200\n",
      "=========================\n",
      "\n",
      "Validation cost: 0.000227\n",
      "Mean average_precision (in %): 63.7708\n",
      "\n",
      "class name               average precision (in %)\n",
      "---------------------  --------------------------\n",
      "helmet                                    78.6892\n",
      "person_with_helmet                        63.0527\n",
      "person_without_helmet                     49.5705\n",
      "\n",
      "Median Inference Time: 0.009086\n",
      "2021-06-20 11:12:28,705 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 40/200: loss: 0.00016 Time taken: 0:00:29.429117 ETA: 1:18:28.658791\n",
      "2021-06-20 11:12:32,024 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 28.607\n",
      "2021-06-20 11:12:41,297 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.743\n",
      "2021-06-20 11:12:50,650 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.425\n",
      "2021-06-20 11:12:55,156 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 41/200: loss: 0.00021 Time taken: 0:00:26.425760 ETA: 1:10:01.695807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-20 11:12:59,976 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.532\n",
      "2021-06-20 11:13:09,292 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.570\n",
      "2021-06-20 11:13:18,554 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.788\n",
      "2021-06-20 11:13:21,547 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 42/200: loss: 0.00025 Time taken: 0:00:26.412624 ETA: 1:09:33.194649\n",
      "2021-06-20 11:13:27,859 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.618\n",
      "2021-06-20 11:13:37,165 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.610\n",
      "2021-06-20 11:13:46,425 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.797\n",
      "2021-06-20 11:13:47,944 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 43/200: loss: 0.00017 Time taken: 0:00:26.400221 ETA: 1:09:04.834639\n",
      "2021-06-20 11:13:55,778 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.426\n",
      "2021-06-20 11:14:05,045 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.767\n",
      "2021-06-20 11:14:14,338 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 44/200: loss: 0.00020 Time taken: 0:00:26.396031 ETA: 1:08:37.780821\n",
      "2021-06-20 11:14:14,338 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.665\n",
      "2021-06-20 11:14:23,642 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.620\n",
      "2021-06-20 11:14:32,915 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.745\n",
      "2021-06-20 11:14:40,777 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 45/200: loss: 0.00019 Time taken: 0:00:26.426682 ETA: 1:08:16.135709\n",
      "2021-06-20 11:14:42,269 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.416\n",
      "2021-06-20 11:14:51,585 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.574\n",
      "2021-06-20 11:15:00,927 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.467\n",
      "2021-06-20 11:15:07,221 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 46/200: loss: 0.00015 Time taken: 0:00:26.447719 ETA: 1:07:52.948778\n",
      "2021-06-20 11:15:10,176 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.842\n",
      "2021-06-20 11:15:19,504 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.522\n",
      "2021-06-20 11:15:28,742 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.887\n",
      "2021-06-20 11:15:33,596 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 47/200: loss: 0.00019 Time taken: 0:00:26.374734 ETA: 1:07:15.334291\n",
      "2021-06-20 11:15:38,061 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.560\n",
      "2021-06-20 11:15:47,295 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.907\n",
      "2021-06-20 11:15:56,601 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.609\n",
      "2021-06-20 11:15:59,978 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 48/200: loss: 0.00025 Time taken: 0:00:26.377418 ETA: 1:06:49.367579\n",
      "2021-06-20 11:16:05,925 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.540\n",
      "2021-06-20 11:16:15,198 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.743\n",
      "2021-06-20 11:16:24,502 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.623\n",
      "2021-06-20 11:16:26,411 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 49/200: loss: 0.00019 Time taken: 0:00:26.434424 ETA: 1:06:31.597976\n",
      "2021-06-20 11:16:33,811 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.597\n",
      "2021-06-20 11:16:43,061 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.839\n",
      "2021-06-20 11:16:52,339 [INFO] iva.detectnet_v2.evaluation.evaluation: step 0 / 17, 0.00s/step\n",
      "2021-06-20 11:16:54,173 [INFO] iva.detectnet_v2.evaluation.evaluation: step 10 / 17, 0.18s/step\n",
      "Matching predictions to ground truth, class 1/3.: 100%|| 545/545 [00:00<00:00, 27742.46it/s]\n",
      "Matching predictions to ground truth, class 2/3.: 100%|| 2307/2307 [00:00<00:00, 27946.44it/s]\n",
      "Matching predictions to ground truth, class 3/3.: 100%|| 930/930 [00:00<00:00, 24534.88it/s]\n",
      "Epoch 50/200\n",
      "=========================\n",
      "\n",
      "Validation cost: 0.000254\n",
      "Mean average_precision (in %): 56.2786\n",
      "\n",
      "class name               average precision (in %)\n",
      "---------------------  --------------------------\n",
      "helmet                                    83.5142\n",
      "person_with_helmet                        50.27\n",
      "person_without_helmet                     35.0518\n",
      "\n",
      "Median Inference Time: 0.009104\n",
      "2021-06-20 11:16:55,684 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 27.728\n",
      "2021-06-20 11:16:56,056 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 50/200: loss: 0.00017 Time taken: 0:00:29.646310 ETA: 1:14:06.946549\n",
      "2021-06-20 11:17:04,938 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.829\n",
      "2021-06-20 11:17:14,244 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.609\n",
      "2021-06-20 11:17:22,417 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 51/200: loss: 0.00021 Time taken: 0:00:26.358157 ETA: 1:05:27.365381\n",
      "2021-06-20 11:17:23,564 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.558\n",
      "2021-06-20 11:17:32,820 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.814\n",
      "2021-06-20 11:17:42,113 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.664\n",
      "2021-06-20 11:17:48,801 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 52/200: loss: 0.00016 Time taken: 0:00:26.387726 ETA: 1:05:05.383458\n",
      "2021-06-20 11:17:51,409 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.651\n",
      "2021-06-20 11:18:00,688 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.720\n",
      "2021-06-20 11:18:10,090 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.231\n",
      "2021-06-20 11:18:15,744 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 53/200: loss: 0.00024 Time taken: 0:00:26.901862 ETA: 1:05:54.573735\n",
      "2021-06-20 11:18:19,900 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 35.677\n",
      "2021-06-20 11:18:29,212 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.586\n",
      "2021-06-20 11:18:38,544 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.507\n",
      "2021-06-20 11:18:42,287 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 54/200: loss: 0.00019 Time taken: 0:00:26.582253 ETA: 1:04:41.008865\n",
      "2021-06-20 11:18:47,894 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.436\n",
      "2021-06-20 11:18:57,184 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.677\n",
      "2021-06-20 11:19:06,460 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.730\n",
      "2021-06-20 11:19:08,713 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 55/200: loss: 0.00020 Time taken: 0:00:26.427745 ETA: 1:03:52.022971\n",
      "2021-06-20 11:19:15,731 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.755\n",
      "2021-06-20 11:19:24,999 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.764\n",
      "2021-06-20 11:19:34,325 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.530\n",
      "2021-06-20 11:19:35,105 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 56/200: loss: 0.00021 Time taken: 0:00:26.378839 ETA: 1:03:18.552784\n",
      "2021-06-20 11:19:43,666 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.471\n",
      "2021-06-20 11:19:52,905 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.883\n",
      "2021-06-20 11:20:01,499 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 57/200: loss: 0.00020 Time taken: 0:00:26.404294 ETA: 1:02:55.813976\n",
      "2021-06-20 11:20:02,252 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-20 11:20:11,541 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.680\n",
      "2021-06-20 11:20:20,833 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.667\n",
      "2021-06-20 11:20:27,880 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 58/200: loss: 0.00020 Time taken: 0:00:26.373395 ETA: 1:02:25.022051\n",
      "2021-06-20 11:20:30,131 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.645\n",
      "2021-06-20 11:20:39,378 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.852\n",
      "2021-06-20 11:20:48,707 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.516\n",
      "2021-06-20 11:20:54,281 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 59/200: loss: 0.00014 Time taken: 0:00:26.401167 ETA: 1:02:02.564569\n",
      "2021-06-20 11:20:57,994 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.689\n",
      "2021-06-20 11:21:07,313 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.560\n",
      "2021-06-20 11:21:16,653 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.474\n",
      "2021-06-20 11:21:24,171 [INFO] iva.detectnet_v2.evaluation.evaluation: step 0 / 17, 0.00s/step\n",
      "2021-06-20 11:21:25,947 [INFO] iva.detectnet_v2.evaluation.evaluation: step 10 / 17, 0.18s/step\n",
      "Matching predictions to ground truth, class 1/3.: 100%|| 647/647 [00:00<00:00, 27188.81it/s]\n",
      "Matching predictions to ground truth, class 2/3.: 100%|| 1582/1582 [00:00<00:00, 26627.40it/s]\n",
      "Matching predictions to ground truth, class 3/3.: 100%|| 351/351 [00:00<00:00, 20073.37it/s]\n",
      "Epoch 60/200\n",
      "=========================\n",
      "\n",
      "Validation cost: 0.000213\n",
      "Mean average_precision (in %): 66.7190\n",
      "\n",
      "class name               average precision (in %)\n",
      "---------------------  --------------------------\n",
      "helmet                                    84.5825\n",
      "person_with_helmet                        68.444\n",
      "person_without_helmet                     47.1306\n",
      "\n",
      "Median Inference Time: 0.008926\n",
      "2021-06-20 11:21:27,716 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 60/200: loss: 0.00015 Time taken: 0:00:33.431966 ETA: 1:18:00.475283\n",
      "2021-06-20 11:21:32,931 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 21.502\n",
      "2021-06-20 11:21:42,203 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.750\n",
      "2021-06-20 11:21:51,452 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.842\n",
      "2021-06-20 11:21:54,063 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 61/200: loss: 0.00019 Time taken: 0:00:26.346861 ETA: 1:01:02.213696\n",
      "2021-06-20 11:22:00,733 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.712\n",
      "2021-06-20 11:22:10,020 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.692\n",
      "2021-06-20 11:22:19,269 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.843\n",
      "2021-06-20 11:22:20,423 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 62/200: loss: 0.00017 Time taken: 0:00:26.366821 ETA: 1:00:38.621305\n",
      "2021-06-20 11:22:28,535 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.773\n",
      "2021-06-20 11:22:37,790 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.816\n",
      "2021-06-20 11:22:46,717 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 63/200: loss: 0.00023 Time taken: 0:00:26.289316 ETA: 1:00:01.636349\n",
      "2021-06-20 11:22:47,115 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.536\n",
      "2021-06-20 11:22:56,398 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.704\n",
      "2021-06-20 11:23:05,601 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 38.033\n",
      "2021-06-20 11:23:13,005 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 64/200: loss: 0.00019 Time taken: 0:00:26.288434 ETA: 0:59:35.227060\n",
      "2021-06-20 11:23:14,885 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.702\n",
      "2021-06-20 11:23:24,135 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.837\n",
      "2021-06-20 11:23:33,460 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.538\n",
      "2021-06-20 11:23:39,414 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 65/200: loss: 0.00016 Time taken: 0:00:26.410036 ETA: 0:59:25.354872\n",
      "2021-06-20 11:23:42,734 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.742\n",
      "2021-06-20 11:23:52,008 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.738\n",
      "2021-06-20 11:24:01,251 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.870\n",
      "2021-06-20 11:24:05,720 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 66/200: loss: 0.00014 Time taken: 0:00:26.298620 ETA: 0:58:44.015110\n",
      "2021-06-20 11:24:10,529 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.724\n",
      "2021-06-20 11:24:19,805 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.735\n",
      "2021-06-20 11:24:29,088 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.703\n",
      "2021-06-20 11:24:32,076 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 67/200: loss: 0.00013 Time taken: 0:00:26.349267 ETA: 0:58:24.452575\n",
      "2021-06-20 11:24:38,367 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.722\n",
      "2021-06-20 11:24:47,643 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.730\n",
      "2021-06-20 11:24:56,976 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.506\n",
      "2021-06-20 11:24:58,459 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 68/200: loss: 0.00014 Time taken: 0:00:26.396755 ETA: 0:58:04.371689\n",
      "2021-06-20 11:25:06,239 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.785\n",
      "2021-06-20 11:25:15,528 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.681\n",
      "2021-06-20 11:25:24,773 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 69/200: loss: 0.00014 Time taken: 0:00:26.305760 ETA: 0:57:26.054579\n",
      "2021-06-20 11:25:24,773 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.857\n",
      "2021-06-20 11:25:34,072 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.641\n",
      "2021-06-20 11:25:43,372 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.636\n",
      "2021-06-20 11:25:50,807 [INFO] iva.detectnet_v2.evaluation.evaluation: step 0 / 17, 0.00s/step\n",
      "2021-06-20 11:25:52,426 [INFO] iva.detectnet_v2.evaluation.evaluation: step 10 / 17, 0.16s/step\n",
      "Matching predictions to ground truth, class 1/3.: 100%|| 332/332 [00:00<00:00, 22477.22it/s]\n",
      "Matching predictions to ground truth, class 2/3.: 100%|| 1157/1157 [00:00<00:00, 24150.18it/s]\n",
      "Matching predictions to ground truth, class 3/3.: 100%|| 275/275 [00:00<00:00, 21763.72it/s]\n",
      "Epoch 70/200\n",
      "=========================\n",
      "\n",
      "Validation cost: 0.000228\n",
      "Mean average_precision (in %): 63.6840\n",
      "\n",
      "class name               average precision (in %)\n",
      "---------------------  --------------------------\n",
      "helmet                                    72.9754\n",
      "person_with_helmet                        72.3353\n",
      "person_without_helmet                     45.7415\n",
      "\n",
      "Median Inference Time: 0.008755\n",
      "2021-06-20 11:25:54,070 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 70/200: loss: 0.00014 Time taken: 0:00:29.295237 ETA: 1:03:28.380818\n",
      "2021-06-20 11:25:55,556 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 28.726\n",
      "2021-06-20 11:26:04,799 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.868\n",
      "2021-06-20 11:26:14,023 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.948\n",
      "2021-06-20 11:26:20,367 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 71/200: loss: 0.00019 Time taken: 0:00:26.302158 ETA: 0:56:32.978428\n",
      "2021-06-20 11:26:23,353 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.512\n",
      "2021-06-20 11:26:32,645 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-20 11:26:41,886 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.876\n",
      "2021-06-20 11:26:46,741 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 72/200: loss: 0.00016 Time taken: 0:00:26.373140 ETA: 0:56:15.761902\n",
      "2021-06-20 11:26:51,199 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.580\n",
      "2021-06-20 11:27:00,503 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.621\n",
      "2021-06-20 11:27:09,753 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.837\n",
      "2021-06-20 11:27:13,126 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 73/200: loss: 0.00013 Time taken: 0:00:26.383687 ETA: 0:55:50.728312\n",
      "2021-06-20 11:27:19,059 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.614\n",
      "2021-06-20 11:27:28,347 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.685\n",
      "2021-06-20 11:27:37,637 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.676\n",
      "2021-06-20 11:27:39,499 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 74/200: loss: 0.00016 Time taken: 0:00:26.364682 ETA: 0:55:21.949957\n",
      "2021-06-20 11:27:46,932 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.656\n",
      "2021-06-20 11:27:56,179 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.852\n",
      "2021-06-20 11:28:05,476 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.646\n",
      "2021-06-20 11:28:05,873 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 75/200: loss: 0.00018 Time taken: 0:00:26.352044 ETA: 0:54:54.005543\n",
      "2021-06-20 11:28:14,743 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.772\n",
      "2021-06-20 11:28:23,974 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.920\n",
      "2021-06-20 11:28:32,155 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 76/200: loss: 0.00016 Time taken: 0:00:26.294220 ETA: 0:54:20.483306\n",
      "2021-06-20 11:28:33,268 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.660\n",
      "2021-06-20 11:28:42,534 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.770\n",
      "2021-06-20 11:28:51,782 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.849\n",
      "2021-06-20 11:28:58,508 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 77/200: loss: 0.00016 Time taken: 0:00:26.367084 ETA: 0:54:03.151277\n",
      "2021-06-20 11:29:01,127 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.456\n",
      "2021-06-20 11:29:10,354 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.931\n",
      "2021-06-20 11:29:19,630 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.732\n",
      "2021-06-20 11:29:24,884 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 78/200: loss: 0.00020 Time taken: 0:00:26.365969 ETA: 0:53:36.648211\n",
      "2021-06-20 11:29:28,963 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.505\n",
      "2021-06-20 11:29:38,220 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.809\n",
      "2021-06-20 11:29:47,531 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.590\n",
      "2021-06-20 11:29:51,244 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 79/200: loss: 0.00016 Time taken: 0:00:26.368866 ETA: 0:53:10.632840\n",
      "2021-06-20 11:29:56,790 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.803\n",
      "2021-06-20 11:30:06,025 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.901\n",
      "2021-06-20 11:30:15,318 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.667\n",
      "2021-06-20 11:30:17,196 [INFO] iva.detectnet_v2.evaluation.evaluation: step 0 / 17, 0.00s/step\n",
      "2021-06-20 11:30:18,951 [INFO] iva.detectnet_v2.evaluation.evaluation: step 10 / 17, 0.18s/step\n",
      "Matching predictions to ground truth, class 1/3.: 100%|| 541/541 [00:00<00:00, 25366.32it/s]\n",
      "Matching predictions to ground truth, class 2/3.: 100%|| 1742/1742 [00:00<00:00, 23920.22it/s]\n",
      "Matching predictions to ground truth, class 3/3.: 100%|| 307/307 [00:00<00:00, 20575.10it/s]\n",
      "Epoch 80/200\n",
      "=========================\n",
      "\n",
      "Validation cost: 0.000216\n",
      "Mean average_precision (in %): 69.2816\n",
      "\n",
      "class name               average precision (in %)\n",
      "---------------------  --------------------------\n",
      "helmet                                    87.1586\n",
      "person_with_helmet                        73.0016\n",
      "person_without_helmet                     47.6847\n",
      "\n",
      "Median Inference Time: 0.008911\n",
      "2021-06-20 11:30:20,706 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 80/200: loss: 0.00015 Time taken: 0:00:29.461162 ETA: 0:58:55.339451\n",
      "2021-06-20 11:30:27,727 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 28.206\n",
      "2021-06-20 11:30:37,063 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.491\n",
      "2021-06-20 11:30:46,356 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.663\n",
      "2021-06-20 11:30:47,145 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 81/200: loss: 0.00015 Time taken: 0:00:26.429220 ETA: 0:52:25.077232\n",
      "2021-06-20 11:30:55,675 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.559\n",
      "2021-06-20 11:31:04,956 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.711\n",
      "2021-06-20 11:31:13,481 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 82/200: loss: 0.00015 Time taken: 0:00:26.344905 ETA: 0:51:48.698778\n",
      "2021-06-20 11:31:14,225 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.764\n",
      "2021-06-20 11:31:23,499 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.743\n",
      "2021-06-20 11:31:32,774 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.734\n",
      "2021-06-20 11:31:39,830 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 83/200: loss: 0.00017 Time taken: 0:00:26.348382 ETA: 0:51:22.760638\n",
      "2021-06-20 11:31:42,075 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.632\n",
      "2021-06-20 11:31:51,313 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.891\n",
      "2021-06-20 11:32:00,592 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.719\n",
      "2021-06-20 11:32:06,189 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 84/200: loss: 0.00019 Time taken: 0:00:26.341314 ETA: 0:50:55.592378\n",
      "2021-06-20 11:32:09,904 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.588\n",
      "2021-06-20 11:32:19,189 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.694\n",
      "2021-06-20 11:32:28,448 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.804\n",
      "2021-06-20 11:32:32,598 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 85/200: loss: 0.00012 Time taken: 0:00:26.418501 ETA: 0:50:38.127631\n",
      "2021-06-20 11:32:37,792 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.460\n",
      "2021-06-20 11:32:47,051 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.802\n",
      "2021-06-20 11:32:56,377 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.531\n",
      "2021-06-20 11:32:58,968 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 86/200: loss: 0.00022 Time taken: 0:00:26.373145 ETA: 0:50:06.538487\n",
      "2021-06-20 11:33:05,675 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.644\n",
      "2021-06-20 11:33:14,995 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.554\n",
      "2021-06-20 11:33:24,221 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.940\n",
      "2021-06-20 11:33:25,357 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 87/200: loss: 0.00011 Time taken: 0:00:26.385963 ETA: 0:49:41.613842\n",
      "2021-06-20 11:33:33,477 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.814\n",
      "2021-06-20 11:33:42,794 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-20 11:33:51,692 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 88/200: loss: 0.00012 Time taken: 0:00:26.341475 ETA: 0:49:10.245148\n",
      "2021-06-20 11:33:52,064 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.757\n",
      "2021-06-20 11:34:01,393 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.520\n",
      "2021-06-20 11:34:10,650 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.809\n",
      "2021-06-20 11:34:18,084 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 89/200: loss: 0.00016 Time taken: 0:00:26.385692 ETA: 0:48:48.811825\n",
      "2021-06-20 11:34:19,927 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.731\n",
      "2021-06-20 11:34:29,200 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.743\n",
      "2021-06-20 11:34:38,449 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.846\n",
      "2021-06-20 11:34:47,521 [INFO] iva.detectnet_v2.evaluation.evaluation: step 0 / 17, 0.00s/step\n",
      "2021-06-20 11:34:49,439 [INFO] iva.detectnet_v2.evaluation.evaluation: step 10 / 17, 0.19s/step\n",
      "Matching predictions to ground truth, class 1/3.: 100%|| 1064/1064 [00:00<00:00, 29583.17it/s]\n",
      "Matching predictions to ground truth, class 2/3.: 100%|| 3208/3208 [00:00<00:00, 28632.86it/s]\n",
      "Matching predictions to ground truth, class 3/3.: 100%|| 300/300 [00:00<00:00, 21480.61it/s]\n",
      "Epoch 90/200\n",
      "=========================\n",
      "\n",
      "Validation cost: 0.000247\n",
      "Mean average_precision (in %): 58.4573\n",
      "\n",
      "class name               average precision (in %)\n",
      "---------------------  --------------------------\n",
      "helmet                                    86.0365\n",
      "person_with_helmet                        70.1864\n",
      "person_without_helmet                     19.149\n",
      "\n",
      "Median Inference Time: 0.008797\n",
      "2021-06-20 11:34:51,398 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 90/200: loss: 0.00013 Time taken: 0:00:33.306546 ETA: 1:01:03.720031\n",
      "2021-06-20 11:34:54,763 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 21.454\n",
      "2021-06-20 11:35:04,065 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.627\n",
      "2021-06-20 11:35:13,295 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.923\n",
      "2021-06-20 11:35:17,797 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 91/200: loss: 0.00015 Time taken: 0:00:26.409115 ETA: 0:47:58.593491\n",
      "2021-06-20 11:35:22,611 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.570\n",
      "2021-06-20 11:35:31,847 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.897\n",
      "2021-06-20 11:35:41,127 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.717\n",
      "2021-06-20 11:35:44,098 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 92/200: loss: 0.00014 Time taken: 0:00:26.292994 ETA: 0:47:19.643329\n",
      "2021-06-20 11:35:50,374 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.851\n",
      "2021-06-20 11:35:59,643 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.760\n",
      "2021-06-20 11:36:08,897 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.822\n",
      "2021-06-20 11:36:10,402 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 93/200: loss: 0.00013 Time taken: 0:00:26.309384 ETA: 0:46:55.104074\n",
      "2021-06-20 11:36:18,186 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.683\n",
      "2021-06-20 11:36:27,483 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.647\n",
      "2021-06-20 11:36:36,770 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 94/200: loss: 0.00018 Time taken: 0:00:26.366940 ETA: 0:46:34.895592\n",
      "2021-06-20 11:36:36,770 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.687\n",
      "2021-06-20 11:36:46,036 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.773\n",
      "2021-06-20 11:36:55,296 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.799\n",
      "2021-06-20 11:37:03,081 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 95/200: loss: 0.00018 Time taken: 0:00:26.311751 ETA: 0:46:02.733843\n",
      "2021-06-20 11:37:04,571 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.738\n",
      "2021-06-20 11:37:13,806 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.900\n",
      "2021-06-20 11:37:23,101 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.657\n",
      "2021-06-20 11:37:29,423 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 96/200: loss: 0.00013 Time taken: 0:00:26.323533 ETA: 0:45:37.647413\n",
      "2021-06-20 11:37:32,366 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.776\n",
      "2021-06-20 11:37:41,588 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.955\n",
      "2021-06-20 11:37:50,847 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.801\n",
      "2021-06-20 11:37:55,682 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 97/200: loss: 0.00022 Time taken: 0:00:26.273561 ETA: 0:45:06.176832\n",
      "2021-06-20 11:38:00,146 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.641\n",
      "2021-06-20 11:38:09,422 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.732\n",
      "2021-06-20 11:38:18,682 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.799\n",
      "2021-06-20 11:38:22,046 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 98/200: loss: 0.00019 Time taken: 0:00:26.363929 ETA: 0:44:49.120761\n",
      "2021-06-20 11:38:27,959 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.731\n",
      "2021-06-20 11:38:37,230 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.752\n",
      "2021-06-20 11:38:46,502 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.751\n",
      "2021-06-20 11:38:48,363 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 99/200: loss: 0.00015 Time taken: 0:00:26.315084 ETA: 0:44:17.823506\n",
      "2021-06-20 11:38:55,825 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.540\n",
      "2021-06-20 11:39:05,098 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.746\n",
      "2021-06-20 11:39:14,376 [INFO] iva.detectnet_v2.evaluation.evaluation: step 0 / 17, 0.00s/step\n",
      "2021-06-20 11:39:16,453 [INFO] iva.detectnet_v2.evaluation.evaluation: step 10 / 17, 0.21s/step\n",
      "Matching predictions to ground truth, class 1/3.: 100%|| 1343/1343 [00:00<00:00, 29391.71it/s]\n",
      "Matching predictions to ground truth, class 2/3.: 100%|| 5141/5141 [00:00<00:00, 27229.45it/s]\n",
      "Matching predictions to ground truth, class 3/3.: 100%|| 435/435 [00:00<00:00, 22764.98it/s]\n",
      "Epoch 100/200\n",
      "=========================\n",
      "\n",
      "Validation cost: 0.000239\n",
      "Mean average_precision (in %): 57.0605\n",
      "\n",
      "class name               average precision (in %)\n",
      "---------------------  --------------------------\n",
      "helmet                                    75.6043\n",
      "person_with_helmet                        65.3462\n",
      "person_without_helmet                     30.231\n",
      "\n",
      "Median Inference Time: 0.009113\n",
      "2021-06-20 11:39:18,247 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 26.619\n",
      "2021-06-20 11:39:18,628 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 100/200: loss: 0.00013 Time taken: 0:00:30.250817 ETA: 0:50:25.081730\n",
      "2021-06-20 11:39:27,501 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.825\n",
      "2021-06-20 11:39:36,790 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.681\n",
      "2021-06-20 11:39:44,944 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 101/200: loss: 0.00013 Time taken: 0:00:26.318015 ETA: 0:43:25.483471\n",
      "2021-06-20 11:39:46,081 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.673\n",
      "2021-06-20 11:39:55,277 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 38.060\n",
      "2021-06-20 11:40:04,514 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.893\n",
      "2021-06-20 11:40:11,195 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 102/200: loss: 0.00013 Time taken: 0:00:26.252543 ETA: 0:42:52.749258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-20 11:40:13,802 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.682\n",
      "2021-06-20 11:40:23,047 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.862\n",
      "2021-06-20 11:40:32,281 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.904\n",
      "2021-06-20 11:40:37,495 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 103/200: loss: 0.00013 Time taken: 0:00:26.309508 ETA: 0:42:32.022261\n",
      "2021-06-20 11:40:41,573 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.670\n",
      "2021-06-20 11:40:50,832 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.802\n",
      "2021-06-20 11:41:00,177 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.453\n",
      "2021-06-20 11:41:03,892 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 104/200: loss: 0.00013 Time taken: 0:00:26.389924 ETA: 0:42:13.432709\n",
      "2021-06-20 11:41:09,406 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.926\n",
      "2021-06-20 11:41:18,698 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.667\n",
      "2021-06-20 11:41:27,977 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.723\n",
      "2021-06-20 11:41:30,257 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 105/200: loss: 0.00016 Time taken: 0:00:26.362336 ETA: 0:41:44.421958\n",
      "2021-06-20 11:41:37,280 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.622\n",
      "2021-06-20 11:41:46,538 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.805\n",
      "2021-06-20 11:41:55,778 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.879\n",
      "2021-06-20 11:41:56,548 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 106/200: loss: 0.00012 Time taken: 0:00:26.297444 ETA: 0:41:11.959723\n",
      "2021-06-20 11:42:05,081 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.626\n",
      "2021-06-20 11:42:14,302 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.957\n",
      "2021-06-20 11:42:22,823 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 107/200: loss: 0.00019 Time taken: 0:00:26.265088 ETA: 0:40:42.653214\n",
      "2021-06-20 11:42:23,589 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.687\n",
      "2021-06-20 11:42:32,894 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.618\n",
      "2021-06-20 11:42:42,116 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.953\n",
      "2021-06-20 11:42:49,170 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 108/200: loss: 0.00024 Time taken: 0:00:26.352378 ETA: 0:40:24.418766\n",
      "2021-06-20 11:42:51,411 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.657\n",
      "2021-06-20 11:43:00,694 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.704\n",
      "2021-06-20 11:43:09,913 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.967\n",
      "2021-06-20 11:43:15,505 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 109/200: loss: 0.00017 Time taken: 0:00:26.333497 ETA: 0:39:56.348253\n",
      "2021-06-20 11:43:19,222 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.599\n",
      "2021-06-20 11:43:28,458 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.893\n",
      "2021-06-20 11:43:37,755 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.650\n",
      "2021-06-20 11:43:41,446 [INFO] iva.detectnet_v2.evaluation.evaluation: step 0 / 17, 0.00s/step\n",
      "2021-06-20 11:43:43,125 [INFO] iva.detectnet_v2.evaluation.evaluation: step 10 / 17, 0.17s/step\n",
      "Matching predictions to ground truth, class 1/3.: 100%|| 470/470 [00:00<00:00, 25446.60it/s]\n",
      "Matching predictions to ground truth, class 2/3.: 100%|| 927/927 [00:00<00:00, 26576.35it/s]\n",
      "Matching predictions to ground truth, class 3/3.: 100%|| 303/303 [00:00<00:00, 21641.85it/s]\n",
      "Epoch 110/200\n",
      "=========================\n",
      "\n",
      "Validation cost: 0.000247\n",
      "Mean average_precision (in %): 65.7688\n",
      "\n",
      "class name               average precision (in %)\n",
      "---------------------  --------------------------\n",
      "helmet                                    81.7889\n",
      "person_with_helmet                        64.4675\n",
      "person_without_helmet                     51.0501\n",
      "\n",
      "Median Inference Time: 0.008898\n",
      "2021-06-20 11:43:44,772 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 110/200: loss: 0.00017 Time taken: 0:00:29.250784 ETA: 0:43:52.570531\n",
      "2021-06-20 11:43:49,950 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 28.700\n",
      "2021-06-20 11:43:59,237 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.691\n",
      "2021-06-20 11:44:08,507 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.757\n",
      "2021-06-20 11:44:11,132 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 111/200: loss: 0.00018 Time taken: 0:00:26.372941 ETA: 0:39:07.191772\n",
      "2021-06-20 11:44:17,810 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.621\n",
      "2021-06-20 11:44:27,077 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.770\n",
      "2021-06-20 11:44:36,315 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.889\n",
      "2021-06-20 11:44:37,458 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 112/200: loss: 0.00015 Time taken: 0:00:26.325695 ETA: 0:38:36.661142\n",
      "2021-06-20 11:44:45,631 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.572\n",
      "2021-06-20 11:44:54,870 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.885\n",
      "2021-06-20 11:45:03,749 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 113/200: loss: 0.00016 Time taken: 0:00:26.294984 ETA: 0:38:07.663596\n",
      "2021-06-20 11:45:04,122 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.827\n",
      "2021-06-20 11:45:13,377 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.819\n",
      "2021-06-20 11:45:22,675 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.646\n",
      "2021-06-20 11:45:30,110 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 114/200: loss: 0.00011 Time taken: 0:00:26.360738 ETA: 0:37:47.023471\n",
      "2021-06-20 11:45:31,955 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.717\n",
      "2021-06-20 11:45:41,173 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.971\n",
      "2021-06-20 11:45:50,459 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.692\n",
      "2021-06-20 11:45:56,396 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 115/200: loss: 0.00015 Time taken: 0:00:26.282074 ETA: 0:37:13.976268\n",
      "2021-06-20 11:45:59,742 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.706\n",
      "2021-06-20 11:46:08,985 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.867\n",
      "2021-06-20 11:46:18,286 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.630\n",
      "2021-06-20 11:46:22,796 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 116/200: loss: 0.00012 Time taken: 0:00:26.398715 ETA: 0:36:57.492022\n",
      "2021-06-20 11:46:27,609 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.545\n",
      "2021-06-20 11:46:36,866 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.811\n",
      "2021-06-20 11:46:46,079 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.991\n",
      "2021-06-20 11:46:49,085 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 117/200: loss: 0.00019 Time taken: 0:00:26.278457 ETA: 0:36:21.111945\n",
      "2021-06-20 11:46:55,425 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.450\n",
      "2021-06-20 11:47:04,639 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.985\n",
      "2021-06-20 11:47:13,903 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.784\n",
      "2021-06-20 11:47:15,411 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 118/200: loss: 0.00015 Time taken: 0:00:26.330872 ETA: 0:35:59.131528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-20 11:47:23,170 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.768\n",
      "2021-06-20 11:47:32,402 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.915\n",
      "2021-06-20 11:47:41,706 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 119/200: loss: 0.00013 Time taken: 0:00:26.300428 ETA: 0:35:30.334661\n",
      "2021-06-20 11:47:41,707 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.616\n",
      "2021-06-20 11:47:50,973 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.771\n",
      "2021-06-20 11:48:00,227 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.822\n",
      "2021-06-20 11:48:11,066 [INFO] iva.detectnet_v2.evaluation.evaluation: step 0 / 17, 0.00s/step\n",
      "2021-06-20 11:48:12,905 [INFO] iva.detectnet_v2.evaluation.evaluation: step 10 / 17, 0.18s/step\n",
      "Matching predictions to ground truth, class 1/3.: 100%|| 455/455 [00:00<00:00, 25236.49it/s]\n",
      "Matching predictions to ground truth, class 2/3.: 100%|| 2930/2930 [00:00<00:00, 26393.66it/s]\n",
      "Matching predictions to ground truth, class 3/3.: 100%|| 360/360 [00:00<00:00, 23469.01it/s]\n",
      "Epoch 120/200\n",
      "=========================\n",
      "\n",
      "Validation cost: 0.000205\n",
      "Mean average_precision (in %): 60.9542\n",
      "\n",
      "class name               average precision (in %)\n",
      "---------------------  --------------------------\n",
      "helmet                                    73.2572\n",
      "person_with_helmet                        67.781\n",
      "person_without_helmet                     41.8245\n",
      "\n",
      "Median Inference Time: 0.008972\n",
      "2021-06-20 11:48:14,765 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 120/200: loss: 0.00011 Time taken: 0:00:33.051000 ETA: 0:44:04.080029\n",
      "2021-06-20 11:48:16,283 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 21.800\n",
      "2021-06-20 11:48:25,532 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.842\n",
      "2021-06-20 11:48:34,795 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.785\n",
      "2021-06-20 11:48:41,126 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 121/200: loss: 0.00019 Time taken: 0:00:26.367536 ETA: 0:34:43.035312\n",
      "2021-06-20 11:48:44,107 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.591\n",
      "2021-06-20 11:48:53,356 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.840\n",
      "2021-06-20 11:49:02,612 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.817\n",
      "2021-06-20 11:49:07,430 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 122/200: loss: 0.00013 Time taken: 0:00:26.302284 ETA: 0:34:11.578189\n",
      "2021-06-20 11:49:11,872 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.796\n",
      "2021-06-20 11:49:21,106 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.904\n",
      "2021-06-20 11:49:30,352 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.857\n",
      "2021-06-20 11:49:33,720 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 123/200: loss: 0.00014 Time taken: 0:00:26.275704 ETA: 0:33:43.229182\n",
      "2021-06-20 11:49:39,663 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.592\n",
      "2021-06-20 11:49:48,910 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.849\n",
      "2021-06-20 11:49:58,162 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.832\n",
      "2021-06-20 11:50:00,049 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 124/200: loss: 0.00016 Time taken: 0:00:26.336546 ETA: 0:33:21.577528\n",
      "2021-06-20 11:50:07,463 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.631\n",
      "2021-06-20 11:50:16,705 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.875\n",
      "2021-06-20 11:50:25,936 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.917\n",
      "2021-06-20 11:50:26,335 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 125/200: loss: 0.00010 Time taken: 0:00:26.257802 ETA: 0:32:49.335133\n",
      "2021-06-20 11:50:35,263 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.529\n",
      "2021-06-20 11:50:44,570 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.607\n",
      "2021-06-20 11:50:52,685 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 126/200: loss: 0.00014 Time taken: 0:00:26.377913 ETA: 0:32:31.965562\n",
      "2021-06-20 11:50:53,831 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.793\n",
      "2021-06-20 11:51:03,147 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.573\n",
      "2021-06-20 11:51:12,349 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 38.036\n",
      "2021-06-20 11:51:19,083 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 127/200: loss: 0.00015 Time taken: 0:00:26.384744 ETA: 0:32:06.086324\n",
      "2021-06-20 11:51:21,674 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.533\n",
      "2021-06-20 11:51:30,935 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.796\n",
      "2021-06-20 11:51:40,176 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.876\n",
      "2021-06-20 11:51:45,363 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 128/200: loss: 0.00013 Time taken: 0:00:26.297555 ETA: 0:31:33.423958\n",
      "2021-06-20 11:51:49,465 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.680\n",
      "2021-06-20 11:51:58,778 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.583\n",
      "2021-06-20 11:52:08,016 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.887\n",
      "2021-06-20 11:52:11,754 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 129/200: loss: 0.00013 Time taken: 0:00:26.382846 ETA: 0:31:13.182091\n",
      "2021-06-20 11:52:17,345 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.519\n",
      "2021-06-20 11:52:26,994 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 36.276\n",
      "2021-06-20 11:52:36,454 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 36.997\n",
      "2021-06-20 11:52:38,325 [INFO] iva.detectnet_v2.evaluation.evaluation: step 0 / 17, 0.00s/step\n",
      "2021-06-20 11:52:40,121 [INFO] iva.detectnet_v2.evaluation.evaluation: step 10 / 17, 0.18s/step\n",
      "Matching predictions to ground truth, class 1/3.: 100%|| 308/308 [00:00<00:00, 22652.43it/s]\n",
      "Matching predictions to ground truth, class 2/3.: 100%|| 1944/1944 [00:00<00:00, 26743.18it/s]\n",
      "Matching predictions to ground truth, class 3/3.: 100%|| 249/249 [00:00<00:00, 22167.12it/s]\n",
      "Epoch 130/200\n",
      "=========================\n",
      "\n",
      "Validation cost: 0.000236\n",
      "Mean average_precision (in %): 62.0854\n",
      "\n",
      "class name               average precision (in %)\n",
      "---------------------  --------------------------\n",
      "helmet                                    79.2859\n",
      "person_with_helmet                        72.3306\n",
      "person_without_helmet                     34.6397\n",
      "\n",
      "Median Inference Time: 0.008946\n",
      "2021-06-20 11:52:41,860 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 130/200: loss: 0.00012 Time taken: 0:00:30.094581 ETA: 0:35:06.620646\n",
      "2021-06-20 11:52:48,875 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 28.178\n",
      "2021-06-20 11:52:58,173 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.647\n",
      "2021-06-20 11:53:07,441 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.763\n",
      "2021-06-20 11:53:08,216 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 131/200: loss: 0.00012 Time taken: 0:00:26.369386 ETA: 0:30:19.487615\n",
      "2021-06-20 11:53:16,743 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.626\n",
      "2021-06-20 11:53:25,982 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.887\n",
      "2021-06-20 11:53:34,512 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 132/200: loss: 0.00012 Time taken: 0:00:26.298762 ETA: 0:29:48.315805\n",
      "2021-06-20 11:53:35,258 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.731\n",
      "2021-06-20 11:53:44,506 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-20 11:53:53,755 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.846\n",
      "2021-06-20 11:54:00,745 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 133/200: loss: 0.00013 Time taken: 0:00:26.229160 ETA: 0:29:17.353693\n",
      "2021-06-20 11:54:02,983 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.929\n",
      "2021-06-20 11:54:12,218 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.899\n",
      "2021-06-20 11:54:21,434 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.982\n",
      "2021-06-20 11:54:27,030 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 134/200: loss: 0.00012 Time taken: 0:00:26.274493 ETA: 0:28:54.116521\n",
      "2021-06-20 11:54:30,742 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.601\n",
      "2021-06-20 11:54:40,025 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.704\n",
      "2021-06-20 11:54:49,220 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 38.068\n",
      "2021-06-20 11:54:53,368 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 135/200: loss: 0.00011 Time taken: 0:00:26.348148 ETA: 0:28:32.629596\n",
      "2021-06-20 11:54:58,529 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.599\n",
      "2021-06-20 11:55:07,758 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.926\n",
      "2021-06-20 11:55:17,057 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.636\n",
      "2021-06-20 11:55:19,659 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 136/200: loss: 0.00011 Time taken: 0:00:26.287022 ETA: 0:28:02.369400\n",
      "2021-06-20 11:55:26,296 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.886\n",
      "2021-06-20 11:55:35,547 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.837\n",
      "2021-06-20 11:55:44,792 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.859\n",
      "2021-06-20 11:55:45,919 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 137/200: loss: 0.00012 Time taken: 0:00:26.252386 ETA: 0:27:33.900339\n",
      "2021-06-20 11:55:54,079 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.689\n",
      "2021-06-20 11:56:03,319 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.877\n",
      "2021-06-20 11:56:12,210 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 138/200: loss: 0.00011 Time taken: 0:00:26.298964 ETA: 0:27:10.535784\n",
      "2021-06-20 11:56:12,580 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.796\n",
      "2021-06-20 11:56:21,874 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.659\n",
      "2021-06-20 11:56:31,131 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.810\n",
      "2021-06-20 11:56:38,557 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 139/200: loss: 0.00011 Time taken: 0:00:26.339728 ETA: 0:26:46.723430\n",
      "2021-06-20 11:56:40,403 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.752\n",
      "2021-06-20 11:56:49,647 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.863\n",
      "2021-06-20 11:56:58,908 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.793\n",
      "2021-06-20 11:57:04,449 [INFO] iva.detectnet_v2.evaluation.evaluation: step 0 / 17, 0.00s/step\n",
      "2021-06-20 11:57:06,176 [INFO] iva.detectnet_v2.evaluation.evaluation: step 10 / 17, 0.17s/step\n",
      "Matching predictions to ground truth, class 1/3.: 100%|| 765/765 [00:00<00:00, 26451.69it/s]\n",
      "Matching predictions to ground truth, class 2/3.: 100%|| 2090/2090 [00:00<00:00, 23957.82it/s]\n",
      "Matching predictions to ground truth, class 3/3.: 100%|| 248/248 [00:00<00:00, 22483.73it/s]\n",
      "Epoch 140/200\n",
      "=========================\n",
      "\n",
      "Validation cost: 0.000223\n",
      "Mean average_precision (in %): 62.4646\n",
      "\n",
      "class name               average precision (in %)\n",
      "---------------------  --------------------------\n",
      "helmet                                    83.359\n",
      "person_with_helmet                        67.6885\n",
      "person_without_helmet                     36.3464\n",
      "\n",
      "Median Inference Time: 0.008782\n",
      "2021-06-20 11:57:07,951 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 140/200: loss: 0.00010 Time taken: 0:00:29.389668 ETA: 0:29:23.380065\n",
      "2021-06-20 11:57:11,268 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 28.317\n",
      "2021-06-20 11:57:20,481 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.993\n",
      "2021-06-20 11:57:29,754 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.747\n",
      "2021-06-20 11:57:34,239 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 141/200: loss: 0.00015 Time taken: 0:00:26.288164 ETA: 0:25:51.001684\n",
      "2021-06-20 11:57:39,089 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.491\n",
      "2021-06-20 11:57:48,350 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.794\n",
      "2021-06-20 11:57:57,641 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.674\n",
      "2021-06-20 11:58:00,596 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 142/200: loss: 0.00011 Time taken: 0:00:26.366447 ETA: 0:25:29.253952\n",
      "2021-06-20 11:58:06,918 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.728\n",
      "2021-06-20 11:58:16,176 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.806\n",
      "2021-06-20 11:58:25,476 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.640\n",
      "2021-06-20 11:58:26,971 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 143/200: loss: 0.00011 Time taken: 0:00:26.373936 ETA: 0:25:03.314376\n",
      "2021-06-20 11:58:34,717 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.873\n",
      "2021-06-20 11:58:43,933 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.981\n",
      "2021-06-20 11:58:53,197 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 144/200: loss: 0.00009 Time taken: 0:00:26.210790 ETA: 0:24:27.804222\n",
      "2021-06-20 11:58:53,197 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.780\n",
      "2021-06-20 11:59:02,433 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.899\n",
      "2021-06-20 11:59:11,685 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.831\n",
      "2021-06-20 11:59:19,426 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 145/200: loss: 0.00012 Time taken: 0:00:26.239961 ETA: 0:24:03.197837\n",
      "2021-06-20 11:59:20,937 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.829\n",
      "2021-06-20 11:59:30,243 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.614\n",
      "2021-06-20 11:59:39,478 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.897\n",
      "2021-06-20 11:59:45,776 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 146/200: loss: 0.00012 Time taken: 0:00:26.349923 ETA: 0:23:42.895823\n",
      "2021-06-20 11:59:48,756 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.728\n",
      "2021-06-20 11:59:58,021 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.777\n",
      "2021-06-20 12:00:07,318 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.646\n",
      "2021-06-20 12:00:12,145 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 147/200: loss: 0.00012 Time taken: 0:00:26.368610 ETA: 0:23:17.536350\n",
      "2021-06-20 12:00:16,591 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.746\n",
      "2021-06-20 12:00:25,850 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.804\n",
      "2021-06-20 12:00:35,099 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.840\n",
      "2021-06-20 12:00:38,441 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 148/200: loss: 0.00012 Time taken: 0:00:26.294758 ETA: 0:22:47.327433\n",
      "2021-06-20 12:00:44,349 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.840\n",
      "2021-06-20 12:00:53,632 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-20 12:01:02,871 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.886\n",
      "2021-06-20 12:01:04,717 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 149/200: loss: 0.00013 Time taken: 0:00:26.276551 ETA: 0:22:20.104101\n",
      "2021-06-20 12:01:12,303 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.106\n",
      "2021-06-20 12:01:21,595 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.668\n",
      "2021-06-20 12:01:34,511 [INFO] iva.detectnet_v2.evaluation.evaluation: step 0 / 17, 0.00s/step\n",
      "2021-06-20 12:01:36,227 [INFO] iva.detectnet_v2.evaluation.evaluation: step 10 / 17, 0.17s/step\n",
      "Matching predictions to ground truth, class 1/3.: 100%|| 487/487 [00:00<00:00, 25190.86it/s]\n",
      "Matching predictions to ground truth, class 2/3.: 100%|| 1450/1450 [00:00<00:00, 24546.71it/s]\n",
      "Matching predictions to ground truth, class 3/3.: 100%|| 217/217 [00:00<00:00, 21707.78it/s]\n",
      "Epoch 150/200\n",
      "=========================\n",
      "\n",
      "Validation cost: 0.000176\n",
      "Mean average_precision (in %): 70.9560\n",
      "\n",
      "class name               average precision (in %)\n",
      "---------------------  --------------------------\n",
      "helmet                                    88.1009\n",
      "person_with_helmet                        73.368\n",
      "person_without_helmet                     51.399\n",
      "\n",
      "Median Inference Time: 0.008926\n",
      "2021-06-20 12:01:37,565 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 21.917\n",
      "2021-06-20 12:01:37,937 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 150/200: loss: 0.00008 Time taken: 0:00:33.213955 ETA: 0:27:40.697734\n",
      "2021-06-20 12:01:46,819 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.827\n",
      "2021-06-20 12:01:56,111 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.667\n",
      "2021-06-20 12:02:04,206 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 151/200: loss: 0.00009 Time taken: 0:00:26.275523 ETA: 0:21:27.500613\n",
      "2021-06-20 12:02:05,333 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.956\n",
      "2021-06-20 12:02:14,583 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.839\n",
      "2021-06-20 12:02:23,847 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.780\n",
      "2021-06-20 12:02:30,544 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 152/200: loss: 0.00008 Time taken: 0:00:26.337235 ETA: 0:21:04.187279\n",
      "2021-06-20 12:02:33,137 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.675\n",
      "2021-06-20 12:02:42,361 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.945\n",
      "2021-06-20 12:02:51,576 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.983\n",
      "2021-06-20 12:02:56,867 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 153/200: loss: 0.00009 Time taken: 0:00:26.297913 ETA: 0:20:36.001915\n",
      "2021-06-20 12:03:00,921 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.456\n",
      "2021-06-20 12:03:10,142 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.959\n",
      "2021-06-20 12:03:19,371 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.925\n",
      "2021-06-20 12:03:23,124 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 154/200: loss: 0.00014 Time taken: 0:00:26.270998 ETA: 0:20:08.465919\n",
      "2021-06-20 12:03:28,675 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.619\n",
      "2021-06-20 12:03:37,911 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.897\n",
      "2021-06-20 12:03:47,129 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.968\n",
      "2021-06-20 12:03:49,371 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 155/200: loss: 0.00009 Time taken: 0:00:26.254474 ETA: 0:19:41.451348\n",
      "2021-06-20 12:03:56,410 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.713\n",
      "2021-06-20 12:04:05,673 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.787\n",
      "2021-06-20 12:04:14,918 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.861\n",
      "2021-06-20 12:04:15,695 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 156/200: loss: 0.00008 Time taken: 0:00:26.317713 ETA: 0:19:17.979352\n",
      "2021-06-20 12:04:24,240 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.545\n",
      "2021-06-20 12:04:33,486 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.854\n",
      "2021-06-20 12:04:42,008 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 157/200: loss: 0.00009 Time taken: 0:00:26.315294 ETA: 0:18:51.557643\n",
      "2021-06-20 12:04:42,773 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.691\n",
      "2021-06-20 12:04:52,036 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.783\n",
      "2021-06-20 12:05:01,259 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.952\n",
      "2021-06-20 12:05:08,310 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 158/200: loss: 0.00007 Time taken: 0:00:26.296499 ETA: 0:18:24.452969\n",
      "2021-06-20 12:05:10,542 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.704\n",
      "2021-06-20 12:05:19,765 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.952\n",
      "2021-06-20 12:05:29,013 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.846\n",
      "2021-06-20 12:05:34,602 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 159/200: loss: 0.00007 Time taken: 0:00:26.295307 ETA: 0:17:58.107603\n",
      "2021-06-20 12:05:38,351 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.483\n",
      "2021-06-20 12:05:47,614 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.784\n",
      "2021-06-20 12:05:56,879 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.780\n",
      "2021-06-20 12:06:00,584 [INFO] iva.detectnet_v2.evaluation.evaluation: step 0 / 17, 0.00s/step\n",
      "2021-06-20 12:06:02,244 [INFO] iva.detectnet_v2.evaluation.evaluation: step 10 / 17, 0.17s/step\n",
      "Matching predictions to ground truth, class 1/3.: 100%|| 374/374 [00:00<00:00, 24694.13it/s]\n",
      "Matching predictions to ground truth, class 2/3.: 100%|| 1322/1322 [00:00<00:00, 24516.60it/s]\n",
      "Matching predictions to ground truth, class 3/3.: 100%|| 203/203 [00:00<00:00, 21553.90it/s]\n",
      "Epoch 160/200\n",
      "=========================\n",
      "\n",
      "Validation cost: 0.000176\n",
      "Mean average_precision (in %): 70.3146\n",
      "\n",
      "class name               average precision (in %)\n",
      "---------------------  --------------------------\n",
      "helmet                                    88.522\n",
      "person_with_helmet                        73.5307\n",
      "person_without_helmet                     48.8912\n",
      "\n",
      "Median Inference Time: 0.008875\n",
      "2021-06-20 12:06:03,909 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 160/200: loss: 0.00008 Time taken: 0:00:29.304732 ETA: 0:19:32.189283\n",
      "2021-06-20 12:06:09,103 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 28.634\n",
      "2021-06-20 12:06:18,352 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.843\n",
      "2021-06-20 12:06:27,611 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.798\n",
      "2021-06-20 12:06:30,208 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 161/200: loss: 0.00008 Time taken: 0:00:26.281055 ETA: 0:17:04.961144\n",
      "2021-06-20 12:06:36,892 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.716\n",
      "2021-06-20 12:06:46,153 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.791\n",
      "2021-06-20 12:06:55,449 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.654\n",
      "2021-06-20 12:06:56,579 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 162/200: loss: 0.00009 Time taken: 0:00:26.390010 ETA: 0:16:42.820385\n",
      "2021-06-20 12:07:04,680 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.917\n",
      "2021-06-20 12:07:13,939 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.801\n",
      "2021-06-20 12:07:22,779 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 163/200: loss: 0.00010 Time taken: 0:00:26.199456 ETA: 0:16:09.379871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-20 12:07:23,150 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 38.000\n",
      "2021-06-20 12:07:32,365 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.982\n",
      "2021-06-20 12:07:41,595 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.922\n",
      "2021-06-20 12:07:49,015 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 164/200: loss: 0.00013 Time taken: 0:00:26.235976 ETA: 0:15:44.495144\n",
      "2021-06-20 12:07:50,869 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.743\n",
      "2021-06-20 12:08:00,142 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.744\n",
      "2021-06-20 12:08:09,468 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.529\n",
      "2021-06-20 12:08:15,433 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 165/200: loss: 0.00009 Time taken: 0:00:26.408339 ETA: 0:15:24.291866\n",
      "2021-06-20 12:08:18,747 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.721\n",
      "2021-06-20 12:08:28,047 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.637\n",
      "2021-06-20 12:08:37,389 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.468\n",
      "2021-06-20 12:08:41,815 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 166/200: loss: 0.00007 Time taken: 0:00:26.390486 ETA: 0:14:57.276516\n",
      "2021-06-20 12:08:46,603 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.984\n",
      "2021-06-20 12:08:55,931 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.523\n",
      "2021-06-20 12:09:05,171 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.883\n",
      "2021-06-20 12:09:08,144 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 167/200: loss: 0.00009 Time taken: 0:00:26.329542 ETA: 0:14:28.874876\n",
      "2021-06-20 12:09:14,451 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.717\n",
      "2021-06-20 12:09:23,706 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.817\n",
      "2021-06-20 12:09:33,012 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.613\n",
      "2021-06-20 12:09:34,512 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 168/200: loss: 0.00008 Time taken: 0:00:26.364571 ETA: 0:14:03.666275\n",
      "2021-06-20 12:09:42,235 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.949\n",
      "2021-06-20 12:09:51,478 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.866\n",
      "2021-06-20 12:10:00,706 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 169/200: loss: 0.00007 Time taken: 0:00:26.179109 ETA: 0:13:31.552367\n",
      "2021-06-20 12:10:00,706 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.929\n",
      "2021-06-20 12:10:09,989 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.706\n",
      "2021-06-20 12:10:19,214 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.943\n",
      "2021-06-20 12:10:26,641 [INFO] iva.detectnet_v2.evaluation.evaluation: step 0 / 17, 0.00s/step\n",
      "2021-06-20 12:10:28,316 [INFO] iva.detectnet_v2.evaluation.evaluation: step 10 / 17, 0.17s/step\n",
      "Matching predictions to ground truth, class 1/3.: 100%|| 375/375 [00:00<00:00, 24049.54it/s]\n",
      "Matching predictions to ground truth, class 2/3.: 100%|| 1331/1331 [00:00<00:00, 24258.44it/s]\n",
      "Matching predictions to ground truth, class 3/3.: 100%|| 195/195 [00:00<00:00, 22024.16it/s]\n",
      "Epoch 170/200\n",
      "=========================\n",
      "\n",
      "Validation cost: 0.000164\n",
      "Mean average_precision (in %): 69.1053\n",
      "\n",
      "class name               average precision (in %)\n",
      "---------------------  --------------------------\n",
      "helmet                                    87.8032\n",
      "person_with_helmet                        74.1385\n",
      "person_without_helmet                     45.3742\n",
      "\n",
      "Median Inference Time: 0.008822\n",
      "2021-06-20 12:10:29,967 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 170/200: loss: 0.00010 Time taken: 0:00:29.271626 ETA: 0:14:38.148780\n",
      "2021-06-20 12:10:31,456 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 28.590\n",
      "2021-06-20 12:10:40,711 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.817\n",
      "2021-06-20 12:10:49,952 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.876\n",
      "2021-06-20 12:10:56,306 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 171/200: loss: 0.00008 Time taken: 0:00:26.341643 ETA: 0:12:43.907650\n",
      "2021-06-20 12:10:59,254 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.631\n",
      "2021-06-20 12:11:08,489 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.900\n",
      "2021-06-20 12:11:17,740 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.834\n",
      "2021-06-20 12:11:22,584 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 172/200: loss: 0.00009 Time taken: 0:00:26.265521 ETA: 0:12:15.434596\n",
      "2021-06-20 12:11:27,035 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.655\n",
      "2021-06-20 12:11:36,270 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.900\n",
      "2021-06-20 12:11:45,487 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.977\n",
      "2021-06-20 12:11:48,822 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 173/200: loss: 0.00008 Time taken: 0:00:26.247950 ETA: 0:11:48.694659\n",
      "2021-06-20 12:11:54,737 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.836\n",
      "2021-06-20 12:12:03,955 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.973\n",
      "2021-06-20 12:12:13,225 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.755\n",
      "2021-06-20 12:12:15,099 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 174/200: loss: 0.00008 Time taken: 0:00:26.278006 ETA: 0:11:23.228152\n",
      "2021-06-20 12:12:22,491 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.775\n",
      "2021-06-20 12:12:31,730 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.883\n",
      "2021-06-20 12:12:40,996 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.775\n",
      "2021-06-20 12:12:41,368 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 175/200: loss: 0.00007 Time taken: 0:00:26.260499 ETA: 0:10:56.512487\n",
      "2021-06-20 12:12:50,271 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.738\n",
      "2021-06-20 12:12:59,502 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.917\n",
      "2021-06-20 12:13:07,672 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 176/200: loss: 0.00007 Time taken: 0:00:26.309223 ETA: 0:10:31.421345\n",
      "2021-06-20 12:13:08,778 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.734\n",
      "2021-06-20 12:13:18,013 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.899\n",
      "2021-06-20 12:13:27,257 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.866\n",
      "2021-06-20 12:13:33,929 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 177/200: loss: 0.00008 Time taken: 0:00:26.245866 ETA: 0:10:03.654925\n",
      "2021-06-20 12:13:36,494 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.889\n",
      "2021-06-20 12:13:45,727 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.910\n",
      "2021-06-20 12:13:54,989 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.792\n",
      "2021-06-20 12:14:00,205 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 178/200: loss: 0.00008 Time taken: 0:00:26.278208 ETA: 0:09:38.120582\n",
      "2021-06-20 12:14:04,337 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.439\n",
      "2021-06-20 12:14:13,581 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.864\n",
      "2021-06-20 12:14:22,774 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 38.077\n",
      "2021-06-20 12:14:26,515 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 179/200: loss: 0.00008 Time taken: 0:00:26.306810 ETA: 0:09:12.443013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-20 12:14:32,105 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.507\n",
      "2021-06-20 12:14:41,372 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.771\n",
      "2021-06-20 12:14:50,641 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.763\n",
      "2021-06-20 12:14:56,136 [INFO] iva.detectnet_v2.evaluation.evaluation: step 0 / 17, 0.00s/step\n",
      "2021-06-20 12:14:57,866 [INFO] iva.detectnet_v2.evaluation.evaluation: step 10 / 17, 0.17s/step\n",
      "Matching predictions to ground truth, class 1/3.: 100%|| 375/375 [00:00<00:00, 25223.13it/s]\n",
      "Matching predictions to ground truth, class 2/3.: 100%|| 1383/1383 [00:00<00:00, 24592.98it/s]\n",
      "Matching predictions to ground truth, class 3/3.: 100%|| 192/192 [00:00<00:00, 22589.87it/s]\n",
      "Epoch 180/200\n",
      "=========================\n",
      "\n",
      "Validation cost: 0.000161\n",
      "Mean average_precision (in %): 68.7214\n",
      "\n",
      "class name               average precision (in %)\n",
      "---------------------  --------------------------\n",
      "helmet                                    86.3184\n",
      "person_with_helmet                        73.9669\n",
      "person_without_helmet                     45.8788\n",
      "\n",
      "Median Inference Time: 0.008886\n",
      "2021-06-20 12:14:59,527 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 180/200: loss: 0.00008 Time taken: 0:00:33.002843 ETA: 0:11:00.056863\n",
      "2021-06-20 12:15:06,538 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 22.017\n",
      "2021-06-20 12:15:15,787 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.842\n",
      "2021-06-20 12:15:25,041 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.825\n",
      "2021-06-20 12:15:25,806 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 181/200: loss: 0.00007 Time taken: 0:00:26.292519 ETA: 0:08:19.557854\n",
      "2021-06-20 12:15:34,322 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.712\n",
      "2021-06-20 12:15:43,642 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.553\n",
      "2021-06-20 12:15:52,129 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 182/200: loss: 0.00007 Time taken: 0:00:26.324349 ETA: 0:07:53.838285\n",
      "2021-06-20 12:15:52,866 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.946\n",
      "2021-06-20 12:16:02,120 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.823\n",
      "2021-06-20 12:16:11,409 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.682\n",
      "2021-06-20 12:16:18,422 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 183/200: loss: 0.00007 Time taken: 0:00:26.295070 ETA: 0:07:27.016185\n",
      "2021-06-20 12:16:20,649 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.879\n",
      "2021-06-20 12:16:29,933 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.703\n",
      "2021-06-20 12:16:39,167 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.904\n",
      "2021-06-20 12:16:44,713 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 184/200: loss: 0.00007 Time taken: 0:00:26.279888 ETA: 0:07:00.478214\n",
      "2021-06-20 12:16:48,412 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.860\n",
      "2021-06-20 12:16:57,707 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.654\n",
      "2021-06-20 12:17:06,934 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.935\n",
      "2021-06-20 12:17:11,060 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 185/200: loss: 0.00008 Time taken: 0:00:26.340094 ETA: 0:06:35.101408\n",
      "2021-06-20 12:17:16,233 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.640\n",
      "2021-06-20 12:17:25,464 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.918\n",
      "2021-06-20 12:17:34,693 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.923\n",
      "2021-06-20 12:17:37,311 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 186/200: loss: 0.00007 Time taken: 0:00:26.265084 ETA: 0:06:07.711180\n",
      "2021-06-20 12:17:43,991 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.646\n",
      "2021-06-20 12:17:53,252 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.793\n",
      "2021-06-20 12:18:02,493 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.878\n",
      "2021-06-20 12:18:03,627 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 187/200: loss: 0.00007 Time taken: 0:00:26.317370 ETA: 0:05:42.125812\n",
      "2021-06-20 12:18:11,763 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.756\n",
      "2021-06-20 12:18:21,013 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.841\n",
      "2021-06-20 12:18:29,910 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 188/200: loss: 0.00008 Time taken: 0:00:26.281295 ETA: 0:05:15.375541\n",
      "2021-06-20 12:18:30,305 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.667\n",
      "2021-06-20 12:18:39,607 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.631\n",
      "2021-06-20 12:18:48,847 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.878\n",
      "2021-06-20 12:18:56,333 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 189/200: loss: 0.00008 Time taken: 0:00:26.405539 ETA: 0:04:50.460924\n",
      "2021-06-20 12:18:58,180 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.501\n",
      "2021-06-20 12:19:07,408 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.931\n",
      "2021-06-20 12:19:16,645 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.894\n",
      "2021-06-20 12:19:22,169 [INFO] iva.detectnet_v2.evaluation.evaluation: step 0 / 17, 0.00s/step\n",
      "2021-06-20 12:19:23,862 [INFO] iva.detectnet_v2.evaluation.evaluation: step 10 / 17, 0.17s/step\n",
      "Matching predictions to ground truth, class 1/3.: 100%|| 387/387 [00:00<00:00, 24091.24it/s]\n",
      "Matching predictions to ground truth, class 2/3.: 100%|| 1400/1400 [00:00<00:00, 24100.15it/s]\n",
      "Matching predictions to ground truth, class 3/3.: 100%|| 181/181 [00:00<00:00, 21297.45it/s]\n",
      "Epoch 190/200\n",
      "=========================\n",
      "\n",
      "Validation cost: 0.000158\n",
      "Mean average_precision (in %): 69.0891\n",
      "\n",
      "class name               average precision (in %)\n",
      "---------------------  --------------------------\n",
      "helmet                                    87.6039\n",
      "person_with_helmet                        74.2072\n",
      "person_without_helmet                     45.4562\n",
      "\n",
      "Median Inference Time: 0.008776\n",
      "2021-06-20 12:19:25,543 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 190/200: loss: 0.00008 Time taken: 0:00:29.175458 ETA: 0:04:51.754584\n",
      "2021-06-20 12:19:28,876 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 28.616\n",
      "2021-06-20 12:19:38,177 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.628\n",
      "2021-06-20 12:19:47,476 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.640\n",
      "2021-06-20 12:19:51,953 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 191/200: loss: 0.00007 Time taken: 0:00:26.430527 ETA: 0:03:57.874741\n",
      "2021-06-20 12:19:56,812 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.490\n",
      "2021-06-20 12:20:06,039 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.936\n",
      "2021-06-20 12:20:15,298 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.801\n",
      "2021-06-20 12:20:18,300 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 192/200: loss: 0.00008 Time taken: 0:00:26.364426 ETA: 0:03:30.915411\n",
      "2021-06-20 12:20:24,639 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.471\n",
      "2021-06-20 12:20:33,915 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.733\n",
      "2021-06-20 12:20:43,198 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.703\n",
      "2021-06-20 12:20:44,683 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 193/200: loss: 0.00007 Time taken: 0:00:26.392299 ETA: 0:03:04.746091\n",
      "2021-06-20 12:20:52,478 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-20 12:21:01,725 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.848\n",
      "2021-06-20 12:21:10,979 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 194/200: loss: 0.00007 Time taken: 0:00:26.295668 ETA: 0:02:37.774006\n",
      "2021-06-20 12:21:10,979 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.822\n",
      "2021-06-20 12:21:20,202 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.953\n",
      "2021-06-20 12:21:29,460 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.806\n",
      "2021-06-20 12:21:37,239 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 195/200: loss: 0.00008 Time taken: 0:00:26.259394 ETA: 0:02:11.296972\n",
      "2021-06-20 12:21:38,755 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.653\n",
      "2021-06-20 12:21:48,004 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.847\n",
      "2021-06-20 12:21:57,251 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.849\n",
      "2021-06-20 12:22:03,557 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 196/200: loss: 0.00007 Time taken: 0:00:26.301898 ETA: 0:01:45.207592\n",
      "2021-06-20 12:22:06,532 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.712\n",
      "2021-06-20 12:22:15,748 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.980\n",
      "2021-06-20 12:22:24,982 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.904\n",
      "2021-06-20 12:22:29,818 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 197/200: loss: 0.00008 Time taken: 0:00:26.273674 ETA: 0:01:18.821023\n",
      "2021-06-20 12:22:34,257 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.739\n",
      "2021-06-20 12:22:43,557 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.637\n",
      "2021-06-20 12:22:52,823 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.774\n",
      "2021-06-20 12:22:56,163 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 198/200: loss: 0.00009 Time taken: 0:00:26.345961 ETA: 0:00:52.691922\n",
      "2021-06-20 12:23:02,059 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.895\n",
      "2021-06-20 12:23:11,266 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 38.016\n",
      "2021-06-20 12:23:20,482 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.976\n",
      "2021-06-20 12:23:22,393 [INFO] /usr/local/lib/python3.6/dist-packages/modulus/hooks/task_progress_monitor_hook.pyc: Epoch 199/200: loss: 0.00006 Time taken: 0:00:26.228446 ETA: 0:00:26.228446\n",
      "2021-06-20 12:23:29,784 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.630\n",
      "2021-06-20 12:23:39,055 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 37.753\n",
      "2021-06-20 12:23:48,286 [INFO] iva.detectnet_v2.evaluation.evaluation: step 0 / 17, 0.00s/step\n",
      "2021-06-20 12:23:49,973 [INFO] iva.detectnet_v2.evaluation.evaluation: step 10 / 17, 0.17s/step\n",
      "Matching predictions to ground truth, class 1/3.: 100%|| 385/385 [00:00<00:00, 25053.25it/s]\n",
      "Matching predictions to ground truth, class 2/3.: 100%|| 1359/1359 [00:00<00:00, 23774.32it/s]\n",
      "Matching predictions to ground truth, class 3/3.: 100%|| 185/185 [00:00<00:00, 20980.59it/s]\n",
      "Epoch 200/200\n",
      "=========================\n",
      "\n",
      "Validation cost: 0.000162\n",
      "Mean average_precision (in %): 70.2344\n",
      "\n",
      "class name               average precision (in %)\n",
      "---------------------  --------------------------\n",
      "helmet                                    89.6939\n",
      "person_with_helmet                        74.4877\n",
      "person_without_helmet                     46.5216\n",
      "\n",
      "Median Inference Time: 0.009097\n",
      "2021-06-20 12:23:51,289 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 28.609\n",
      "2021-06-20 12:23:55,452 [INFO] modulus.hooks.sample_counter_hook: Train Samples / sec: 28.609\n",
      "Time taken to run iva.detectnet_v2.scripts.train:main: 1:29:56.893039.\n"
     ]
    }
   ],
   "source": [
    "# Retraining using the pruned model as pretrained weights \n",
    "!tlt-train detectnet_v2 -e $SPECS_DIR/detectnet_v2_retrain_resnet18_kitti.txt \\\n",
    "                        -r $USER_EXPERIMENT_DIR/experiment_dir_retrain \\\n",
    "                        -k $KEY \\\n",
    "                        -n resnet18_detector_helmet_pruned_0_2 \\\n",
    "                        --gpus $NUM_GPUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 25520\r\n",
      "-rwxrwxrwx 1 1000 1000  1321808 Jun 20 09:47 resnet18_detector_helmet_pruned.tlt\r\n",
      "-rwxrwxrwx 1 1000 1000 24807408 Jun 20 12:23 resnet18_detector_helmet_pruned_0_2.tlt\r\n"
     ]
    }
   ],
   "source": [
    "# Listing the newly retrained model.\n",
    "!ls -rlt $USER_EXPERIMENT_DIR/experiment_dir_retrain/weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluate the retrained model <a class=\"anchor\" id=\"head-7\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section evaluates the pruned and retrained model, using `tlt-evaluate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "2021-06-20 13:11:48.340366: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-06-20 13:11:50,252 [INFO] iva.detectnet_v2.spec_handler.spec_loader: Merging specification from helmet/detectnet_v2/tlt_specs/detectnet_v2_retrain_resnet18_kitti.txt\n",
      "2021-06-20 13:11:51.222899: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-06-20 13:11:51.247391: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 13:11:51.247855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce RTX 2060 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.68\n",
      "pciBusID: 0000:06:00.0\n",
      "2021-06-20 13:11:51.247878: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-06-20 13:11:51.247919: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2021-06-20 13:11:51.248914: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2021-06-20 13:11:51.249152: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2021-06-20 13:11:51.250320: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2021-06-20 13:11:51.251189: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2021-06-20 13:11:51.251238: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-06-20 13:11:51.251384: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 13:11:51.251869: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 13:11:51.252257: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
      "2021-06-20 13:11:51.252283: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-06-20 13:11:51.887308: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-06-20 13:11:51.887353: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
      "2021-06-20 13:11:51.887360: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
      "2021-06-20 13:11:51.887592: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 13:11:51.887975: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 13:11:51.888328: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 13:11:51.888663: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6213 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:06:00.0, compute capability: 7.5)\n",
      "2021-06-20 13:11:52,457 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: Serial augmentation enabled = False\n",
      "2021-06-20 13:11:52,458 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: Pseudo sharding enabled = False\n",
      "2021-06-20 13:11:52,458 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: Max Image Dimensions (all sources): (0, 0)\n",
      "2021-06-20 13:11:52,458 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: number of cpus: 16, io threads: 32, compute threads: 16, buffered batches: 4\n",
      "2021-06-20 13:11:52,458 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: total dataset size 247, number of sources: 1, batch size per gpu: 14, steps: 18\n",
      "2021-06-20 13:11:52,534 [INFO] iva.detectnet_v2.dataloader.default_dataloader: Bounding box coordinates were detected in the input specification! Bboxes will be automatically converted to polygon coordinates.\n",
      "2021-06-20 13:11:52.557440: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 13:11:52.557738: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce RTX 2060 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.68\n",
      "pciBusID: 0000:06:00.0\n",
      "2021-06-20 13:11:52.557770: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-06-20 13:11:52.557806: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2021-06-20 13:11:52.557821: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2021-06-20 13:11:52.557834: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2021-06-20 13:11:52.557846: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2021-06-20 13:11:52.557858: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2021-06-20 13:11:52.557870: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-06-20 13:11:52.557937: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 13:11:52.558206: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 13:11:52.558415: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
      "2021-06-20 13:11:52,798 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: shuffle: False - shard 0 of 1\n",
      "2021-06-20 13:11:52,802 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: sampling 1 datasets with weights:\n",
      "2021-06-20 13:11:52,802 [INFO] modulus.blocks.data_loaders.multi_source_loader.data_loader: source: 0 weight: 1.000000\n",
      "2021-06-20 13:11:53,051 [INFO] iva.detectnet_v2.evaluation.build_evaluator: Found 247 samples in validation set\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 3, 544, 960)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 64, 272, 480) 9472        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 64, 272, 480) 256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 64, 272, 480) 0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_conv_1 (Conv2D)        (None, 64, 136, 240) 36928       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_1 (BatchNormalizati (None, 64, 136, 240) 256         block_1a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_relu_1 (Activation)    (None, 64, 136, 240) 0           block_1a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_conv_2 (Conv2D)        (None, 64, 136, 240) 36928       block_1a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_conv_shortcut (Conv2D) (None, 64, 136, 240) 4160        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_2 (BatchNormalizati (None, 64, 136, 240) 256         block_1a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_bn_shortcut (BatchNorm (None, 64, 136, 240) 256         block_1a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 64, 136, 240) 0           block_1a_bn_2[0][0]              \n",
      "                                                                 block_1a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1a_relu (Activation)      (None, 64, 136, 240) 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_conv_1 (Conv2D)        (None, 64, 136, 240) 36928       block_1a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_bn_1 (BatchNormalizati (None, 64, 136, 240) 256         block_1b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_relu_1 (Activation)    (None, 64, 136, 240) 0           block_1b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_conv_2 (Conv2D)        (None, 64, 136, 240) 36928       block_1b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_bn_2 (BatchNormalizati (None, 64, 136, 240) 256         block_1b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 64, 136, 240) 0           block_1b_bn_2[0][0]              \n",
      "                                                                 block_1a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_1b_relu (Activation)      (None, 64, 136, 240) 0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_conv_1 (Conv2D)        (None, 128, 68, 120) 73856       block_1b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_1 (BatchNormalizati (None, 128, 68, 120) 512         block_2a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_relu_1 (Activation)    (None, 128, 68, 120) 0           block_2a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_conv_2 (Conv2D)        (None, 128, 68, 120) 147584      block_2a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_conv_shortcut (Conv2D) (None, 128, 68, 120) 8320        block_1b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_2 (BatchNormalizati (None, 128, 68, 120) 512         block_2a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_bn_shortcut (BatchNorm (None, 128, 68, 120) 512         block_2a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 128, 68, 120) 0           block_2a_bn_2[0][0]              \n",
      "                                                                 block_2a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2a_relu (Activation)      (None, 128, 68, 120) 0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_conv_1 (Conv2D)        (None, 128, 68, 120) 147584      block_2a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_bn_1 (BatchNormalizati (None, 128, 68, 120) 512         block_2b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_relu_1 (Activation)    (None, 128, 68, 120) 0           block_2b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_conv_2 (Conv2D)        (None, 128, 68, 120) 147584      block_2b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_bn_2 (BatchNormalizati (None, 128, 68, 120) 512         block_2b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 128, 68, 120) 0           block_2b_bn_2[0][0]              \n",
      "                                                                 block_2a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_2b_relu (Activation)      (None, 128, 68, 120) 0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_conv_1 (Conv2D)        (None, 256, 34, 60)  295168      block_2b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_1 (BatchNormalizati (None, 256, 34, 60)  1024        block_3a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_relu_1 (Activation)    (None, 256, 34, 60)  0           block_3a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_conv_2 (Conv2D)        (None, 256, 34, 60)  590080      block_3a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_conv_shortcut (Conv2D) (None, 256, 34, 60)  33024       block_2b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_2 (BatchNormalizati (None, 256, 34, 60)  1024        block_3a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_bn_shortcut (BatchNorm (None, 256, 34, 60)  1024        block_3a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 256, 34, 60)  0           block_3a_bn_2[0][0]              \n",
      "                                                                 block_3a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3a_relu (Activation)      (None, 256, 34, 60)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_conv_1 (Conv2D)        (None, 248, 34, 60)  571640      block_3a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_bn_1 (BatchNormalizati (None, 248, 34, 60)  992         block_3b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_relu_1 (Activation)    (None, 248, 34, 60)  0           block_3b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_conv_2 (Conv2D)        (None, 256, 34, 60)  571648      block_3b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_bn_2 (BatchNormalizati (None, 256, 34, 60)  1024        block_3b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 256, 34, 60)  0           block_3b_bn_2[0][0]              \n",
      "                                                                 block_3a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_3b_relu (Activation)      (None, 256, 34, 60)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_conv_1 (Conv2D)        (None, 352, 34, 60)  811360      block_3b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_bn_1 (BatchNormalizati (None, 352, 34, 60)  1408        block_4a_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_relu_1 (Activation)    (None, 352, 34, 60)  0           block_4a_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_conv_2 (Conv2D)        (None, 512, 34, 60)  1622528     block_4a_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_conv_shortcut (Conv2D) (None, 512, 34, 60)  131584      block_3b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_bn_2 (BatchNormalizati (None, 512, 34, 60)  2048        block_4a_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_bn_shortcut (BatchNorm (None, 512, 34, 60)  2048        block_4a_conv_shortcut[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 512, 34, 60)  0           block_4a_bn_2[0][0]              \n",
      "                                                                 block_4a_bn_shortcut[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_4a_relu (Activation)      (None, 512, 34, 60)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_conv_1 (Conv2D)        (None, 88, 34, 60)   405592      block_4a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_bn_1 (BatchNormalizati (None, 88, 34, 60)   352         block_4b_conv_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_relu_1 (Activation)    (None, 88, 34, 60)   0           block_4b_bn_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_conv_2 (Conv2D)        (None, 512, 34, 60)  406016      block_4b_relu_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_bn_2 (BatchNormalizati (None, 512, 34, 60)  2048        block_4b_conv_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 512, 34, 60)  0           block_4b_bn_2[0][0]              \n",
      "                                                                 block_4a_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block_4b_relu (Activation)      (None, 512, 34, 60)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "output_bbox (Conv2D)            (None, 12, 34, 60)   6156        block_4b_relu[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "output_cov (Conv2D)             (None, 3, 34, 60)    1539        block_4b_relu[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 6,149,695\n",
      "Trainable params: 6,141,151\n",
      "Non-trainable params: 8,544\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-20 13:11:53.941828: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 13:11:53.942111: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce RTX 2060 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.68\n",
      "pciBusID: 0000:06:00.0\n",
      "2021-06-20 13:11:53.942139: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-06-20 13:11:53.942174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2021-06-20 13:11:53.942188: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2021-06-20 13:11:53.942200: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2021-06-20 13:11:53.942212: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2021-06-20 13:11:53.942223: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2021-06-20 13:11:53.942235: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-06-20 13:11:53.942292: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 13:11:53.942540: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 13:11:53.942737: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
      "2021-06-20 13:11:53.943663: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-06-20 13:11:53.943673: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
      "2021-06-20 13:11:53.943678: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
      "2021-06-20 13:11:53.943768: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 13:11:53.944023: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 13:11:53.944228: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6213 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:06:00.0, compute capability: 7.5)\n",
      "2021-06-20 13:11:55,029 [INFO] iva.detectnet_v2.evaluation.evaluation: step 0 / 18, 0.00s/step\n",
      "2021-06-20 13:11:55.480091: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2021-06-20 13:11:55.512103: I tensorflow/core/kernels/cuda_solvers.cc:159] Creating CudaSolver handles for stream 0x92247a0\n",
      "2021-06-20 13:11:55.512431: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2021-06-20 13:11:55.999452: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-06-20 13:11:56.157096: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2021-06-20 13:12:00,354 [INFO] iva.detectnet_v2.evaluation.evaluation: step 10 / 18, 0.53s/step\n",
      "Matching predictions to ground truth, class 1/3.: 100%|| 413/413 [00:00<00:00, 24164.04it/s]\n",
      "Matching predictions to ground truth, class 2/3.: 100%|| 1484/1484 [00:00<00:00, 23783.92it/s]\n",
      "Matching predictions to ground truth, class 3/3.: 100%|| 190/190 [00:00<00:00, 21529.01it/s]\n",
      "\n",
      "Validation cost: 0.000670\n",
      "Mean average_precision (in %): 69.4064\n",
      "\n",
      "class name               average precision (in %)\n",
      "---------------------  --------------------------\n",
      "helmet                                    87.7353\n",
      "person_with_helmet                        74.0432\n",
      "person_without_helmet                     46.4407\n",
      "\n",
      "Median Inference Time: 0.009020\n",
      "2021-06-20 13:12:01,876 [INFO] iva.detectnet_v2.scripts.evaluate: Evaluation complete.\n",
      "Time taken to run iva.detectnet_v2.scripts.evaluate:main: 0:00:11.626096.\n"
     ]
    }
   ],
   "source": [
    "!tlt-evaluate detectnet_v2 -e $SPECS_DIR/detectnet_v2_retrain_resnet18_kitti.txt \\\n",
    "                           -m $USER_EXPERIMENT_DIR/experiment_dir_retrain/weights/resnet18_detector_helmet_pruned_0_2.tlt \\\n",
    "                           -k $KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualize inferences <a class=\"anchor\" id=\"head-8\"></a>\n",
    "In this section, we run the `tlt-infer` tool to generate inferences on the trained models. To render bboxes from more classes, please edit the spec file `detectnet_v2_inference_kitti_tlt.txt` to include all the classes you would like to visualize and edit the rest of the file accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this you will need to create `test_images` directory containing at least 8 images with masked and no-masked faces, it can be from test data or simply face captures from your own photos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "2021-06-20 13:12:25.116141: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-06-20 13:12:27,331 [INFO] iva.detectnet_v2.scripts.inference: Overlain images will be saved in the output path.\n",
      "2021-06-20 13:12:27,331 [INFO] iva.detectnet_v2.inferencer.build_inferencer: Constructing inferencer\n",
      "2021-06-20 13:12:27.332468: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-06-20 13:12:27.332625: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 13:12:27.332998: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce RTX 2060 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.68\n",
      "pciBusID: 0000:06:00.0\n",
      "2021-06-20 13:12:27.333013: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-06-20 13:12:27.333043: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2021-06-20 13:12:27.333831: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2021-06-20 13:12:27.333866: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2021-06-20 13:12:27.334754: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2021-06-20 13:12:27.335416: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2021-06-20 13:12:27.335448: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-06-20 13:12:27.335522: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 13:12:27.335887: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 13:12:27.336193: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
      "2021-06-20 13:12:27.336211: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-06-20 13:12:27.946793: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-06-20 13:12:27.946838: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
      "2021-06-20 13:12:27.946845: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
      "2021-06-20 13:12:27.947052: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 13:12:27.947555: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 13:12:27.947915: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 13:12:27.948234: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6126 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:06:00.0, compute capability: 7.5)\n",
      "2021-06-20 13:12:27,948 [INFO] iva.detectnet_v2.inferencer.tlt_inferencer: Loading model from /workspace/mntpt/helmet/detectnet_v2/experiment_dir_retrain/weights/resnet18_detector_helmet_pruned_0_2.tlt:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3, 544, 960)       0         \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              [(None, 3, 34, 60), (None 6149695   \n",
      "=================================================================\n",
      "Total params: 6,149,695\n",
      "Trainable params: 6,141,151\n",
      "Non-trainable params: 8,544\n",
      "_________________________________________________________________\n",
      "2021-06-20 13:12:29,665 [INFO] iva.detectnet_v2.scripts.inference: Initialized model\n",
      "2021-06-20 13:12:29,666 [INFO] iva.detectnet_v2.scripts.inference: Commencing inference\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]2021-06-20 13:12:30.925044: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-06-20 13:12:31.921922: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "100%|| 1/1 [00:07<00:00,  7.25s/it]\n",
      "2021-06-20 13:12:36,916 [INFO] iva.detectnet_v2.scripts.inference: Inference complete\n"
     ]
    }
   ],
   "source": [
    "# Running inference for detection on n images\n",
    "!tlt-infer detectnet_v2 -e $SPECS_DIR/detectnet_v2_inference_kitti_tlt.txt \\\n",
    "                        -o $USER_EXPERIMENT_DIR/tlt_infer_testing \\\n",
    "                        -i $DATA_DOWNLOAD_DIR/test_images \\\n",
    "                        -k $KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `tlt-infer` tool produces two outputs. \n",
    "1. Overlain images in `$USER_EXPERIMENT_DIR/tlt_infer_testing/images_annotated`\n",
    "2. Frame by frame bbox labels in kitti format located in `$USER_EXPERIMENT_DIR/tlt_infer_testing/labels`\n",
    "\n",
    "*Note: To run inferences for a single image, simply replace the path to the -i flag in `tlt-infer` command with the path to the image.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple grid visualizer\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from math import ceil\n",
    "valid_image_ext = ['.jpg', '.png', '.jpeg', '.ppm']\n",
    "\n",
    "def visualize_images(image_dir, num_cols=4, num_images=10):\n",
    "    output_path = os.path.join(os.environ['USER_EXPERIMENT_DIR'], image_dir)\n",
    "    num_rows = int(ceil(float(num_images) / float(num_cols)))\n",
    "    f, axarr = plt.subplots(num_rows, num_cols, figsize=[80,30])\n",
    "    f.tight_layout()\n",
    "    a = [os.path.join(output_path, image) for image in os.listdir(output_path) \n",
    "         if os.path.splitext(image)[1].lower() in valid_image_ext]\n",
    "    for idx, img_path in enumerate(a[:num_images]):\n",
    "        col_id = idx % num_cols\n",
    "        row_id = idx / num_cols\n",
    "        img = plt.imread(img_path)\n",
    "        axarr[row_id, col_id].imshow(img) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-91ead3767157>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mIMAGES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m \u001b[0;31m# number of images to visualize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mvisualize_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOUTPUT_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCOLS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_images\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mIMAGES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-27-9e549cb89c76>\u001b[0m in \u001b[0;36mvisualize_images\u001b[0;34m(image_dir, num_cols, num_images)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mrow_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnum_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0maxarr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 5760x2160 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing the first 12 images.\n",
    "OUTPUT_PATH = 'tlt_infer_testing/images_annotated' # relative path from $USER_EXPERIMENT_DIR.\n",
    "COLS = 4 # number of columns in the visualizer grid.\n",
    "IMAGES = 8 # number of images to visualize.\n",
    "\n",
    "visualize_images(OUTPUT_PATH, num_cols=COLS, num_images=IMAGES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Deploy! <a class=\"anchor\" id=\"head-9\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "2021-06-20 13:20:09.224378: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-06-20 13:20:11.323208: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-06-20 13:20:11.323375: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 13:20:11.323748: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce RTX 2060 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.68\n",
      "pciBusID: 0000:06:00.0\n",
      "2021-06-20 13:20:11.323765: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-06-20 13:20:11.323799: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2021-06-20 13:20:11.324618: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2021-06-20 13:20:11.324656: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2021-06-20 13:20:11.325550: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2021-06-20 13:20:11.326208: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2021-06-20 13:20:11.326243: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-06-20 13:20:11.326321: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 13:20:11.326687: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 13:20:11.326993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
      "2021-06-20 13:20:11.327012: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-06-20 13:20:11.924294: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-06-20 13:20:11.924341: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
      "2021-06-20 13:20:11.924347: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
      "2021-06-20 13:20:11.924558: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 13:20:11.924931: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 13:20:11.925273: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 13:20:11.925594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6102 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:06:00.0, compute capability: 7.5)\n",
      "2021-06-20 13:20:14.077570: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 13:20:14.077953: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce RTX 2060 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.68\n",
      "pciBusID: 0000:06:00.0\n",
      "2021-06-20 13:20:14.077981: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-06-20 13:20:14.078008: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2021-06-20 13:20:14.078027: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2021-06-20 13:20:14.078037: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2021-06-20 13:20:14.078047: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2021-06-20 13:20:14.078057: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2021-06-20 13:20:14.078067: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-06-20 13:20:14.078117: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 13:20:14.078454: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 13:20:14.078748: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
      "2021-06-20 13:20:14.078770: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-06-20 13:20:14.078776: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
      "2021-06-20 13:20:14.078781: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
      "2021-06-20 13:20:14.078853: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 13:20:14.079190: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 13:20:14.079492: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6102 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:06:00.0, compute capability: 7.5)\n",
      "2021-06-20 13:20:15.705602: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 13:20:15.705965: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce RTX 2060 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.68\n",
      "pciBusID: 0000:06:00.0\n",
      "2021-06-20 13:20:15.705992: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-06-20 13:20:15.706020: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2021-06-20 13:20:15.706039: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2021-06-20 13:20:15.706049: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2021-06-20 13:20:15.706060: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2021-06-20 13:20:15.706071: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2021-06-20 13:20:15.706081: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-06-20 13:20:15.706131: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 13:20:15.706470: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 13:20:15.706760: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
      "2021-06-20 13:20:15.706782: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-06-20 13:20:15.706788: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
      "2021-06-20 13:20:15.706793: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
      "2021-06-20 13:20:15.706865: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 13:20:15.707199: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 13:20:15.707498: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6102 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:06:00.0, compute capability: 7.5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-20 13:20:17.284592: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 13:20:17.284965: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce RTX 2060 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.68\n",
      "pciBusID: 0000:06:00.0\n",
      "2021-06-20 13:20:17.284995: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-06-20 13:20:17.285022: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2021-06-20 13:20:17.285040: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2021-06-20 13:20:17.285051: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2021-06-20 13:20:17.285062: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2021-06-20 13:20:17.285073: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2021-06-20 13:20:17.285083: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-06-20 13:20:17.285135: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 13:20:17.285478: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 13:20:17.285773: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
      "2021-06-20 13:20:17.285979: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 13:20:17.286283: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: GeForce RTX 2060 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.68\n",
      "pciBusID: 0000:06:00.0\n",
      "2021-06-20 13:20:17.286297: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-06-20 13:20:17.286308: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n",
      "2021-06-20 13:20:17.286319: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n",
      "2021-06-20 13:20:17.286329: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n",
      "2021-06-20 13:20:17.286339: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n",
      "2021-06-20 13:20:17.286350: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n",
      "2021-06-20 13:20:17.286360: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-06-20 13:20:17.286408: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 13:20:17.286747: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 13:20:17.287041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
      "2021-06-20 13:20:17.287063: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-06-20 13:20:17.287069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
      "2021-06-20 13:20:17.287074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
      "2021-06-20 13:20:17.287148: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 13:20:17.287491: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-20 13:20:17.287792: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6102 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:06:00.0, compute capability: 7.5)\n",
      "NOTE: UFF has been tested with TensorFlow 1.14.0.\n",
      "WARNING: The version of TensorFlow installed on this system is not guaranteed to work with UFF.\n",
      "DEBUG [/usr/local/lib/python3.6/dist-packages/uff/converters/tensorflow/converter.py:96] Marking ['output_cov/Sigmoid', 'output_bbox/BiasAdd'] as outputs\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p $USER_EXPERIMENT_DIR/experiment_dir_final\n",
    "# Removing a pre-existing copy of the etlt if there has been any.\n",
    "import os\n",
    "output_file=os.path.join(os.environ['USER_EXPERIMENT_DIR'],\n",
    "                         \"experiment_dir_final_0_2/resnet18_detector_pruned.etlt\")\n",
    "if os.path.exists(output_file):\n",
    "    os.system(\"rm {}\".format(output_file))\n",
    "!tlt-export detectnet_v2 \\\n",
    "            -m $USER_EXPERIMENT_DIR/experiment_dir_retrain/weights/resnet18_detector_helmet_pruned_0_2.tlt \\\n",
    "            -o $USER_EXPERIMENT_DIR/experiment_dir_final_0_2/resnet18_detector_pruned.etlt \\\n",
    "            -k $KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported model:\n",
      "------------\n",
      "total 24M\r\n",
      "-rwxrwxrwx 1 1000 1000 24M Jun 20 13:20 resnet18_detector_pruned.etlt\r\n"
     ]
    }
   ],
   "source": [
    "print('Exported model:')\n",
    "print('------------')\n",
    "!ls -lh $USER_EXPERIMENT_DIR/experiment_dir_final_0_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Int8 Optimization <a class=\"anchor\" id=\"head-9-1\"></a>\n",
    "DetectNet_v2 model supports int8 inference mode in TRT. In order to use int8 mode, we must calibrate the model to run 8-bit inferences. This involves 2 steps\n",
    "\n",
    "* Generate calibration tensorfile from the training data using tlt-int8-tensorfile\n",
    "* Use tlt-export to generate int8 calibration table.\n",
    "\n",
    "*Note: For this example, we generate a calibration tensorfile containing 10 batches of training data.\n",
    "Ideally, it is best to use atleast 10-20% of the training data to calibrate the model. The more data provided during calibration, the closer int8 inferences are to fp32 inferences.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tlt-int8-tensorfile detectnet_v2 -e $SPECS_DIR/detectnet_v2_retrain_resnet18_kitti.txt \\\n",
    "                                  -m 40 \\\n",
    "                                  -o $USER_EXPERIMENT_DIR/experiment_dir_final/calibration.tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf $USER_EXPERIMENT_DIR/experiment_dir_final/resnet18_detector.etlt\n",
    "!rm -rf $USER_EXPERIMENT_DIR/experiment_dir_final/calibration.bin\n",
    "!tlt-export detectnet_v2 \\\n",
    "            -m $USER_EXPERIMENT_DIR/experiment_dir_retrain/weights/resnet18_detector_pruned.tlt \\\n",
    "            -o $USER_EXPERIMENT_DIR/experiment_dir_final/resnet18_detector.etlt \\\n",
    "            -k $KEY  \\\n",
    "            --cal_data_file $USER_EXPERIMENT_DIR/experiment_dir_final/calibration.tensor \\\n",
    "            --data_type int8 \\\n",
    "            --batches 20 \\\n",
    "            --batch_size 4 \\\n",
    "            --max_batch_size 4\\\n",
    "            --engine_file $USER_EXPERIMENT_DIR/experiment_dir_final/resnet18_detector.trt.int8 \\\n",
    "            --cal_cache_file $USER_EXPERIMENT_DIR/experiment_dir_final/calibration.bin \\\n",
    "            --verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Generate TensorRT engine <a class=\"anchor\" id=\"head-9-2\"></a>\n",
    "Verify engine generation using the `tlt-converter` utility included with the docker.\n",
    "\n",
    "The `tlt-converter` produces optimized tensorrt engines for the platform that it resides on. Therefore, to get maximum performance, please instantiate this docker and execute the `tlt-converter` command, with the exported `.etlt` file and calibration cache (for int8 mode) on your target device. The converter utility included in this docker only works for x86 devices, with discrete NVIDIA GPU's. \n",
    "\n",
    "For the jetson devices, please download the converter for jetson from the dev zone link [here](https://developer.nvidia.com/tlt-converter). \n",
    "\n",
    "If you choose to integrate your model into deepstream directly, you may do so by simply copying the exported `.etlt` file along with the calibration cache to the target device and updating the spec file that configures the `gst-nvinfer` element to point to this newly exported model. Usually this file is called `config_infer_primary.txt` for detection models and `config_infer_secondary_*.txt` for classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Some tactics do not have sufficient workspace memory to run. Increasing workspace size may increase performance, please check verbose output.\n",
      "[INFO] Detected 1 inputs and 2 output network tensors.\n"
     ]
    }
   ],
   "source": [
    "!tlt-converter $USER_EXPERIMENT_DIR/experiment_dir_final_0_2/resnet18_detector_pruned.etlt \\\n",
    "               -k $KEY \\\n",
    "               -c $USER_EXPERIMENT_DIR/experiment_dir_final_0_2/calibration.bin \\\n",
    "               -o output_cov/Sigmoid,output_bbox/BiasAdd \\\n",
    "               -d 3,544,960 \\\n",
    "               -i nchw \\\n",
    "               -m 64 \\\n",
    "               -t fp16 \\\n",
    "               -e $USER_EXPERIMENT_DIR/experiment_dir_final_0_2/resnet18_detector_pruned.trt \\\n",
    "               -b 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Verify Deployed Model <a class=\"anchor\" id=\"head-10\"></a>\n",
    "Verify the exported model by visualizing inferences on TensorRT.\n",
    "In addition to running inference on a `.tlt` model in [step 8](#head-8), the `tlt-infer` tool is also capable of consuming the converted `TensorRT engine` from [step 9.B](#head-9-2).\n",
    "\n",
    "*If after int-8 calibration the accuracy of the int-8 inferences seem to degrade, it could be because the there wasn't enough data in the calibration tensorfile used to calibrate thee model or, the training data is not entirely representative of your test images, and the calibration maybe incorrect. Therefore, you may either regenerate the calibration tensorfile with more batches of the training data, and recalibrate the model, or calibrate the model on a few images from the test set. This may be done using `--cal_image_dir` flag in the `tlt-export` tool. For more information, please follow the instructions in the USER GUIDE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Inference using TensorRT engine <a class=\"anchor\" id=\"head-10-1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "2021-06-20 13:31:42.334773: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n",
      "2021-06-20 13:31:44,395 [INFO] iva.detectnet_v2.scripts.inference: Overlain images will be saved in the output path.\n",
      "2021-06-20 13:31:44,395 [INFO] iva.detectnet_v2.inferencer.build_inferencer: Constructing inferencer\n",
      "2021-06-20 13:31:44,834 [INFO] iva.detectnet_v2.inferencer.trt_inferencer: Reading from engine file at: /workspace/mntpt/helmet/detectnet_v2/experiment_dir_final_0_2/resnet18_detector_pruned.trt\n",
      "[TensorRT] WARNING: Current optimization profile is: 0. Please ensure there are no enqueued operations pending in this context prior to switching profiles\n",
      "2021-06-20 13:31:45,739 [INFO] iva.detectnet_v2.scripts.inference: Initialized model\n",
      "2021-06-20 13:31:45,739 [INFO] iva.detectnet_v2.scripts.inference: Commencing inference\n",
      "100%|| 1/1 [00:06<00:00,  6.16s/it]\n",
      "2021-06-20 13:31:51,895 [INFO] iva.detectnet_v2.inferencer.trt_inferencer: Clearing input buffers.\n",
      "2021-06-20 13:31:51,896 [INFO] iva.detectnet_v2.inferencer.trt_inferencer: Clearing output buffers.\n",
      "2021-06-20 13:31:51,896 [INFO] iva.detectnet_v2.inferencer.trt_inferencer: Clearing tensorrt runtime.\n",
      "2021-06-20 13:31:51,896 [INFO] iva.detectnet_v2.inferencer.trt_inferencer: Clearing tensorrt context.\n",
      "2021-06-20 13:31:51,896 [INFO] iva.detectnet_v2.inferencer.trt_inferencer: Clearing tensorrt engine.\n",
      "2021-06-20 13:31:51,896 [INFO] iva.detectnet_v2.scripts.inference: Inference complete\n"
     ]
    }
   ],
   "source": [
    "!tlt-infer detectnet_v2 -e $SPECS_DIR/detectnet_v2_inference_kitti_etlt.txt \\\n",
    "                        -o $USER_EXPERIMENT_DIR/etlt_infer_testing \\\n",
    "                        -i $DATA_DOWNLOAD_DIR/test_images \\\n",
    "                        -k $KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-d06e2efeb55a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mIMAGES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m \u001b[0;31m# number of images to visualize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mvisualize_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOUTPUT_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCOLS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_images\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mIMAGES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-27-9e549cb89c76>\u001b[0m in \u001b[0;36mvisualize_images\u001b[0;34m(image_dir, num_cols, num_images)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mrow_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnum_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0maxarr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 5760x2160 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize the first 12 inferenced images.\n",
    "OUTPUT_PATH = 'etlt_infer_testing/images_annotated' # relative path from $USER_EXPERIMENT_DIR.\n",
    "COLS = 4 # number of columns in the visualizer grid.\n",
    "IMAGES = 8 # number of images to visualize.\n",
    "\n",
    "visualize_images(OUTPUT_PATH, num_cols=COLS, num_images=IMAGES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
